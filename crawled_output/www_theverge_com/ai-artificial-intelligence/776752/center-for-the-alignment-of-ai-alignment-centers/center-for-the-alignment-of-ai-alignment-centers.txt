Aligning those who align AI, one satirical website at a time | The VergeSkip to main contentThe homepageThe VergeThe Verge logo.The VergeThe Verge logo.TechReviewsScienceEntertainmentAIHamburger Navigation ButtonThe homepageThe VergeThe Verge logo.Hamburger Navigation ButtonNavigation DrawerThe VergeThe Verge logo.Login / Sign UpcloseCloseSearchTechExpandAll TechAmazonAppleFacebookGoogleMicrosoftSamsungBusinessCreatorsMobilePolicySecurityTransportationReviewsExpandAll ReviewsBuying GuidesDealsGift GuideLaptopsPhonesHeadphonesTabletsSmart HomeSmartwatchesSpeakersDronesScienceExpandAll ScienceSpaceEnergyEnvironmentHealthEntertainmentExpandAll EntertainmentGamesTV ShowsMoviesAudioAICarsExpandAll CarsElectric CarsAutonomous CarsRide-SharingScootersOther TransportationFeaturesVideosExpandAll VideosYouTubeTikTokInstagramPodcastsExpandAll PodcastsDecoderThe VergecastNewslettersExpandAll NewslettersThe Verge DailyInstallerVerge DealsNotepadOptimizerRegulatorThe StepbackStoreSubscribeFacebookThreadsInstagramYoutubeRSSThe VergeThe Verge logo.Aligning those who align AI, one satirical website at a timeComments0Comments DrawerCommentsLoading commentsGetting the conversation ready...AICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechAligning those who align AI, one satirical website at a timeA new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. A new center uses humor to point out the tangled web of those focused on making AI safe with AI companies themselves. by
Elissa WelleCloseElissa WellePosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleSep 11, 2025, 8:24 PM UTCLinkFacebookThreadsComments0CommentsImage: Cath Virginia / The Verge, Getty ImagesElissa WelleCloseElissa WellePosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa Welle is a NYC-based AI reporter and is currently supported by the Tarbell Center for AI Journalism. She covers AI companies, policies, and products.The work of creating artificial intelligence that holds to the guardrails of human values, known in the industry as alignment, has developed into its own (somewhat ambiguous) field of study rife with policy papers and benchmarks to rank models against each other.But who aligns the alignment researchers?Enter the Center for the Alignment of AI Alignment Centers, an organization purporting to coordinate thousands of AI alignment researchers into “one final AI center singularity.”At first glance, CAAAC seems legitimate. The aesthetics of the website are cool and calming, with a logo of converging arrows reminiscent of the idea of togetherness and sets of parallel lines swirling behind black font.But stay on the page for 30 seconds and the swirls spell out “bullshit,” giving away that CAAAC is all one big joke. One second longer and you’ll notice the hidden gems tucked away in every sentence and page of the fantasy center’s website.CAAAC launched Tuesday from the same team that brought us The Box, a literal, physical box that women can wear on dates to avoid the threat of their image being turned into AI-generated deepfake slop.“This website is the most important thing that anyone will read about AI in this millenium or the next,” said CAAAC cofounder Louis Barclay, staying in character when talking to The Verge. (The second founder of CAAAC wished to remain anonymous, according to Barclay.)CAAAC’s vibe is so similar to AI alignment research labs — who are featured on the website’s homepage with working links to their own websites — that even those in the know initially thought it was real, including Kendra Albert, a machine learning researcher and technology attorney, who spoke with The Verge.CAAAC makes fun of the trend, according to Albert, of those who want to make AI safe drifting away from the “real problems happening in the real world” — such as bias in models, exacerbating the energy crisis, or replacing workers — to the “very, very theoretical” risks of AI taking over the world, Albert said in an interview with The Verge.To fix the “AI alignment alignment crisis,” CAAAC will be recruiting its global workforce exclusively from the Bay Area. All are welcome to apply, “as long as you believe AGI will annihilate all humans in the next six months,” according to the jobs page.Those who are willing to take the dive to work with CAAAC — the website urges all readers to bring their own wet gear — need only comment on the LinkedIn post announcing the center to automatically become a fellow. CAAAC also offers a generative AI tool to create your own AI center, complete with an executive director, in “less than a minute, zero AI knowledge required.”The more ambitious job seeker applying to the “AI Alignment Alignment Alignment Researcher” position will, after clicking through the website, eventually find themselves serenaded by Rick Astley’s “Never Gonna Give You Up.”0 CommentsFollow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates.Elissa WelleCloseElissa WellePosts from this author will be added to your daily email digest and your homepage feed.PlusFollowSee All by Elissa WelleAICloseAIPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All AINewsCloseNewsPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All NewsTechCloseTechPosts from this topic will be added to your daily email digest and your homepage feed.PlusFollowSee All TechMost PopularMost PopularApple’s new iPhone charger is a (second) of its kindMicrosoft is changing how Xbox controllers work on Windows 11iOS 26 with Apple’s Liquid Glass redesign is out nowThe unbearable sameness of Liquid GlassAirPods Pro 3 review: tripling down on a good thingThe Verge DailyA free daily digest of the news that matters most.Email (required)Sign UpBy submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.Advertiser Content FromThis is the title for the native adMore in AIGoogle thinks it can have AI summaries and a healthy web, tooMicrosoft’s Office apps now have free Copilot Chat featuresHere’s why usage of Gemini’s Nano Banana image editor is growingRolling Stone’s parent company sues Google over AI OverviewsTucker Carlson asks Sam Altman if an OpenAI employee was murdered ‘on your orders’Encyclopedia Britannica and Merriam-Webster sue Perplexity for copying their definitions Google thinks it can have AI summaries and a healthy web, tooElissa WelleSep 15Microsoft’s Office apps now have free Copilot Chat featuresTom WarrenSep 15Here’s why usage of Gemini’s Nano Banana image editor is growingRobert HartSep 15Rolling Stone’s parent company sues Google over AI OverviewsTerrence O'BrienSep 14Tucker Carlson asks Sam Altman if an OpenAI employee was murdered ‘on your orders’Richard LawlerSep 13Encyclopedia Britannica and Merriam-Webster sue Perplexity for copying their definitions Elissa WelleSep 12Advertiser Content FromThis is the title for the native adTop StoriesSep 15The unbearable sameness of Liquid GlassSep 15Battling for the lead at an IRL version of Mario KartSep 15I’ve been using macOS Tahoe 26 since June and here are the eight best things about itSep 15AirPods Pro 3 review: tripling down on a good thingSep 15How brands and creators are fighting for your attention — and your moneySep 15Trump says foreign workers are ‘welcome’ after ICE raid in Georgia targets hundreds of South KoreansThe VergeThe Verge logo.FacebookThreadsInstagramYoutubeRSSContactTip UsCommunity GuidelinesAboutEthics StatementHow We Rate and Review ProductsCookie SettingsTerms of UsePrivacy NoticeCookie PolicyLicensing FAQAccessibilityPlatform Status© 2025 Vox Media, LLC. All Rights Reserved