Stargazers · fla-org/flash-linear-attention · GitHub
Skip to content
Navigation Menu
Toggle navigation
Sign in
Appearance settings
Platform
GitHub Copilot
Write better code with AI
GitHub Spark
New
Build and deploy intelligent apps
GitHub Models
New
Manage and compare prompts
GitHub Advanced Security
Find and fix vulnerabilities
Actions
Automate any workflow
Codespaces
Instant dev environments
Issues
Plan and track work
Code Review
Manage code changes
Discussions
Collaborate outside of code
Code Search
Find more, search less
Explore
Why GitHub
Documentation
GitHub Skills
Blog
Integrations
GitHub Marketplace
MCP Registry
View all features
Solutions
By company size
Enterprises
Small and medium teams
Startups
Nonprofits
By use case
DevSecOps
DevOps
CI/CD
View all use cases
By industry
Healthcare
Financial services
Manufacturing
Government
View all industries
View all solutions
Resources
Topics
AI
DevOps
Security
Software Development
View all
Explore
Learning Pathways
Events & Webinars
Ebooks & Whitepapers
Customer Stories
Partners
Executive Insights
Open Source
GitHub Sponsors
Fund open source developers
The ReadME Project
GitHub community articles
Repositories
Topics
Trending
Collections
Enterprise
Enterprise platform
AI-powered developer platform
Available add-ons
GitHub Advanced Security
Enterprise-grade security features
Copilot for business
Enterprise-grade AI features
Premium Support
Enterprise-grade 24/7 support
Pricing
Search or jump to...
Search code, repositories, users, issues, pull requests...
Search
Clear
Search syntax tips
Provide feedback
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel
Submit feedback
Saved searches
Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our documentation.
Cancel
Create saved search
Sign in
Sign up
Appearance settings
Resetting focus
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
Dismiss alert
fla-org
/
flash-linear-attention
Public
Notifications
You must be signed in to change notification settings
Fork
255
Star
3.3k
Code
Issues
37
Pull requests
8
Discussions
Actions
Projects
0
Wiki
Security
Uh oh!
There was an error while loading. Please reload this page.
Insights
Additional navigation options
Code
Issues
Pull requests
Discussions
Actions
Projects
Wiki
Security
Insights
Stargazers
All 3,305
You know
CrazyDave999
Works for Shanghai Jiao Tong University
Shanghai Jiao Tong University
Follow
cs-qyzhang
Works for Huazhong University of Science and Technology
Huazhong University of Science and Technology
Follow
yaolinx10
Joined on Jul 28, 2025
Follow
enduringstack
Joined on Feb 19, 2017
Follow
9p15p
Joined on Jun 17, 2018
Follow
linln1
Is from Beijing
Beijing
Follow
HuangZiheng-o-O
Joined on Jul 28, 2021
Follow
RissyRan
Joined on Jul 10, 2016
Follow
DucHUNG312
Works for Hanoi University of Science and Technology
Hanoi University of Science and Technology
Follow
sufubao
Works for shenzhen university
shenzhen university
Follow
KunB-Fighting
Joined on Mar 13, 2017
Follow
lixumin-zai
Joined on Oct 21, 2018
Follow
werdupboyee
Joined on Jan 9, 2022
Follow
xinyu-intel
Works for @intel
@intel
Follow
Ananddd06
Is from Chennai
Chennai
Follow
vadiklyutiy
Joined on Jan 11, 2024
Follow
masc-it
Is from Bari, Italy
Bari, Italy
Follow
FENP
Is from Hangzhou, China
Hangzhou, China
Follow
fairyshine
Joined on Jul 22, 2019
Follow
dansasser
Works for Sasser Development, LLC
Sasser Development, LLC
Follow
Snrise-Z
Joined on Jan 13, 2024
Follow
zhuochenKIDD
Is from Beijing
Beijing
Follow
ycli219
Joined on Sep 10, 2024
Follow
stein-666
Works for Tsinghua University
Tsinghua University
Follow
PreviousNext
Footer
© 2025 GitHub, Inc.
Footer navigation
Terms
Privacy
Security
Status
Docs
Contact
Manage cookies
Do not share my personal information
You can’t perform that action at this time.