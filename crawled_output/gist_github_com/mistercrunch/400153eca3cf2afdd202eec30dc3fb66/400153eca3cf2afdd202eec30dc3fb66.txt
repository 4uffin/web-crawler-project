gist:400153eca3cf2afdd202eec30dc3fb66 ¬∑ GitHub
Skip to content
Search Gists
Search Gists
All gists
Back to GitHub
Sign in
Sign up
Sign¬†in
Sign¬†up
You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.
Dismiss alert
Instantly share code, notes, and snippets.
mistercrunch/gist:400153eca3cf2afdd202eec30dc3fb66
Created
September 17, 2025 03:05
Show Gist options
Download ZIP
Star
1
(1)
You must be signed in to star a gist
Fork
0
(0)
You must be signed in to fork a gist
Embed
Embed
Embed this gist in your website.
Share
Copy sharable link for this gist.
Clone via HTTPS
Clone using the web URL.
Learn more about clone URLs
Clone this repository at &lt;script src=&quot;https://gist.github.com/mistercrunch/400153eca3cf2afdd202eec30dc3fb66.js&quot;&gt;&lt;/script&gt;
Save mistercrunch/400153eca3cf2afdd202eec30dc3fb66 to your computer and use it in GitHub Desktop.
Code
Revisions
1
Stars
1
Embed
Embed
Embed this gist in your website.
Share
Copy sharable link for this gist.
Clone via HTTPS
Clone using the web URL.
Learn more about clone URLs
Clone this repository at &lt;script src=&quot;https://gist.github.com/mistercrunch/400153eca3cf2afdd202eec30dc3fb66.js&quot;&gt;&lt;/script&gt;
Save mistercrunch/400153eca3cf2afdd202eec30dc3fb66 to your computer and use it in GitHub Desktop.
Download ZIP
Raw
gistfile1.txt
# Prompt Style Analysis
Analyze a user's prompting style to understand what makes their interactions with AI coding assistants effective.
## Analysis Scope
$ARGUMENTS
## Process
### Step 1: Extract and Prepare Data
1. **Extract user prompts from conversation history**
- Use `jq -r '.projects | to_entries[] | .value.history[]?.display // empty' ~/.claude.json > /tmp/user_prompts.txt`
- If no arguments provided, analyze all prompts
- If project path provided as argument, filter to that project only
2. **Handle large files**
- If file >5MB, sample first 2000, middle 2000, and last 2000 prompts for balanced analysis
- Truncate individual prompts >1000 chars to avoid skewing statistics
### Step 2: Quantitative Analysis
Gather comprehensive metrics:
1. **Basic Statistics**
- Total prompts analyzed
- Average prompt length (chars)
- Number of sessions (separated by empty prompts)
- Prompts per session average
2. **Length Distribution**
- Short (<50 chars): Quick commands/acknowledgments
- Medium (50-200 chars): Standard requests
- Long (200-500 chars): Detailed instructions
- Very Long (>500 chars): Complex problems/pastes
3. **Communication Patterns**
- Questions (ending with ?)
- Exclamations (ending with !)
- Commands (starting with action verbs)
- Acknowledgments (ok, good, thanks, etc.)
4. **Technical Content**
- Error/debug content (stack traces, error messages)
- Test-related (pytest, jest, test files)
- Code/paths (file paths, function names)
- URLs/PRs (links, PR numbers)
### Step 3: Dimensional Analysis
Score each dimension on a 1-10 scale:
#### Core Dimensions
1. **Assertive ‚Üî Questioning** (1=Always asking, 10=Always commanding)
- Analyze ratio of questions to statements
- Look for: "can you", "could you", "what if" vs direct commands
2. **Formal ‚Üî Informal** (1=Very formal, 10=Very casual)
- Check for casual language: "yo", "hey", slang, contractions
- Count proper punctuation and grammar vs shortcuts
3. **Technical ‚Üî Abstract** (1=High-level, 10=Deep technical)
- Count file paths, function names, error logs
- Measure specificity of requests
4. **Enthusiastic ‚Üî Neutral** (1=Flat, 10=Very enthusiastic)
- Count exclamation marks, positive words
- Look for energy indicators: "let's go!", "awesome"
5. **Directive ‚Üî Collaborative** (1=Commands only, 10=Full collaboration)
- Check for inclusive language: "let's", "we", "should we"
- Ratio of imperatives to suggestions
6. **Patient ‚Üî Urgent** (1=Very patient, 10=Very urgent)
- Look for urgency markers: "quick", "asap", "now"
- Check follow-up frequency
7. **Verbose ‚Üî Concise** (1=Very brief, 10=Very detailed)
- Based on length distribution
- Amount of context provided
8. **Goal-Oriented ‚Üî Exploratory** (1=Exploration, 10=Clear goals)
- Check for specific deliverables and file outputs
- Look for exploratory language: "curious", "what if"
9. **Prompt Length Profile** (NEW)
- Micro (<25 chars): Single word/phrase responses
- Short (25-75 chars): Quick commands
- Standard (75-250 chars): Normal requests
- Extended (250-500 chars): Detailed instructions
- Comprehensive (>500 chars): Full context/pastes
### Step 4: Pattern Recognition
Identify key behavioral patterns:
1. **Starting Patterns**
- Most common first words (reveals default approach)
- Greeting style (formal/informal/none)
2. **Iteration Style**
- Course corrections: "wait", "oh", "actually"
- Error recovery patterns
- Follow-up frequency
3. **Context Provision**
- Pasted content frequency
- Error log inclusion
- File path specificity
4. **Politeness & Tone**
- Please/thanks frequency
- Apology patterns
- Acknowledgment style
### Step 5: Generate Report
## Output Format
Create a markdown report and save to `/tmp/prompt-style-report.md`:
```markdown
# üéØ Prompt Style Analysis Report
## Executive Summary
**Total Prompts**: [number] | **Sessions**: [number] | **Avg Length**: [chars]
### Your Style Profile: "[Style Title]"
*[2-sentence description of what makes this style effective]*
## üìä Dimensional Scores (1-10)
| Dimension | Score | Interpretation |
|-----------|-------|----------------|
| **Assertiveness** | [X]/10 | [Questioning ‚Üê ‚Üí Commanding] |
| **Formality** | [X]/10 | [Formal ‚Üê ‚Üí Casual] |
| **Technical Depth** | [X]/10 | [Abstract ‚Üê ‚Üí Technical] |
| **Energy Level** | [X]/10 | [Neutral ‚Üê ‚Üí Enthusiastic] |
| **Collaboration** | [X]/10 | [Directive ‚Üê ‚Üí Collaborative] |
| **Urgency** | [X]/10 | [Patient ‚Üê ‚Üí Urgent] |
| **Verbosity** | [X]/10 | [Concise ‚Üê ‚Üí Detailed] |
| **Goal Focus** | [X]/10 | [Exploratory ‚Üê ‚Üí Goal-Oriented] |
## üìà Prompt Length Distribution
| Category | Count | Percentage | Typical Use |
|----------|-------|------------|-------------|
| Micro (<25) | [n] | [%] | Acknowledgments |
| Short (25-75) | [n] | [%] | Quick commands |
| Standard (75-250) | [n] | [%] | Normal requests |
| Extended (250-500) | [n] | [%] | Detailed instructions |
| Comprehensive (500+) | [n] | [%] | Context/pastes |
## üé≠ Communication Patterns
### Top Starting Words
1. [word] ([count] times)
2. [word] ([count] times)
3. [word] ([count] times)
### Interaction Style
- Questions: [n] ([%])
- Commands: [n] ([%])
- Acknowledgments: [n] ([%])
- Course corrections: [n] ([%])
### Technical Content
- Error/debug pastes: [n] ([%])
- Test-related: [n] ([%])
- File paths/code: [n] ([%])
- URLs/PRs: [n] ([%])
## üí™ Key Strengths
1. **[Strength]**: [Brief explanation]
2. **[Strength]**: [Brief explanation]
3. **[Strength]**: [Brief explanation]
## üéØ Effectiveness Indicators
- **Clarity Score**: [High/Medium/Low] - Based on specificity of requests
- **Context Richness**: [High/Medium/Low] - Based on information provided
- **Iteration Style**: [Smooth/Moderate/Frequent] - Based on corrections needed
## üöÄ Recommendations
1. **Keep doing**: [What's working well]
2. **Consider**: [Potential improvement]
3. **Try**: [New technique to enhance effectiveness]
---
*Generated on [date] | Analyzed [n] prompts across [n] sessions*
```
## Final Steps
1. Display summary in terminal showing:
- Total prompts analyzed
- Dominant style classification
- Top 3 dimensional scores
- One key insight
2. Inform user that full report saved to `/tmp/prompt-style-report.md`
3. Suggest sharing insights with team to improve collective AI interaction skills
Sign up for free
to join this conversation on GitHub.
Already have an account?
Sign in to comment
Footer
¬© 2025 GitHub,¬†Inc.
Footer navigation
Terms
Privacy
Security
Status
Community
Docs
Contact
Manage cookies
Do not share my personal information
You can‚Äôt perform that action at this time.