AMD’s RDNA4 GPU architecture | Hacker NewsHacker Newsnew | past | comments | ask | show | jobs | submitloginAMD’s RDNA4 GPU architecture (chipsandcheese.com)106 points by rbanffy 11 hours ago
| hide | past | favorite | 8 comments
steelbrain 1 hour ago
| next [–]
Went down the MI300A rabbit hole that was just casually mentioned in this post (https://chipsandcheese.com/p/inside-the-amd-radeon-instinct-...). What a fun chip! (and blog!)replyerulabs 3 hours ago
| prev | next [–]
Lower power consumption on a desktop monitor is an interesting technical challenge but I do wonder “Cui bono?” - obviously I’d want my gaming machine to consume less power but I’m not sure I’ve ever considered mouse-idle monitor-on power consumption when considering eg AMD versus Nvidia for my gaming machine.Don’t get me wrong this is very interesting and AMD does great engineering and I loath to throw shade on an engineering focused company but… Is this going to convert to even a single net gain purchase for AMD?I’m a relatively (to myself) a large AMD shareholder (colloquially: fanboy) and damn I’d love to see more focus on hardware matmul acceleration rather than idle monitor power draw.replyLuker88 14 minutes ago
| parent | next [–]
Some people appreciate leaving the pc open for light tasks even at night, and wasting too much power doing nothing is... well, wasteful. Imagine a home server that has the GPU for AI or multimedia stuff.The same architecture will also be used in mobile, so depending on where this comes from (architecturally) it could mean more power savings there, too.Besides, lower power also means lower cooling/noise on idle, and shorter cooldown times after a burst of work.And since AMD is slowly going to the (ever next-time) unified architecture, any gains there will also mean less idle power draw in other environments, like servers.Nothing groundbreaking, sure, but I won't say no to all of that.replyjayd16 2 hours ago
| parent | prev | next [–]
Rumors have been floating around about some kind of PS6 portable or next gen steam deck with RDNA4 where power consumption matters.There's also simply laptop longevity that would be nice.replymakeitdouble 1 hour ago
| parent | prev | next [–]
To wager a guess, would that optimization also help push the envelope when one application needs all the power it can get while another monitor is just sitting idle ?Another angle I'm wondering about is longevity of the card. Not sure if AMD would positively care in the first place, but as a user if the card didn't have to grind much on the idle parts and thus last a year or two longer, it would be pretty valuable.replyadgjlsfhk1 2 hours ago
| parent | prev | next [–]
the architecture is shared between desktop and mobile. this sounds 100% like something that they did to give some dual display laptop or handheld 3 hours extra battery life by fixing something dumb.replysyntaxing 6 hours ago
| prev [–]
More curious, does RDNA4 have native FP8 support?replykrasin 6 hours ago
| parent [–]
I refer to the RDNA4 instruction set manual ([1]), page 90, Table 41. WMMA Instructions.They support FP8/BF8 with F32 accumulate and also IU4 with I32 accumulate. The max matrix size is 16x16. For comparison, NVIDIA Blackwell GB200 supports matrices up to 256x32 for FP8 and 256x96 for NVFP4.This matters for overall throughput, as feeding a bigger matrix unit is actually cheaper in terms of memory bandwidth, as the number of FLOPs grows O(n^2) when increasing the size of a systolic array, while the number of inputs/outputs as O(n).1. https://www.amd.com/content/dam/amd/en/documents/radeon-tech...2. https://semianalysis.com/2025/06/23/nvidia-tensor-core-evolu...reply
Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search: