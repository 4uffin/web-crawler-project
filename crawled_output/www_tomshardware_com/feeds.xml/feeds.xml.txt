<![CDATA[ Latest from Tom's Hardware ]]>
https://www.tomshardware.com
All the latest content from the Tom's Hardware team
Wed, 17 Sep 2025 18:31:41 +0000
en
<![CDATA[ PlayStation 5 Digital Edition with 1TB SSD downgraded to 825GB listed at the same price — CFI-2116 revision emerges overseas on Amazon ]]>
<p>The rumors (via <a data-analytics-id="inline-link" href="https://x.com/billbil_kun/status/1967899998382952566?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1967899998382952566%7Ctwgr%5E85f97f0baf6bbfa74ab49ae3fe800cdd6accf54c%7Ctwcon%5Es1_c10&ref_url=https%3A%2F%2Fkotaku.com%2Fsony-playstation-5-digital-slim-storage-price-2000622679">billbil-kun</a>) regarding Sony's revision of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/playstation-5-sony-ps5">PlayStation 5 </a>Digital Edition have been confirmed through various overseas Amazon listings. Although the new CFI-2116 revision maintains the original pricing, Sony has decreased the internal storage from 1TB to 825GB, representing a 17.5% reduction in capacity. This change further emphasizes the importance for owners to upgrade their consoles with one of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ps5-ssds">best PS5 SSDs.<br><br></a>The PlayStation 5 has been on the market for nearly five years, during which time the console has undergone multiple hardware revisions. These modifications have varied from minor optimizations, such as improvements in heatsink design, to substantial hardware alterations, including a die shrink, culminating in the transition to the PlayStation 5 Slim models. Consequently, the most recent CFI-2116 revision feels like a regression.<br><br>The original PlayStation 5, colloquially referred to now as the PlayStation 5 Fat, was equipped with 825GB of internal storage, of which approximately 650GB was accessible to the user, depending on system updates and other variables. The shift to the PlayStation 5 Slim introduced numerous enhancements, including an increase to 1TB of storage, providing the user with approximately 850GB of available space (subject to similar factors).<br><br>The CFI-2116 revision, also known as "Chassis E," marks the return of the 825GB SSD, which Sony advertises on the new packaging. Consumers are losing close to 200GB, or 24%, of usable, high-speed storage with the latest revision. You could argue that 200GB isn't a lot, and that's true in a way since some AAA titles — specifically, <em>Call of Duty: Black Ops Cold War —</em> are pushing over 300GB of installed size. But under normal circumstances, 200GB should be enough for one or two games.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1500px;"><p class="vanilla-image-block" style="padding-top:48.20%;"><img id="Mvu4VYuhS7ziGvZMKZKXb5" name="61h7VjYt-fL._AC_SL1500_ (1)" alt="PlayStation 5 Digital Edition" src="https://cdn.mos.cms.futurecdn.net/Mvu4VYuhS7ziGvZMKZKXb5.jpg" mos="" link="" align="" fullscreen="" width="1500" height="723" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Amazon Italy)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:459px;"><p class="vanilla-image-block" style="padding-top:154.68%;"><img id="8ZhCgh6rkTRDJ4ucLrcMGF" name="41gEsV574zL" alt="PlayStation 5 Digital Edition" src="https://cdn.mos.cms.futurecdn.net/8ZhCgh6rkTRDJ4ucLrcMGF.jpg" mos="" link="" align="" fullscreen="" width="459" height="710" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Amazon Italy)</span></figcaption></figure></div></div></div><p>The reason Sony has downgraded the internal storage in the CFI-2116 revision is unknown. If it weren't for past leaks or the Amazon listings, we wouldn't even know about the revision, since Sony hasn't officially announced it. However, given the current market situation, it's plausible that the downgrade could be a way for Sony to optimize production costs without resorting to another price hike. Sony already <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/console-gaming/sony-hikes-ps5-prices-by-usd50-starting-tomorrow-sony-adds-up-to-10-percent-to-the-price-of-every-model-from-august-21">increased the pricing</a> for the different PlayStation 5 models by $50 last month, citing the "challenging economic environment." <br><br>This generation of gaming consoles is the first to experience <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/console-gaming/gaming-consoles-are-becoming-more-expensive-as-they-age-for-the-first-time-in-history-gamers-blame-tariffs-for-playstation-xbox-and-switch-price-increases">price increases</a> rather than decreases. Despite this, Sony has sold over 77 million units as of May 2025, so the company is eager to keep up the momentum. Instead of raising prices again, Sony may have decided that reducing internal storage was a better way to keep prices stable.<br><br>Sony silently released the revised PlayStation 5 Digital Edition in Europe on Sept. 13. The console has already surfaced on <a data-analytics-id="inline-link" href="https://www.amazon.es/dp/B0FN7ZG39D">Amazon Spain</a>, <a data-analytics-id="inline-link" href="https://www.amazon.it/dp/B0FN7ZG39D">Amazon Italy</a>, <a data-analytics-id="inline-link" href="https://www.amazon.fr/dp/B0FN7ZG39D">Amazon France</a>, and <a data-analytics-id="inline-link" href="https://www.amazon.de/dp/B0FN7ZG39D">Amazon Germany</a>. It's available for purchase at Amazon Italy and Amazon Germany for €499, which aligns with the European MSRP for the existing PlayStation 5 Digital Edition (Chassis D). Amazon Germany has set a delivery date by October 23.<br><br>Initial rumors suggest that the CFI-2116 revision may be exclusive to the European market. However, it's plausible that the revised console could make its way to the U.S. market. Fortunately, the revision only affects the PlayStation 5 Digital Edition, so the disc version is safe. Nonetheless, if you're set on buying the digital edition, it might be a good time to pull the trigger, as there's no telling if or when the 1TB SKUs will disappear from the shelves to be replaced by the 825GB variant.<br><br><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/video-games/playstation/playstation-5-digital-edition-with-1tb-ssd-downgraded-to-825gb-listed-at-the-same-price-cfi-2116-revision-emerges-overseas-on-amazon
The new revision (CFI-2116) of the PlayStation 5 Digital Edition has been listed on Amazon Italy, Amazon France, and Amazon Germany at the same MSRP.
oV2NsfSYWNJxnc9ojG8jJH
Wed, 17 Sep 2025 18:31:41 +0000 PlayStation
Video Games
Console Gaming
Zhiye Liu
Amazon Italy
PlayStation 5 Digital Edition
PlayStation 5 Digital Edition
<![CDATA[ Alibaba’s AI chip goes head-to-head with Nvidia H20 in state-backed benchmark demo ]]>
<p>Alibaba’s semiconductor unit, T-Head, has reportedly <a data-analytics-id="inline-link" href="https://www.reuters.com/business/media-telecom/china-spotlights-major-data-centre-project-using-domestic-chips-2025-09-17/" target="_blank"><u>developed a new AI processor</u></a> that it claims matches the performance of Nvidia’s H20 — the GPU built specifically for the Chinese market that’s currently <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-h20-gpus-reportedly-caught-up-in-u-s-commerce-departments-worst-export-license-backlog-in-30-years-billions-of-dollars-worth-of-gpus-and-other-products-in-limbo-due-to-staffing-cuts-communication-issues"><u>stuck in geopolitical purgatory</u></a>. <br><br>The demonstration aired Tuesday, September 16, on China Central Television (CCTV), during a broadcast covering Premier Li Qiang’s visit to China Umicom’s Sanjiangyuan Energy Intelligent Computing Centre in Qinghai. In the segment, T-Head’s new “PPU” accelerator was directly compared with Nvidia’s H20 and A800, as well as Huawei’s Ascend 910B, with a chart implying performance parity between the Alibaba and Nvidia parts. <br><br>The chip, an ASIC designed for AI workloads, features 96 GB of HBM2e, 700 GB/s chip-to-chip interconnect, PCIe support, and 400 W board power, according to the on-screen specs as reported by <a data-analytics-id="inline-link" href="https://www.scmp.com/tech/tech-war/article/3325894/tech-war-alibaba-developed-ai-processor-par-nvidias-h20-chip-cctv-report-shows" target="_blank"><u><em>South China Morning Post</em></u></a>. While the broadcast didn’t disclose the specifics of the testing methodology used or publish raw figures, it’s the first public benchmark placing Alibaba’s hardware in the same class as Nvidia’s datacenter GPUs. <br><br>According to <em>Reuters</em>, China Unicom has already deployed 16,384 of Alibaba’s PPU cards across its infrastructure, accounting for more than half of the almost 23,000 domestic accelerators currently installed at the Qinghai facility. Together, the cards deliver 3,579 petaflops of compute, with the site expected to scale to more than 20,000 petaflops once all phases are complete.<br><br>There’s just as much geopolitical context behind the CCTV demonstration as there is technical. <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/the-tale-of-nvidias-hgx-h20-how-an-ai-gpu-became-a-political-lightning-rod"><u>Nvidia’s H20</u></a> was introduced to comply with U.S. export controls limiting the sale of high-performance silicon to China. Built on Hopper architecture but cut down to meet restrictions, the H20 ships with 96 GB of HBM3 and roughly 4.0 TB/s of memory bandwidth. That lends some perspective to Alibaba’s matching 96 GB HBM2e capacity, though not necessarily its real-world performance. <br><br>The biggest unknown right now is on the software side. While Alibaba is understandably <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/china-bans-its-biggest-tech-companies-from-acquiring-nvidia-chips-says-report-beijing-claims-its-homegrown-ai-processors-now-match-h20-and-rtx-pro-6000d"><u>eager to show</u></a> it can meet AI hardware needs in-house, the company has not disclosed details about frameworks, toolchains, or compatibility with existing model stacks. Until independent benchmarks and developer support materialize, the PPU’s parity with Nvidia’s hardware is just a claim backed by Chinese state TV and endorsed by the Chinese government.<br><br><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><u><em> Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/alibaba-ai-chip-goes-head-to-head-with-nvidia-h20
Alibaba’s semiconductor unit, T-Head, has reportedly developed a new AI processor that it claims matches the performance of Nvidia's H20 — the GPU built specifically for the Chinese market.
eTEwJwZgicad7UUJeZVdQU
Wed, 17 Sep 2025 18:02:57 +0000 GPUs
PC Components
lukejamesalden@gmail.com (Luke James)
Luke James
Getty/Bloomberg
Nvidia CEO Jensen Huang speaking to journalists in China.
Nvidia CEO Jensen Huang speaking to journalists in China.
<![CDATA[ MSI enters the US Electric Vehicle charger market with EV Life Series ]]>
<p>When I think of MSI, I think of<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/motherboards/msi-meg-x870e-godlike-motherboard-drops-at-an-eyewatering-usd1-099-unleashes-ddr5-9000-ram-five-m-2-slots-10-gbe-and-wi-fi-7-alongside-two-usb-4-0-40-gbps-ports"> <u>motherboards</u></a>,<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/msi-skips-rdna-4-and-will-not-manufacture-amd-radeon-9000-series-gpus"> <u>video cards</u></a>,<a data-analytics-id="inline-link" href="https://www.tomshardware.com/monitors/gaming-monitors/msis-new-500-hz-qd-oled-monitor-leverages-ai-tech-to-save-it-from-burn-in"> <u>gaming monitors</u></a>, and, more recently,<a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/handheld-gaming/msis-brings-amd-based-gaming-handheld-updated-mid-range-gaming-laptops-to-computex"> <u>PC gaming handhelds</u></a>. So, the thought of MSI entering the electric vehicle (EV) was a foreign concept to me. Unbeknownst to me, even as an enthusiast with two EVs, MSI has marketed EV chargers in other parts of the world for quite some time. However, the company is now ready to expand to North America with MSI's EV Life and EV Life Plus EV chargers.</p><p>The EV Life Series is available in four different models: you can opt for a SAE J1772 or NACS (Tesla) connector in NEMA 14-50 (think U.S. dryer outlet) or hardwired configurations. No matter which SKU you choose, you'll receive an incredibly long 24.6-foot, IP55-rated charging cable and 14.4kW/60A that will add between 43 and 59 miles of range per hour to the average EV (think Tesla Model 3 or Hyundai Ioniq 7). If you're driving something like a Chevrolet Silverado EV with a massive 200 kWh battery, you'll probably see those numbers halved.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.20%;"><img id="gt3mKdvxqy8ucyErnhWi8h" name="image1" alt="MSI EV Life Series" src="https://cdn.mos.cms.futurecdn.net/gt3mKdvxqy8ucyErnhWi8h.jpg" mos="" align="middle" fullscreen="" width="1920" height="1079" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: MSI)</span></figcaption></figure><p>When it comes to EVs, many owners like to geek out on charging stats and electricity running costs. With that in mind, the EV Life Series has built-in Bluetooth, which, when paired with the MSI aConnect app, provides a powerful tool for monitoring your EV and setting up scheduling routines. With aConnect, you can monitor current and historical charging times, how much you're saving by using electricity over a comparable gasoline- or diesel-powered vehicle, the total cost of the electricity you've pumped into your EV, and how much carbon emissions you've saved.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.20%;"><img id="kGYfASWF2L3JjNwwV42cxg" name="image2" alt="MSI EV Life Series" src="https://cdn.mos.cms.futurecdn.net/kGYfASWF2L3JjNwwV42cxg.jpg" mos="" align="middle" fullscreen="" width="1920" height="1079" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: MSI)</span></figcaption></figure><p>The EV Life Plus Series is in many ways similar to its lesser sibling. You'll find the same four connection options (NACS with NEMA 14-50 or hardwired, or SAE J1772 with NEMA 14-50 or hardwired). You also get the same 14.4KW/60A charging capabilities as on the EV Life. However, the EV Life Plus amps things up with RFID authentication support along with Wi-Fi and Ethernet connectivity. The latter two features allow you to monitor the charging progress of your vehicle from anywhere, instead of the short-range limitations of Bluetooth-only support.</p><p>The EV Life Plus Series also supports the OCPP 1.6J standard, which provides a secure, industry-standard communications protocol for charging. This helps avoid vendor lock-in through proprietary standards, which is why MSI's EV chargers can work not only with Tesla vehicles, which helped popularize the NACS connector, but also with vehicles that use the SAE J1772 connector.</p><p>The MSI EV Life with NACS or SAE J1772 connector is available for $449. If you want to connect to your home's grid with a NEMA 14-50 connection, the price increases to $499. The EV Life Plus starts at $549.99 for a hardwired connection with a NACS or SAE J1772 connector. You'll also pay a $50 premium for a NEMA 14-50 electrical hookup. The chargers are available directly from<a data-analytics-id="inline-link" href="https://us-store.msi.com/EV-Solution/EV-chargers"> <u>MSI</u></a> or from<a data-analytics-id="inline-link" href="https://www.amazon.com/stores/page/741AAEE3-21A0-46D6-9F0C-073BFB4E34DE"> <u>Amazon</u></a>. For comparison,<a data-analytics-id="inline-link" href="https://shop.tesla.com/product/wall-connector"> <u>Tesla's 11.5kW/48A Wall Connector is $420</u></a>.</p>
https://www.tomshardware.com/tech-industry/msi-enters-the-us-electric-vehicle-charger-market-with-ev-life-series
MSI's EV Life and EV Life Plus EV chargers support NACS and SAE J1772 vehicles.
Q8NGpFC6D8ZK7T4XeuKsyP
Wed, 17 Sep 2025 17:30:56 +0000 Tech Industry
brandon.hill@futurenet.com (Brandon Hill)
Brandon Hill
MSI
MSI EV Life Series
MSI EV Life Series
<![CDATA[ Exploring the RTX Pro 6000D, Nvidia's China-only GPU, which is now banned from sale — neutered specs cannot compete with grey-market chips ]]>
<p>Nvidia’s RTX 6000D was never going to be a hero product. <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-reportedly-preparing-rtx-6000d-for-chinese-market-to-comply-with-u-s-export-controls-fabricated-on-tsmc-n4-featuring-gddr7-memory-capable-of-delivering-1-100-gb-s-of-bidirectional-bandwidth">Built specifically for the Chinese market</a> to navigate U.S. export restrictions, it has a constrained design: a GDDR-based Blackwell GPU with no NVLink, targeting AI inference instead of full-scale training.</p><p>Two procurement sources speaking to the <a data-analytics-id="inline-link" href="https://www.scmp.com/tech/big-tech/article/3325740/nvidia-sees-tepid-demand-new-rtx6000d-ai-chip-chinese-tech-firms-sources"><em>South China Morning Post</em></a> say that demand is tepid and the chip’s value proposition is “expensive for what it does.” And that’s before you factor in the uncomfortable comparison to Nvidia’s own RTX 5090, the flagship gaming GPU that’s officially banned from China but widely available through grey-market channels. By some measure, that consumer card not only costs half as much but outperforms the 6000D in the same inference tasks Nvidia designed its export-safe silicon to run.</p><p>Shortly after this report, it was noted that <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/china-bans-its-biggest-tech-companies-from-acquiring-nvidia-chips-says-report-beijing-claims-its-homegrown-ai-processors-now-match-h20-and-rtx-pro-6000d">China has now banned its biggest tech companies from acquiring Nvidia chips</a>, which may be the real reason why 6000D interest was so tepid in the region. But there are still interesting observations to be made about the curious 6000D itself.</p><h2 id="blackwell-sans-bandwidth-2">Blackwell sans bandwidth</h2><p>Nvidia hasn’t published formal specifications for the RTX 6000D, but multiple sources indicate it uses <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-pro-6000d-b40-blackwell-gpus-reportedly-set-to-supersede-banned-h20-accelerators-in-china">Blackwell architecture with conventional GDDR memory</a>, and delivers around 1,398 GB/s of bandwidth — just under the 1.4 TB/s export limit. There are strong indications that it avoids HBM and high‑bandwidth interconnect packaging, suggesting simpler die structures and likely dependence on PCIe or external NICs, rather than NVLink.</p><p>In other words, the 6000D is a PCIe workstation card that looks a lot like the RTX 6000 Blackwell or a tweaked 5090, just with a different name and a dramatically higher price tag. But rather than specs, the core issue is what happens when you try to scale it.</p><p>Without NVLink, the 6000D may rely on PCIe or external NICs like ConnectX to communicate between GPUs. That puts it at an immediate disadvantage in large-model inference workloads. A 70B-parameter model at FP16 can easily require 140 GB or more just for weights. Even INT8 quantization struggles to fit under 50 GB once you add the KV cache, meaning that you’ll often need two or more GPUs just to serve a single model replica. At that point, GPU-to-GPU comms becomes the bottleneck.</p><p>PCIe 4.0 x16 delivers around 64 GB/s of bandwidth. Meanwhile, NVLink 5.0 is closer to 900 GB/s. Nvidia’s own documentation recommends keeping tensor parallelism inside the NVLink domain for exactly this reason — collective operations like all-reduce and activation exchange are latency-sensitive. Try doing that over PCIe or even 800Gbps Ethernet, and step time balloons. Add more 6000Ds to the cluster, and you can imagine how the payoff in throughput starts to collapse. From a buyer's perspective, what’s the point of doing that when you can do better with alternative hardware?</p><h2 id="grey-market-swarm-2">Grey-market swarm</h2><p>The RTX 6000D retailed in China for around $7,000 (¥50,000). That’s not far off the amount you might expect to pay for a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-next-gen-ai-chip-could-double-the-price-of-h20-if-china-export-is-approved-chinese-firms-still-consider-nvidias-b30a-a-good-deal">lower-end HBM-based GPU like the H20</a>, not a GDDR card with no NVLink. And unlike the H20, it’s not even pretending to be a training-class GPU.</p><p>Now compare that to what’s available unofficially. Grey-market RTX 5090s, which were designed for gamers but blessed with Nvidia’s full Blackwell silicon, are trading for as little as $3,500 (¥25,000). Some are even being <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidias-rtx-5090-gpus-with-blower-style-coolers-appear-in-china-design-optimizes-nvidias-fastest-gaming-gpus-for-use-in-ai-workloads">resold in blower-style enclosures</a> with expanded VRAM of up to 80GB or even 128GB in modded units. Despite being technically banned under U.S. export rules, they’re everywhere. And they perform.</p><p>So, why choose the 6000D when you can get a more powerful grey-market part without any issues? From a throughput-per-yuan perspective, the grey-market 5090 swarm makes the 6000D look like a bad joke. And with better options potentially being just over the horizon, why would Chinese buyers want to spend money on the 6000D at all?</p><h2 id="a-domestic-market-right-around-the-corner-2">A domestic market right around the corner?</h2><p>A big part of the 6000D’s lackluster reception is circumstantial. Chinese buyers were still waiting on shipments of <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/the-tale-of-nvidias-hgx-h20-how-an-ai-gpu-became-a-political-lightning-rod">Nvidia’s sanctioned H20</a>, an HBM-based Hopper GPU approved for export in July but still stuck in limbo. It’s the chip many hyperscalers wanted for high-density inference, but the latest news of China's Nvidia ban calls into question whether those orders will even be fulfilled.</p><p>At the same time, there was a hope that the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-could-be-readying-b30a-accelerator-for-chinese-market-new-blackwell-chip-reportedly-beats-h20-and-even-h100-while-complying-with-u-s-export-controls">B30A</a> — a more powerful Blackwell part designed for training — would win approval for sale, too. However, with the new ban on acquiring Nvidia chips, this seems more unlikely than ever. The B30A was reportedly equipped with 144 GB of HBM3E and NVLink support, delivering up to six times the performance of the H20 for only double the price.</p><p>As evidenced by the Cyberspace Administration of China (CAC)'s latest actions, the country is clearly moving beyond reliance on Nvidia chips. There’s a deeper shift underway. China is pushing hard for domestic AI hardware adoption, mandating that state-backed clouds procure at least <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/china-mandates-domestic-firms-source-50-percent-of-chips-from-chinese-producers-beijing-continues-to-squeeze-companies-over-reliance-on-foreign-semiconductors">50% of their AI accelerators from Chinese vendors</a>. Huawei’s Ascend, Biren’s CloudMatrix, and Cambricon’s NPU lines are all on the table. So is CANN: Huawei’s CUDA alternative that just went fully open source.</p><p>This (in theory) allows developers to move workloads away from Nvidia and toward Ascend, but the transition has been rocky. Chinese LLM lab DeepSeek notoriously scrapped plans to train its next model on Ascend NPUs, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/deepseek-reportedly-urged-by-chinese-authorities-to-train-new-model-on-huawei-hardware-after-multiple-failures-r2-training-to-switch-back-to-nvidia-hardware-while-ascend-gpus-handle-inference">much to the disdain of the Chinese government</a>, citing unstable performance and poor chip-to-chip communication.</p><p>For now, that leaves China’s major clouds effectively locked into CUDA. But the political and strategic pressure to break free is building. From China's perspective, there are too few advantages to justify doubling down on Nvidia’s ecosystem, which would be terminally behind Western counterparts, if export control rules continued.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em> Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/why-nobody-is-buying-nvidia-6000d-in-china
Nvidia's RTX 6000D might be banned from sale in China, but what lies inside the GPU itself? We explore why it's not as good a deal as grey-market RTX 5090s in the region.
SpJFSsot77AggpA5dYvRpU
Wed, 17 Sep 2025 17:17:05 +0000 Semiconductors
Tech Industry
Manufacturing
lukejamesalden@gmail.com (Luke James)
Luke James
Nvidia
Nvidia RTX 6000
Nvidia RTX 6000
<![CDATA[ These must-have accessories helped me power through my overseas trip to IFA 2025 ]]>
<p>I recently took a trip overseas to Germany for IFA 2025, which meant I had to bring some essential gear to keep my devices charged while on the go. These devices ranged from a multi-outlet USB-C wall adapter to a portable 25,000 mAh battery to a thin MagSafe battery for my iPhone to a Euro plug converter for keeping my devices charged in my hotel room in Berlin.</p><h3 class="article-body__section" id="section-ugreen-65-watt-retractable-usb-c-power-block"><span>Ugreen 65-watt Retractable USB-C Power Block</span></h3><p><strong>🧳 Ugreen USB-C Power Block</strong></p><p>I actually picked up both 45-watt and 65-watt Ugreen retractable USB-C power blocks during the last Amazon Prime Day event in July. I took the 65-watt version with me on my trip due to its higher power output.</p><div class="inlinegallery
mosaic-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="FQwGymMmGbnNEb5mhvWu9R" name="image5" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/FQwGymMmGbnNEb5mhvWu9R.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="zgcb6782EcBgUob5cfuDBR" name="image1" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/zgcb6782EcBgUob5cfuDBR.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>When using it to charge a single device, the retractable USB-C cable can deliver up to 60 watts. The USB-C port tops out at 60 watts, while the USB-A port doles out 22.5 watts. If you're charging two devices at once, either the retractable USB-C cable or the USB-C port can deliver a maximum of 45 watts, with the other topping out at 25 watts.</p><p>While in my hotel room, I used the Ugreen adapter to supply power to my 3-in-1 travel MagSafe charger via the retractable USB-C cable and to charge my MacBook Air with the USB-C port. Even with my MacBook Air, iPhone, Apple Watch, and AirPods Pro charging all at once, the adapter was just barely warm to the touch. The thermal performance is likely due to the Gallium Nitride (GaN) power transistors, which help improve efficiency and thus reduce heat output.</p><p>The<a data-analytics-id="inline-link" href="https://www.amazon.com/gp/product/B0DNSQCRJB"> <u>65-watt Green USB-C Power Bank</u></a> is currently on sale for $37.99. If you can get by with the lower-output<a data-analytics-id="inline-link" href="https://www.amazon.com/gp/product/B0DRP9HKKC"> <u>45-watt version</u></a>, it sells for $28.99.</p><h3 class="article-body__section" id="section-anker-737-power-bank"><span>Anker 737 Power Bank</span></h3><p><strong>🧳 Anker 737</strong></p><p>My Anker 737 is my go-to power source when flying, and I've had it for nearly two years at this point. The power bank features a 24,000 mAh internal battery that has enough juice to charge an iPhone 16 Pro from empty to full four times.</p><p>The Anker 737 has two USB-C ports, each of which can deliver up to 140 watts if just one device is attached. There's also a USB-A port that tops out at 18 watts. When you've fully depleted the power bank, if you have a 140-watt charger on hand, you can get it back to a 100 percent charge in 52 minutes.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="Y4D8fGbJagDGwmXRncqwDR" name="image3" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/Y4D8fGbJagDGwmXRncqwDR.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:75.04%;"><img id="SzvhHKwwx74V2Xdn8iMaAR" name="image4" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/SzvhHKwwx74V2Xdn8iMaAR.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1500" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>One of my favorite features of the power bank is the built-in OLED display, which provides information on the current charge capacity, the estimated time to deplete the battery based on the current output, and the wattage delivered to each port.</p><p>While crossing the Atlantic on my NYC to Berlin leg of my trip, I used the Anker 737 to charge my iPhone 16 Pro (not in use) and iPad Pro (as I binge-watched The Pitt). Granted, I could have used the power outlet near the floor, mounted on the seat in front of me. However, since I was in the aisle seat, and the two passengers beside me kept getting up to use the bathroom, which would have required me to keep unplugging to let them pass. With the Anker 737, I just set the battery beside me in my seat. It's also a lot easier than fumbling, trying to find the seat-mounted power outlet in the dark.</p><p>The Anker 737 is<a data-analytics-id="inline-link" href="https://www.amazon.com/Anker-PowerCore-Portable-Charger-Compatible/dp/B09VPHVT2Z/"> <u>currently priced at $87.99</u></a>, or 20 percent off its MSRP of $109.99.</p><h3 class="article-body__section" id="section-baseus-magsafe-portable-charger-for-iphone-10-000mah-20w-magnetic-power-bank"><span>Baseus MagSafe Portable Charger for iPhone, 10,000mAh 20W Magnetic Power Bank</span></h3><p><strong>🧳 Baseus MagSafe Portable Chargerk</strong></p><p>When on the ground in Berlin, I was in and out of meetings, in and out of Ubers, and walking around the show floor without easy access to power. It's easy to run through my phone's battery when taking tons of pictures, uploading those images to the cloud, and recording interviews for execs.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="Q9cvoTamgXCYF5eTu7wX7R" name="image6" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/Q9cvoTamgXCYF5eTu7wX7R.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="t7pR42fJ82iE9rSYGqWX7R" name="image2" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/t7pR42fJ82iE9rSYGqWX7R.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.23%;"><img id="4oTgfnyVuhsp9hufB4PW7R" name="image8" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/4oTgfnyVuhsp9hufB4PW7R.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1124" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>As a result, I use a Baseus 10,000 mAh 20W MagSafe battery. It magnetically attaches to the back of my phone, doubling its thickness. Despite the added heft, I still have no trouble fitting it in my front pants pocket. It has enough capacity to provide a 0-100 percent charge (and a bit more) on my iPhone 16 Pro. The battery pack recharges via its USB-C port. You can also recharge your phone or another device via the USB-C port at up to 20 watts if you don't want to bother with the MagSafe function.</p><p>I bought my Baseus MagSafe battery charger on clearance from<a data-analytics-id="inline-link" href="https://sellout.woot.com/offers/baseus-magsafe-10000mah-20w-power-bank"> <u>Woot.com for $18.99</u></a>. However, a newer, 22.5-watt version of the device is<a data-analytics-id="inline-link" href="https://www.amazon.com/Baseus-Portable-10000mAh-Wireless-Compatible/dp/B0DZWVN6GX"> <u>currently available from Amazon for $26.99</u></a>.</p><h3 class="article-body__section" id="section-vintar-international-power-plug-adapter"><span>VINTAR International Power Plug Adapter</span></h3><p><strong>🧳 Vintar Power Plug Adapter</strong></p><p>All of my U.S. plugs are useless in Europe without a travel plug adapter. I previously bought a VINTAR 2-pack of Euro travel adapters for a family vacation to Greece last year, and took one along for my trip to Berlin.</p><div class="inlinegallery
mosaic-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="KGxASjBnxZoxR5QRmkW39R" name="image7" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/KGxASjBnxZoxR5QRmkW39R.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1999px;"><p class="vanilla-image-block" style="padding-top:56.28%;"><img id="ouoCKHwWTSSpNazsYrbnAR" name="image9" alt="Travel Tech" src="https://cdn.mos.cms.futurecdn.net/ouoCKHwWTSSpNazsYrbnAR.jpg" mos="" link="" align="" fullscreen="" width="1999" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The plug is quite versatile, offering two U.S.-style outlets, three USB-A ports, and one USB-C port for your devices. The plug is sturdy and doesn't feature moving parts, making it less susceptible to breaking from continual use and being tossed in my carry-on bag.</p><p>The VINTAR European Travel Plug Adapter is available in a<a data-analytics-id="inline-link" href="https://docs.google.com/document/d/1dKE0okuJ9y2nEjas3J5U2rJF5EPG4MibXPYEiqDBoaM/edit?tab=t.0"> </a><a data-analytics-id="inline-link" href="https://www.amazon.com/European-VINTAR-International-Compatible-American/dp/B07WRWX15J"><u>two-pack for $19.99 at Amazon</u></a>.</p>
https://www.tomshardware.com/peripherals/cables-connectors/these-must-have-accessories-helped-me-power-through-my-overseas-trip-to-ifa-2025
From MagSafe batteries to a retractable cable USB-C charger, here’s what’s in my overseas travel bag.
kDaHzRL7PR2egyoQqa6mjG
Wed, 17 Sep 2025 17:10:11 +0000 Cables and Connectors
Peripherals
brandon.hill@futurenet.com (Brandon Hill)
Brandon Hill
Tom&#039;s Hardware
Travel Tech
Travel Tech
<![CDATA[ This upcoming Thunderbolt 5 eGPU dock lets you mount an entire mini-PC on the side — also features aftermarket ATX and SFX power supply support ]]>
<p>Mini-PC and eGPU maker Aoostar has added yet another eGPU dock to its arsenal of products. On <a data-analytics-id="inline-link" href="https://www.reddit.com/r/eGPU/comments/1nhzw0s/aoostar_ag02_vs_wait_for_aoostar_eg01/" target="_blank">Reddit</a>, the company announced the EG01, a Thunderbolt 5 graphics card dock that supports full-size desktop graphics cards, ATX/SFX power supplies, and features an optional mini-PC holder on top. Pricing and a release date have yet to be disclosed.</p><p>Not much information has been publicly revealed about the dock; however, <a data-analytics-id="inline-link" href="https://www.notebookcheck.net/Aoostar-EG01-Thunderbolt-5-and-OCuLink-eGPU-dock-revealed-globally-with-mini-PC-mount.1116086.0.html" target="_blank">Notebookcheck</a> was able to get some in-depth information about the EG01. But the outlet was able to find that the dock allegedly takes advantage of a Thunderbolt 5 interface and is compatible with OCuLink, making it one of the first docks to feature both connectivity standards. <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/thunderbolt-5-debuts-120-gbps-speed-is-three-times-faster-than-previous-gen">Thunderbolt 5</a> and OCuLink provide a PCIe 4.0 x4 interface from the host system to the graphics card, offering the best connectivity you'll see on eGPU docks right now.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="wKBkGKqE6saJwuuoGBeDSZ" name="Aoostar EG01 eGPU dock" alt="Aoostar EG01 eGPU Dock" src="https://cdn.mos.cms.futurecdn.net/wKBkGKqE6saJwuuoGBeDSZ.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Aoostar)</span></figcaption></figure><p>The EG01 differs significantly from most of Aoostar's other eGPU docks, featuring full compatibility for desktop GPUs, but having no embedded PSU, instead having a mount for aftermarket units. For those who want to upgrade power supplies down the road, this is a great feature and allows the user to choose whatever ATX or SFX PSU they want to use, significantly increasing the dock's flexibility. Past iterations of Aoostar docks have featured embedded power supplies, ranging from 400W to 800W of power output. Besides its 800W offerings, Aoostar's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/aoostar-ag01-egpu-with-oculink-and-built-in-400w-psu-released-at-dollar150">older trims,</a> sporting 400W or <a data-analytics-id="inline-link" href="https://www.tomshardware.com/peripherals/docking-stations-hubs/aoostar-ag02-egpu-dock-with-oculink-support-and-500w-psu-announced-for-usd219">500W</a> power supplies, would limit GPU power draw to a max of 250W or 350W, respectively, limiting GPU options to AMD or Nvidia's mid-range desktop graphics cards.</p><p>With the EG01, you have the option of building a GPU setup that only needs enough power for what you need in the current moment, with an upgrade path down the road. If you find you want to upgrade to a more power-hungry GPU in the future, you can easily swap out the PSU with a more potent unit if necessary.</p><p>The dock can be used with any Thunderbolt or OCuLink capable device; however, the dock has also been designed with mini-PCs in mind. The power supply bracket includes an optional mini-PC mounting solution on the top, turning the eGPU dock into a computer that mimics a mini-ITX PC. This will inevitably be a highly used feature for those who plan on daily driving the EG01 with a mini-PC or NUC-like device rather than a laptop or handheld gaming PC.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/desktops/mini-pcs/this-upcoming-thunderbolt-5-egpu-dock-lets-you-mount-an-entire-mini-pc-on-the-side-also-features-aftermarket-atx-and-sfx-power-supply-support
Aoostar has announced an upcoming eGPU dock that features Thunderbolt 5 connectivity and OCuLink connectivity, plus support for aftermarket ATX/SFX power supplies. The cherry on top is the included mini-PC mount for mini-PC daily drivers.
4ThCooLt9dGFS5h6rhyT8b
Wed, 17 Sep 2025 16:52:46 +0000 Mini PCs
Desktops
editors@tomshardware.com (Aaron Klotz)
Aaron Klotz
Aoostar
Aoostar EG01 eGPU Dock
Aoostar EG01 eGPU Dock
<![CDATA[ Modern memory is still vulnerable to Rowhammer vulnerabilities — Phoenix root privilege escalation attack proves that Rowhammer still smashes DDR5 security to bits ]]>
<p>Scientists from the Computer Security Group (COMSEC) at the ETH Zürich college, in conjunction with Google, have published a proof-of-concept attack on DDR5 RAM called <a data-analytics-id="inline-link" href="https://comsec.ethz.ch/research/dram/phoenix/" target="_blank">Phoenix</a>, with the CVE number 2025-6202. The new attack causes bit-flips in memory, leading to a set of vulnerabilities that includes high-level privilege escalation. Phoenix adeptly bypasses DDR5's preventive measures for<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/new-rowhammer-attack-silently-corrupts-ai-models-on-gddr6-nvidia-cards-gpuhammer-attack-drops-ai-accuracy-from-80-percent-to-0-1-percent-on-rtx-a6000"> Rowhammer-style attacks</a>, and neither ECC nor ODECC (on-die ECC) are of help.</p><p>It's worth noting that COMSEC only tested the attacks on an AMD Zen 4 platform, against 15 SK hynix DDR5 DIMMs from 2021-2024. The team states it chose the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/sk-hynix-dethrones-samsung-to-become-worlds-top-selling-memory-maker-for-the-first-time-success-mostly-attributed-to-its-hbm3-dominance-for-nvidias-ai-gpus">largest DRAM vendor</a>, as the analysis is time-intensive even with the help of dedicated FPGA test boards. Having said that, the research is part of a <a data-analytics-id="inline-link" href="https://security.googleblog.com/2025/09/supporting-rowhammer-research-to.html" target="_blank">Google-led effort</a> for better RAM security in cooperation with JEDEC, the consortium that defines memory standards. It's also not the first time that COMSEC has worked on RAM security, having previously cooperated with VUSec to create the <a data-analytics-id="inline-link" href="https://www.vusec.net/projects/trrespass/" target="_blank">TRRespass attack</a>.</p><p>Phoenix is a mix-up and evolution of existing Rowhammer-style attacks that repeatedly "hammer" a set of RAM locations with reads, in a specific pattern, in a bid to force at least one bit to flip via electromagnetic interference. This allows for extracting data or modifying code to an attacker's preference. The scenario is concerning enough in desktops and workstations, but particularly worrying in large-scale servers hosting thousands of clients. You can download the proof-of-concept software at <a data-analytics-id="inline-link" href="https://github.com/comsec-group/phoenix" target="_blank">COMSEC's Phoenix GitHub repository</a> if you want to test your systems.</p><p>Phoenix's creators tested specific scenarios and had a 100% success rate in replicating attacks that manipulate Page Table Entries (PTE), granting access to forbidden locations in memory; a 73% chance of extracting the SSH login keys from a virtual machine in the same server; and a 33% probability of straight up getting root access thanks to manipulating the in-memory binary for the <strong>sudo</strong> utility. The team replicated the privilege escalation scenario in the <a data-analytics-id="inline-link" href="https://github.com/comsec-group/rubicon" target="_blank">Rubicon suite</a> in only 5 minutes and 19 seconds flat. COMSEC's researchers revealed their findings past June 6 to SK hynix, CPU vendors, and the major cloud platforms, and will publish their findings at the IEEE Security & Privacy 2026 conference.</p><p>There's no bulletproof mitigation for this issue yet — at least for the tested SK hynix DIMMs — but the researchers state that increasing the row refresh rate (tREFI) in the machine's UEFI by 3 times down to around 1.3 μs makes the attacks unlikely to succeed. However, that comes at a steep cost, as a benchmark with the SPEC CPU2017 suite revealed a nasty 8.4% performance hit. COMSEC says there's an impending BIOS update for AMD client systems to address this problem, but couldn't verify its effectiveness as of the date of its publication.</p><p><a data-analytics-id="inline-link" href="https://security.googleblog.com/2025/09/supporting-rowhammer-research-to.html" target="_blank">Google points out in a related blog post</a> that DDR5's TRR (Target Row Refresh) and ECC/ODECC can't quite fix the problem as they're not deterministic. For example, TRR's mechanism of triggering a refresh of a memory row doesn't keep an exact count of the number of accesses to it, making it easy to exploit by increasing the attack surface. Meanwhile, even the mighty ODECC only corrects bit-flips when data is written, or after a certain time (usually hours), meaning that just keeping an attack going for a long while is enough.</p><p>Those circumstances led to the creation of the PRAC (Per-Row Activation Counting) JEDEC standard, <a data-analytics-id="inline-link" href="https://www.jedec.org/news/pressreleases/jedec-updates-jesd79-5c-ddr5-sdram-standard-elevating-performance-and-security" target="_blank">first announced</a> in April 2024 for a future DD5 revision. PRAC keeps an accurate count of sequential accesses to a memory row and alerts the host system if a limit is exceeded, so that mitigation measures (likely a refresh) are implemented. Predictably, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/dram/jedec-publishes-first-lpddr6-standard-new-interface-promises-double-the-effective-bandwidth-of-current-gen">upcoming LPDDR6 standard</a> is integrating PRAC from the get-go. Here's to hoping the new feature will finally put a stake through Rowhammer's heart.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/tech-industry/cyber-security/modern-memory-is-still-vulnerable-to-rowhammer-vulnerabilities-phoenix-root-privilege-escalation-attack-proves-that-rowhammer-still-smashes-ddr5-security-to-bits
A new attack on DDR5 further demonstrates that current countermeasures against Rowhammer-style assaults aren't enough.
bQRwTZSjALkiVeM5QEDxVj
Wed, 17 Sep 2025 16:40:53 +0000 Cyber Security
Tech Industry
Bruno Ferreira
Getty Images
A hammer smashing a laptop computer.
A hammer smashing a laptop computer.
<![CDATA[ I got excited for the idea of sub-$1,000 gaming laptops with integrated graphics — but there are more than a few reasons why that's probably not happening ]]>
<p>There's been a trend the last two or three years in gaming laptops (and elsewhere) that no one likes: Prices are going up. It hasn't been surprising to see systems with the most powerful graphics, along with high-refresh displays, mechanical keyboards, or tons of RAM, to cost anywhere between $3,000 and $5,000, and more. See some of our most powerful picks like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/laptops/gaming-laptops/msi-titan-18-hx-ai-review"><u>MSI Titan 18 HX AI</u></a> and the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/laptops/gaming-laptops/razer-blade-18-review"><u>Razer Blade 18</u></a>.</p><p>But that same thing has been happening on the low end. Systems that used to be $999 or less are now often at least $1,100. Those laptops often use older processors and the lowest-end current GPUs.</p><p>Up until Lenovo announced that its Legion Go 2 handheld would start at $1,049, I was thinking that handhelds might replace the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-gaming-laptops-under-1000"><u>best gaming laptops under $1,000</u></a>.</p><p>We're in a place where it feels like we need something new to broaden what's available. Could gamers get a cheaper portable rig if they were willing to get handheld-style performance with integrated graphics?</p><p>That might not sound so appealing, but the best thing for PC gamers is to have options, including gaming laptops with discrete GPUs at $1,000 or less if that is the best they can afford. But with an increase in integrated GPU power that we've seen in everything from laptop chips to handheld <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/apu-accelerated-processing-unit-definition,37645.html"><u>APUs</u></a> to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amds-game-changing-strix-halo-apu-formerly-ryzen-ai-max-poses-for-new-die-shots"><u>Strix Halo</u></a>, along with the economies of scale that already build budget gaming PCs, could we finally see a new low-end gaming laptop with an iGPU?</p><p>It’s a nice idea, but the more I thought it through with my colleagues, the more quickly my dreams were dashed.</p><h2 id="there-s-precedent-but-it-makes-more-sense-now-2">There's precedent, but it makes more sense now</h2><p>Back in 2021, Adata released the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/xpg-xenia-xe"><u>XPG Xenia Xe</u></a>. It was a whitebox system from Intel, but more importantly, it used Intel's Core i7-1165G7 CPU with integrated Intel Iris Xe graphics. Still, Adata referred to it as a "gaming lifestyle notebook.” Its predecessor, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/xpg-xenia-15"><u>Xenia 15</u></a>, had used a GTX 1660 Ti. We saw a similar idea in <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/alienware-concept-ufo-gaming-handheld-hands-on"><u>Alienware's Concept UFO</u></a>, which used a 10th Gen Intel CPU with integrated graphics to power the gaming handheld, but that never turned into a real product.</p><p>I scoffed at the idea. My colleague at the time, Michelle Ehrhardt, titled her review of the system "expensive and unbalanced." It was $1,600. She was right.</p><p>But what if the Xenia Xe hadn't been designed to be premium? I could see a version of that, using today's chips, making a new kind of low-end gaming laptop.</p><p>Imagine an ultraportable-sized system, perhaps with a 14-inch, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/what-is-fhd-full-hd,5741.html"><u>1080p</u></a> display up to 120 Hz, using something like the AMD Ryzen Z2 Extreme (or its most equivalent laptop part that exists). Other than some beefed up cooling, designs using largely plastic chassis that could work are probably already sitting on shelves.</p><h2 id="what-would-make-that-gaming-2">What would make that gaming?</h2><p>On the other hand, there are laptops out there now with chips using AMD's Radeon 890M, though they're generally in premium <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ultrabooks-premium-laptops"><u>ultrabooks</u></a>. People do play games on those, the same way Apple's entire product line doesn't include a dedicated "gaming" laptop. There's no reason you couldn't use one of them, but they're probably priced higher than I'm thinking.</p><p>So, now we have a theoretical plastic laptop with an otherwise strong chip that could, generously, play games at 1080p on medium settings. Hopefully, that could make for something affordable, even if it's not powerful.</p><p>With handhelds, gamers accept that lack of power because they get portability. Gamers expect portability from laptops already. So what would make
something like this a gaming laptop? What could give that <em>value?</em></p><p>For starters, I would want to see an OS focused on gaming. What if it was officially licensed to run SteamOS, and you could use Arch Linux for productivity? Or perhaps it could run Windows 11's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/handheld-gaming/microsoft-focusing-on-handheld-gaming-support-with-new-xbox-compact-mode"><u>upcoming handheld gaming mode</u></a> that will debut on the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/handheld-gaming/asus-rog-xbox-ally-and-xbox-ally-x-to-launch-october-16-co-branded-handhelds-sport-new-cpus-game-friendly-windows-tweaks-but-pricing-is-still-unknown"><u>Asus ROG Xbox Ally</u></a>. In exchange for power, get rid of bloatware and give people a gaming-focused experience. Using one of these would also allow for game validation, like what the Steam Deck and upcoming Xbox Ally will offer, so you can get an idea if games will run. But honestly, these should be options on high-end machines, too.</p><p>The laptop companies could also team up with Nvidia or Microsoft to get lengthy trial subscriptions to streaming services for games that may have trouble running well on integrated graphics.</p><p>Lastly, if you're not paying for a discrete GPU, maybe toss a mechanical keyboard in there. It's not unprecedented. The Dell G16 previously had cheap configurations with a Cherry keyboard, and that was a great value-add (the Dell Gaming lineup has since been discontinued).</p><p>There's also the question of which companies might be bold enough to put their gaming brand on a laptop without a discrete GPU.</p><h2 id="counterpoint-the-market-is-complex-2">Counterpoint: The market is complex</h2><p>But enough brainstorming. When you start to think about how things really work, this idea is harder than it seems.</p><p>Take my thought that companies could stick a chip with strong integrated graphics in some existing system's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/pc-chassis-definition,37651.html"><u>chassis</u></a>. They probably could, to some degree, but more cooling would still be helpful. And existing gaming laptop designs are built around the idea that a dedicated GPU is there, so tweaking that would require more tooling. Additionally, using an existing gaming chassis defeats the idea that you could get a slimmer laptop if you don't have a GPU to cool.</p><p>Next up is that in most systems, the companies that make gaming laptops can pair the CPU and GPU they want together. That's why we're seeing so many RTX 50-series laptops with 13th Gen Intel Core CPUs — those CPUs are fast <em>enough</em>, and they're likely cheaper. Companies can mix and match to hit whatever price point they want. But APUs using graphics like Radeon 890M are the highest-end parts, paired with high-end CPU cores, and they're sold at a premium.</p><p>If a laptop company wanted to make something like what I described, they might have to go to Intel or AMD and ask for something custom, and that would require a big order. (This is also what happened with the Steam Deck. Valve got a custom chip.)</p><p>Otherwise, we're hoping Intel or AMD come around and make an SoC with a "good enough" CPU but the best GPU cores on the market. That doesn't seem likely, especially with limited fab capacity and a demand for higher-margin parts.</p><p>In an ideal world, maybe one day, the companies that make these systems could bring costs back down. But realistically, I don't see that happening. That makes each gaming laptop below $1,000 a rare bird these days. And while an RTX xx50-class mobile GPU might not excite you, it's all some people can afford, especially as prices creep up.</p><p>Despite the hardships of doing it cheaply, we are already seeing some steps down this road; they're just not cheap. After all, we saw AMD's Radeon 8060S with the Ryzen AI Max+ 395 in the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/gaming-pcs/framework-desktop-review"><u>Framework Desktop</u></a>, as well as in the Asus ROG Flow Z13. The latter is technically a laptop (well, tablet) and is selling <a data-analytics-id="inline-link" href="https://www.bestbuy.com/product/asus-rog-flow-z13-13-4-2-5k-180hz-touch-screen-gaming-laptop-copilot-pc-amd-ryzen-ai-max-395-64gb-ram-1tb-ssd-off-black/JJGGLHG8X9"><u>for $2,400 on Best Buy</u></a>. Admittedly, it would be easy to drop the price by using something without Strix Halo and 64GB of RAM. But even then, it’s probably not getting close to the sub $1,000 mark, at least until it goes on clearance.</p><p>And companies that make gaming handhelds have been <em>raising</em> prices. If those devices sell, no company is going to have much incentive to put those in laptops at a lower price.</p><h2 id="almost-but-not-quite-there-2">Almost, but not quite, there</h2><p>I think we're a lot closer to the idea of laptop gaming on integrated graphics than we've ever been. (You can argue it's been happening for a long time! People who want to game will find the means to play on any system they have.)</p><p>On the other hand, people buy gaming laptops because they want to play games – usually modern AAA titles. Some of the initial handheld chips, like the Steam Deck's Aerith, are showing their age. This happens to all systems, eventually.</p><p>That might just be the way games are now, with less optimization and more graphical capabilities (Nvidia and AMD are trying to sell their high-end GPUs, after all). But to call a laptop a gaming laptop, it really needs to play all of the games, at least for a while after launch. So maybe a few more iterations will be required before this idea is ready for prime time.</p><p>But it also means we need to wait for great integrated graphics to get even cheaper for market forces to get in line. I think it would be great to see a true "gaming lifestyle notebook" that’s slim, powerful enough for most games, and ready with plenty of gaming features at the OS level. But with all of the factors making it tough on the low end, we'll have to settle for pricier Strix Halo experiments, at least for now.</p>
https://www.tomshardware.com/laptops/gaming-laptops/i-got-excited-for-the-idea-of-sub-usd1-000-gaming-laptops-with-integrated-graphics-but-there-are-more-than-a-few-reasons-why-thats-probably-not-happening
The prices of gaming laptops have been going up. Is it possible for laptops with integrated graphics to bridge the gap? It sounds like a good idea until you look into market realities.
DCjNGnQ2Hpd2Wb4onrsCPC
Wed, 17 Sep 2025 16:38:13 +0000 Gaming Laptops
Laptops
Andrew E. Freedman
Tom&#039;s Hardware, AMD
Sub-$1,000 gaming laptops with integrated graphics
Sub-$1,000 gaming laptops with integrated graphics
<![CDATA[ DOOM left running on ASUS MyPal PDA for 2.5 years finally crashes — bug that crashes the game when gametic value hits 2,147,483,647 ticks likely to blame ]]>
<p>Released in December of 1993 after an unbelievable amount of hype among PC gamers hooked up to the then-novel Internet, <em>DOOM</em> codified the standards of the nascent first-person shooter genre and was so popular that "<em>Doom</em> clone" was the way we described first-person shooters for years after its release. Gamers have put millions, if not billions of hours, into the title in the nearly 32 years since its launch, thanks to a virtual cornucopia of mods and user levels, but it's pretty unlikely that many of them have left the game running for upwards of two years straight. <a data-analytics-id="inline-link" href="https://lenowo.org/viewtopic.php?t=31" target="_blank">At least one person did</a>, though, and the result is... that it crashed.</p><p>Posting at LenOwO, site admin Minki remarks that they have reproduced the expected crash by loading<em> WinDOOM</em> on what appears to be an ASUS MyPal A620 pocket PC from 2003 running the then-novel Windows Mobile on an <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-builds-10nm-arm-chips,32501.html" target="_blank">Intel XScale ARMv5 SoC</a>. Minki says that the device was modified to use a "DIY 18650 [lithium cell] based UPS which was itself connected to the USB port of my router for a constant 5V supply." They left the system running and mostly forgot about it until yesterday, when they noticed a pop-up appearing on the device and complaining of an application crash:</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="sKBtPo78Th4NWPqyebDtuA" name="windoom-fatal-error-fhd-crop" alt="A cropped photo showing the WinDOOM crashing after over two years on Windows Mobile 2003." src="https://cdn.mos.cms.futurecdn.net/sKBtPo78Th4NWPqyebDtuA.png" mos="" align="middle" fullscreen="1" width="1920" height="1080" attribution="" endorsement="" class="expandable"></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">The crash, in the ASUS MyPal's Windows Mobile 2003 operating system. </span><span class="credit" itemprop="copyrightHolder">(Image credit: minki/LenOwO)</span></figcaption></figure><p>Like most source ports of the era, WinDOOM is based on the original source code release from 1997, and so it reproduces most features — and most bugs — of the original game. Like most large commercial software projects, <em>DOOM</em> has <a data-analytics-id="inline-link" href="https://doomwiki.org/wiki/Engine_bug" target="_blank">numerous known bugs</a> even in its final 1.9 release. Among them is a curious quirk where, when playing back "demo" files internally, usually for the game's "attract" loop, the "gametic" value does not reset upon starting a new demo playback. This value is used for tracking game timing for various purposes, and it increments at a rate of 35 Hz, or 35 times per second, independent of the game's render loop.</p><p>It doesn't take even high school-level math to figure out that the gametic value never resetting will eventually result in an enormous value over time. <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/in-1991-after-a-28-hour-coding-spree-the-efforts-of-john-carmack-doomed-us-all" target="_blank">Principal <em>DOOM</em> engine coder John Carmack</a> was surely aware of this when he programmed it, but he likely reasoned that it simply didn't matter because the value is stored as a signed 32-bit integer. That means that it can reach a maximum value of 2,147,483,647 ticks before rolling over. Integer overflow behavior is undefined in C, but on x86 PCs it always results in a roll-over to the maximum negative value of -2,147,483,647. Unsurprisingly, the game doesn't handle this very gracefully, which is to say it crashes, at least on Windows Mobile 2003.</p><a href="https://github.com/chocolate-doom/chocolate-doom/issues/1287#issuecomment-636414423"><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:648px;"><p class="vanilla-image-block" style="padding-top:54.17%;"><img id="qCUbVy2Ac6u3H9fXxEdFCk" name="doom-dosbox-crash" alt="A screenshot of a more traditional DOOM crash in DOSBox." src="https://cdn.mos.cms.futurecdn.net/qCUbVy2Ac6u3H9fXxEdFCk.png" mos="" align="middle" fullscreen="1" width="648" height="351" attribution="" endorsement="" class="expandable"></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">Of course, there are many other ways to crash DOOM, such as loading an invalid level. </span><span class="credit" itemprop="copyrightHolder">(Image credit: GitHub/AXDOOMER)</span></figcaption></figure></a><p>At 35 ticks per second, it takes about 1.95 years to overflow the gametic value. That's a bit less than Minki's estimate, but who knows how long the ASUS PDA sat before they noticed the error message on screen; from the photo, it doesn't look like the 22-year-old pocket computer gets a lot of attention. It's also possible that Doom4CE, the Windows CE port of WinDoom that Minki was likely using, reduces the game tick rate to 30 Hz for better frame pacing and reduced hardware demands; this was common in the console ports of DOOM, such as the Jaguar and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/hack-snes-classic-add-games" target="_blank">Super NES versions</a>. If that's the case, it would take around 2.26 years to overflow the gametic value, closer to the stated 2.5.</p><p>Whatever the case, the takeaway is this: don't leave <em>DOOM</em> running for two years — or any game, probably, at least if it's a game client and not a dedicated server. Other thoughts provoked by Minki's experiment include both an appreciation for scientific rigor (experimental testing of even irrelevant conclusions) and the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/3d-printing/this-3d-printer-was-repurposed-as-a-robotic-camera-and-it-doubles-as-a-photogrammetry-rig-for-3d-scanning" target="_blank">clever re-use of "junk" hardware</a>. That appears to be a theme of the Len0w0 boards, so kudos to that gang for doing what nobody else bothered to do.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/video-games/pc-gaming/doom-left-running-on-asus-mypal-pda-for-2-5-years-finally-crashes-bug-that-crashes-the-game-when-gametic-value-hits-2-147-483-647-ticks-likely-to-blame
Gamers have put millions of hours into DOOM in the 32 years since its launch, but it's unlikely that many of them have left the game running for upwards of two years straight. At least one person did, though, and the result is... that it crashed.
x6y4rhXBfFAtmock42JjkE
Wed, 17 Sep 2025 16:23:25 +0000 PC Gaming
Video Games
Zak Killian
Zenimax/Id Software
The title screen of the classic video game DOOM.
The title screen of the classic video game DOOM.
<![CDATA[ China's largest chipmaker testing first homegrown immersion DUV litho tool — SMIC takes significant step on road to wafer fab equipment self-sufficiency ]]>
<p>SMIC, the largest foundry in China, is test-driving one of China's first domestic immersion DUV lithography tools, reports <a data-analytics-id="inline-link" href="https://www.ft.com/content/8fd79522-e34f-4633-bc87-ef0aae2d9159">Financial Times</a>. The system was developed by Shanghai Yuliangsheng Technology Co., which is linked to Huawei's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/chinas-sicarrier-challenges-u-s-and-eu-with-full-spectrum-of-chipmaking-equipment-huawei-linked-firm-makes-an-impressive-debut">SiCarrier</a>, and is believed to be a significant part of China's effort to become self-sufficient in wafer fab equipment.</p><p>SMIC's test platform from Yuliangsheng involves a DUV machine that uses immersion lithography and is reportedly designed for 28nm-class fabrication technologies, though it could be used for 7nm or even 5nm production nodes by applying multipatterning. The Yuliangsheng tool is mostly made from components sourced within China, although some parts are still imported. The company is actively working to localize the entire supply chain. Once that is achieved (though it is unclear when), it would allow China to operate outside the influence of the U.S. or European export policies in this segment of chip production.</p><p>If the description of the tool by <em>Financial Times</em> is accurate, then the Yuliangsheng immersion DUV system currently being tested by SMIC resembles ASML's <a data-analytics-id="inline-link" href="https://www.asml.com/en/news/press-releases/2008/asml-launches-the-twinscan-nxt1950i-immersion-lithography-system">Twinscan NXT:1950i</a> from 2008, which was designed for 32nm-class process technology in one exposure. The unit featured optics with 1.35 numerical aperture, a 2.5nm overlay, a 38nm resolution, and could be used for making chips on a 22nm-class fabrication node. While theoretically the NXT:1950i could be used to make chips on 7nm and 5nm-class nodes, ASML has developed NXT:2000i for such fabrication technologies, which is generations ahead of the NXT:1950i.</p><p>It is unclear whether the Yuliangsheng tool is being tested within SMIC's production flow (i.e., they are producing actual chips or patterns) or if the company is just beginning to test the scanner and has merely reached first light on the wafer or first patterning milestones (a more likely scenario). If it is the latter, then the scanner is years away from mass-producing actual chips. Indeed, the goal is reportedly to integrate domestic immersion DUV lithography machines into production lines starting in 2027, after their qualification. Before that, SMIC will continue to rely on tools from ASML.</p><p>It should be noted that while SMIC (and probably Yuliangsheng) believes that it is possible to build chips on 7nm and 5nm-class process technologies on the same tools that are used for 28nm-class production nodes, it remains to be seen whether this is possible without a dramatic improvement of a 28nm-class tool when it comes to overlay performance, precision, control, and complexity. Essentially, after the existing tool matures and gets inserted into SMIC's 28nm flow in 2027, it <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/china-injects-tens-of-billions-of-dollars-in-chipmaking-tools-but-its-easily-more-than-a-decade-behind-the-market-leaders-heres-why">will take Yuliangsheng years to jump to 16nm and then to 7nm fabrication nodes</a> with a significantly redesigned scanner, so do not expect SMIC's sub-10nm fabrication processes on domestic lithography systems earlier than in 2030.</p><p>The tool is codenamed 'Mount Everest,' after the world's tallest mountain, perhaps highlighting the importance of the project. Interestingly, but SiCarrier also tends to call its WFE projects after mountains, which perhaps proves that SiCarrier and Shanghai Yuliangsheng Technology Co. are not only affiliated (SiCarrier is reportedly an investor of Yuliangsheng), but likely belong to the same group working on the same goal. It is noteworthy that Shanghai Yuliangsheng Technology Co. is already known to the U.S. Department of Commerce, which put it into its <a data-analytics-id="inline-link" href="https://www.federalregister.gov/documents/2024/12/05/2024-28267/additions-and-modifications-to-the-entity-list-removals-from-the-validated-end-user-veu-program">Entity List in late 2024</a>.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/chinas-largest-foundry-testing-first-domestic-immersion-duv-lithography-tool-smic-takes-significant-step-on-road-to-wafer-fab-equipment-self-sufficiency
SMIC is testing a domestically built immersion DUV lithography system developed by Yuliangsheng and capable of 28nm-class process technology. But while it is said that the tool could be used to make 7nm or even 5nm-class chips with multipatterning, it remains to be seen whether this is going to happen any time soon.
3HazxWKQJrJJADHwtkLJG
Wed, 17 Sep 2025 14:11:15 +0000 Semiconductors
Tech Industry
Manufacturing
ashilov@gmail.com (Anton Shilov)
Anton Shilov
SMIC
SMIC
SMIC
<![CDATA[ Cooler Master debuts new 3D Heatpipe tech in new coolers — Hyper 212 3DHP promises reduced thermals and improved efficiency
]]>
<p>Cooler Master showed off its 3D Heatpipe technology back at Computex 2025, and now it's finally coming to the public just a few months later. This quick turnaround time can be attributed to perhaps the ingenious simplicity of this solution. Instead of having the heatpipes only go up against the edges of the heatsink fin stack, another one cuts through the center, allowing for more even heat dissipation — and now Cooler Master is bringing it to its legendary Hyper 212 lineup, as reported by <a data-analytics-id="inline-link" href="https://www.techpowerup.com/340696/cooler-master-intros-hyper-212-3dhp-cpu-cooler-with-3d-heat-pipe-technology" target="_blank">TechPowerUp</a>.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:800px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="dXUGmaPtsgULVTUFF8bpQE" name="inside-3dhp-p2-01-ezgif.com-video-to-gif-converter" alt="Cooler Master's 3D Heatpipe tech" src="https://cdn.mos.cms.futurecdn.net/dXUGmaPtsgULVTUFF8bpQE.gif" mos="" align="middle" fullscreen="" width="800" height="450" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Cooler Master)</span></figcaption></figure><p>If you've been in the PC community for even a smidge, the name Hyper 212 must ring a bell. Originally launched almost two decades ago, the Hyper 212 has gone through countless revisions, modernizing it for every generation of PC gaming. The latest in this line of iterations is the aforementioned 3D Heatpipe technology, dubbing the new cooler "Hyper 212 3DHP." To understand why this is special, we should first look at how (most) standard air coolers work. Generally, these tower coolers feature a dense heatsink with multiple fins stacked atop each other, through which a U-shaped heatpipe runs.</p><p>This pipe takes heat from the CPU's IHS and carries it across the finstack, where the mounted fans blow fresh air onto it to cool it down. This is a pretty decent thermal exchange, but it can be made better. Instead of just two heatpipes at the periphery of the fin stack, Cooler Master introduced a third one running through the middle, essentially forming a trident-like shape. This results in much more efficient distribution and dissipation of heat, since each pipe will not only be responsible for less heat now, but they will cover a larger area on the fin stack.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:741px;"><p class="vanilla-image-block" style="padding-top:74.09%;"><img id="TyDeStcnYhq7nX7HNbAdCU" name="RW6YnbvAXNkk1mHI" alt="Cooler Master's 3D Heatpipe tech" src="https://cdn.mos.cms.futurecdn.net/TyDeStcnYhq7nX7HNbAdCU.jpg" mos="" link="" align="" fullscreen="" width="741" height="549" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Cooler Master)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:871px;"><p class="vanilla-image-block" style="padding-top:62.23%;"><img id="Lkjor7X9aGycVsFeZHuwCU" name="GME5C0gyanRqHrFe" alt="Cooler Master's 3D Heatpipe tech" src="https://cdn.mos.cms.futurecdn.net/Lkjor7X9aGycVsFeZHuwCU.jpg" mos="" link="" align="" fullscreen="" width="871" height="542" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Cooler Master)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:756px;"><p class="vanilla-image-block" style="padding-top:55.56%;"><img id="uCTTzBVpRYmBLTAf8HXUv7" name="hp-3dhp-side-by-side" alt="Cooler Master's 3D Heatpipe tech" src="https://cdn.mos.cms.futurecdn.net/uCTTzBVpRYmBLTAf8HXUv7.png" mos="" link="" align="" fullscreen="" width="756" height="420" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Cooler Master)</span></figcaption></figure></div></div></div><p>It sounds simple (and it is), but it works, and that's why it's first appearing in the Hyper 212 series. Cooler Master is prepping two variants of the Hyper 212 3DHP: the standard one featuring ARGB fan(s) and the 3DHP Black, which, shocker, comes in black and with a non-LED-lit fan. Owing to the lineup's affordable nature, the Hyper 212 3DHP Black will cost just $29.99 — same as the standard non-3DHP model — and include a generous 5-year warranty, where Hyper 212s usually only get two.</p><p>The specs are otherwise identical between the ARGB and Black models; both come with two 3D Heatpipes, one on either side so totaling six ends at the top. While the company did not disclose weight, the dimensions are 133mm x 86mm x 158mm. The supplied fans will spin up to 2,050 RPM, moving 63.1 CFM of airflow with a static pressure of 2.69 mm. Noise is also kept under control with a max claimed output of just 27 dBA. The Hyper 212 3DHP is not available right away on Cooler Master's website, but it should start to show up soon at retailers.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em> Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/air-cooling/cooler-master-debuts-new-3d-heatpipe-tech-in-new-coolers-hyper-212-3dhp-promises-reduced-thermals-and-improved-efficiency
Cooler Master is updating its iconic lineup of Hyper 212 coolers with its proprietary 3D Heatpipe tech. Hyper 212 3DHP, therefore, has two trident-like heatpipes running through its finstack that dissipate heat more evenly while costing the same. They will come in two flavors: Black and ARGB, and will be backed with 5-year warranties.
KLbDDtbtNwcFAd2odhxixS
Wed, 17 Sep 2025 13:57:08 +0000 Air Cooling
PC Components
Cooling
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
Cooler Master / Future
Cooler Master Hyper 212 3DHP
Cooler Master Hyper 212 3DHP
<![CDATA[ $320 camera lens buyers hit with $2,000 delivery fee in tariffs fight — some sellers implement exorbitant shipping costs to dissuade US customers ]]>
<p>President Donald Trump ended the de minimis exemption for goods coming from China and Hong Kong in May 2025, with imports from the rest of the world following suit at the end of July 2025. This means that products entering the U.S. are now subject to customs duties and import taxes, even if their value is less than $800. This change most heavily affected online shoppers, especially those who are used to purchasing cheap goods from abroad. This has caused some retailers to take extreme 'countermeasures,' often to dissuade Americans from purchasing their products.</p><p>Some sellers, particularly on eBay, have resorted to charging exorbitant shipping fees to deter Americans from purchasing their items. <a data-analytics-id="inline-link" href="https://www.404media.co/2-000-shipping-international-sellers-charge-absurd-prices-to-avoid-dealing-with-american-tariffs/"><em>404 Media</em></a> reports seeing several listings of lightweight items from across the globe with high delivery costs.</p><p>For example, there’s a camera lens from Japan priced at around $320, which only costs $29 to ship globally — except for the U.S., which has a $2,000 delivery fee. Other sellers charge more than $500 to ship their items to the U.S., far more expensive than the actual price of the product. According to the report, this is much easier than taking down hundreds of listings and excluding the U.S. from them. There’s also the issue that some American buyers might not understand how tariffs work, and leave negative feedback on the seller, affecting their profile on the platform.</p><p>According to the <a data-analytics-id="inline-link" href="https://www.wsj.com/business/logistics/the-new-pitfall-of-online-shopping-a-surprise-tariff-bill-bc4f333f"><em>Wall Street Journal</em></a>, one customer bought a $77 shirt from a Swedish brand and was charged an extra $42.35 on top of the $30 shipping fee. Another person bought $640 worth of oven replacement parts from Canada and was surprised by a $1,196.12 “government charges” bill and a brokerage fee of $128.17. These tariffs and import taxes heavily affect tech goods, especially as many of them are manufactured outside of the U.S. <em>Tom’s Hardware </em>staff are also encountering a similar problem, though not to these extremes, even when dealing with review samples.</p><p>This change has caused widespread confusion in international shipping, with many post offices across the globe suspending e-commerce shipments until they’ve updated their systems to account for the new charges. The big shipping companies in the U.S. — FedEx, DHL, and UPS — reported that customers are confused by the new rules. And although they process tariff payments for imports, either by the buyer or the seller, the service is not free, resulting in additional brokerage or processing fees.</p><p>Some sellers pay the tariffs upfront to make the transaction smoother for their customers, while others leave all these extra costs to the recipient. Nevertheless, the person who bought the item will ultimately be the one responsible for import taxes. But even though couriers are trying to make the process as smooth as possible, the payment process can sometimes be confusing.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em>Tom's Hardware on Google News</em></u></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em>add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/usd320-camera-lens-buyers-hit-with-usd2-000-delivery-fee-in-tariffs-fight-some-sellers-implement-exorbitant-shipping-costs-to-dissuade-us-customers
Some sellers are resorting to ridiculous shipping fees to deter American customers from buying their items.
ZEZC2J5QMbzGyykdgajEWM
Wed, 17 Sep 2025 13:38:15 +0000 Tech Industry
editors@tomshardware.com (Jowi Morales)
Jowi Morales
Shutterstock
Shipping containers
Shipping containers
<![CDATA[ NAND and DRAM prices surge by up to 20% — contract price increases driven by AI demands and tight supply ]]>
<p>Contract prices for both NAND and DRAM have jumped by an estimated 15-20% in the fourth quarter of 2025, according to numbers published by <a data-analytics-id="inline-link" href="https://www.digitimes.com/news/a20250917PD211.html" target="_blank"><em>DigiTimes</em></a> on September 17, an off-season surge the publication ties directly to AI infrastructure build-outs and supply tightness.</p><p>“Supply shortages led to aggressive procurement from cloud service providers, with high-stack 3D NAND products nearly sold out,” writes <em>DigiTimes</em>, adding that, “3D NAND… has attracted strong priority purchasing interest from CSP customers,” citing demand for faster read speed and larger die capacities. This is a stark difference from the normal Q4 pattern, when component prices typically drift lower.</p><p>There are signs that the supply side is tightening. TrendForce says SanDisk pushed for a roughly 10% NAND hike in September, while Micron temporarily suspended DRAM and NAND price quotations to reassess allocations after customer forecasts pointed to shortages. The firm also flags a structural shortage in nearline HDDs that is forcing hyperscalers to accelerate plans for QLC SSD deployments in 2026.</p><p>DigiTimes goes further, saying <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/storage/bigger-and-cheaper-ssds-are-coming-thanks-to-samsung-chipmaker-starts-mass-producing-280-layer-qlc-9th-generation-v-nand">Samsung’s next-gen V9 NAND</a> for 2026 is “nearly sold out”, with cloud customers locking in capacity early due to its improved density and cost advantages. A separate TrendForce brief from this week, however, says Samsung has delayed V9 QLC to the first half of 2026, which suggests customers may be reserving capacity ahead of firm volume timing. Either way, it’s clear to see that cloud buyers are aggressively securing supply well into the future.</p><p>This could easily have a knock-on effect on consumer prices. If hyperscalers are absorbing more wafers for enterprise SSDs while DRAM makers prioritize server parts and HBM, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ram/ddr4-costs-soar-as-manufacturers-pull-the-plug">retail pricing</a> is going to lose some of its slack. TrendForce has already warned that legacy DRAM types remain under the most pressure as capacity is reallocated, and if cloud orders continue to rise, the familiar winter bargains on NVMe drives could be thinner than expected.</p><p>One tell that money is switching hands is controller specialist Phison’s record August figures. It reported a revenue of NT$5.934 billion, up 23% year over year. That’s a dramatic jump from last year’s weak base. The company has attributed the strength to non-consumer demand and closer tie-ups with NAND makers, which fits the broader theme of data-center-led flash tightness.</p><p>The bottom line is that multiple data points now converge on a common theme: AI is rewriting cloud storage hierarchy while HDD supply is constrained and flash makers have more pricing power than they usually do in the year’s final quarter. If you’re planning an upgrade, watch retail memory prices closely and move quickly when a good price pops up, because it probably won’t stick around for long.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><em> add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/nand-and-dram-prices-spike-in-q42025
Contract prices for both NAND and DRAM have jumped by an estimated 15-20% in the fourth quarter of 2025, according to numbers published by DigiTimes on September 17.
dufqRVzPk924sCrymrz9XE
Wed, 17 Sep 2025 12:31:45 +0000 Tech Industry
lukejamesalden@gmail.com (Luke James)
Luke James
Samsung
Samsung 9th Gen QLC V-NAND
Samsung 9th Gen QLC V-NAND
<![CDATA[ AMD launches Ryzen 9000 PRO series, flagship model tops out at 12 cores — new enterprise lineup includes 3 CPUs for OEMs featuring added business and security features ]]>
<p>AMD released a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-launches-four-new-ryzen-cpus-including-cutdown-zen-4-and-zen-3-models-most-only-available-in-global-markets" target="_blank">bunch of new Zen 3, Zen 4, and Zen 5 processors yesterday</a>, refreshing both existing and older families of CPUs. During this time, the company also silently launched its new enterprise lineup: <a data-analytics-id="inline-link" href="https://www.amd.com/en/products/processors/ryzen-for-professionals.html#tabs-9610e26165-item-17365abc16-tab" target="_blank">Ryzen PRO 9000</a>. These include three new SKUs built on the same Zen 5 "Granite Ridge" architecture as the mainline Ryzen 9000 series, but they feature cut-down silicon in favor of enterprise management and security features not present on standard CPUs.</p><p>First up, we have the Ryzen 5 Pro 9645. It comes with 6 cores and 12 threads, clocked at 3.9 GHz with boost speeds up to 5.4 GHz. Then there's the Ryzen 7 Pro 9745 with 8 cores and 16 threads, featuring the same 5.4 GHz boost clock but a slightly reduced 3.8 GHz base clock. The final model is the Ryzen 9 Pro 9945, which only has 12 cores and 24 threads, clocked at 3.4 GHz and boosting up to 5.4 GHz. Cache levels also remain unaltered in comparison to analogous Ryzen 9000 models.</p><div ><table><caption>Ryzen PRO 9000</caption><thead><tr><th class="firstcol " ><p>SKU</p></th><th
><p>Core Count</p></th><th
><p>Base Clock / Boost Clock</p></th><th
><p>Cache</p></th><th
><p>TDP</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>Ryzen 9 PRO 9945</p></td><td
><p>12C / 24T</p></td><td
><p>3.4 GHz / Up to 5.4 GHz</p></td><td
><p>76 MB</p></td><td
><p>65W</p></td></tr><tr><td class="firstcol " ><p>Ryzen 7 PRO 9745</p></td><td
><p>8C / 16T</p></td><td
><p>3.8 GHz / Up to 5.4 GHz</p></td><td
><p>40 MB</p></td><td
><p>65W</p></td></tr><tr><td class="firstcol " ><p>Ryzen 5 PRO 9645</p></td><td
><p>6C / 12T</p></td><td
><p>3.9 GHz / Up to 5.4 GHz</p></td><td
><p>38 MB</p></td><td
><p>65W</p></td></tr></tbody></table></div><p>All three SKUs share the same 65W TDP, despite the standard Ryzen 9 9900X — which the Pro 9945 would be based on — featuring a 120W TDP. But it makes sense given there are 4 fewer cores on the Pro 9945. There are consistent base and boost clock gains over the previous generation Ryzen PRO 7000 series, like a 300 MHz boost clock increase on the Ryzen 5 Pro SKUs. However, the Ryzen Pro 9945 loses 300 MHz in its base clock when compared to its predecessor (3.4 GHz vs 3.7 GHz).</p><p>Performance-wise, AMD shared some slides highlighting the improvements these Zen 5-based enterprise processors carry. Even though they're technically not focused on raw numbers, the Ryzen 9 Pro 9945 is reportedly up to 44% faster in Blender and up to 22% faster in other productivity benchmarks, when compared to Intel's Core i7-14700 processor. Moreover, surprisingly, these CPUs will also come with a bundled Wraith Stealth stock cooler</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2672px;"><p class="vanilla-image-block" style="padding-top:56.96%;"><img id="wpYN3Gs6Yo2qkJZ6p7v3in" name="Screenshot 2025-09-17 at 4.56.26 PM" alt="AMD Ryzen PRO 9000 performance" src="https://cdn.mos.cms.futurecdn.net/wpYN3Gs6Yo2qkJZ6p7v3in.png" mos="" align="middle" fullscreen="" width="2672" height="1522" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Future)</span></figcaption></figure><p>Pricing and availability are not clear because these CPUs are distributed to OEMs that supply them in bulk to enterprises around the world. Ryzen PRO is generally less mature than Intel's competing vPro technology, but both offer similar features with an overlapping goal in mind.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em> Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/cpus/amd-launches-ryzen-9000-pro-series-flagship-model-tops-out-at-12-cores-new-enterprise-lineup-includes-3-cpus-for-oems-featuring-added-business-and-security-features
AMD has just launched its latest series of Zen 5 processors aimed at enterprise. Featuring largely the same silicon as their mainstream counterparts, these Ryzen 9000 Pro models are set to become available with OEMs soon. They feature extensive security and management features that are crucial for the sector.
j3aAV7axbvVdzwccGATGn9
Wed, 17 Sep 2025 12:23:24 +0000 CPUs
PC Components
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
AMD
AMD Ryzen AI Pro
AMD Ryzen AI Pro
<![CDATA[ UK cosies up to big tech with $42 billion data center and AI investment deal ]]>
<p>A bevy of tech companies have announced over $40 billion in collective investment in the UK to coincide with the second state visit of President Trump. With announcements of cooperation from Nvidia, OpenAI, Google, Microsoft, and others, the UK is set to build new data centers, as well as AI and energy infrastructure, reports<a data-analytics-id="inline-link" href="https://www.reuters.com/world/uk/uk-us-agree-42-billion-tech-pact-mark-trumps-visit-2025-09-16/" target="_blank"> Reuters</a>. The British government hopes that having a lighter approach to AI legislation and planning will allow the country to attract further investment from technology companies that may be deterred by tighter regulations in the EU.</p><p>Since coming to power in spring 2024, the UK's Labour government has struggled to balance its progressive policies with a need to drive economic growth in the wake of years of stagnation within the country. Despite improving wages for public sector workers and driving investment into public services, the economy has failed to rally like the government hoped. Encouraging such large-scale investment from so many international companies is a potential way to dig the UK out of the economic hole it's found itself in.</p><p>British Prime Minister Keir Starmer hailed the news as both prosperous for the UK and the relationship between the United States and the UK.</p><p>"This Tech Prosperity Deal marks a generational step change in our relationship with the US, shaping the futures of millions of people on both sides of the Atlantic, and delivering growth, security and opportunity up and down the country," he said.</p><p>"By teaming-up with world-class companies from both the UK and US, we’re laying the foundations for a future where together we are world leaders in the technology of tomorrow, creating highly skilled jobs, putting more money in people’s pockets and ensuring this partnership benefits every corner of the United Kingdom."</p><p>Several deals have been announced from various companies, ranging from hundreds of millions of dollars of investment to several billions. <a data-analytics-id="inline-link" href="https://blog.google/around-the-globe/google-europe/united-kingdom/waltham-cross-data-centre/">Google opened a new data center in Waltham</a>, Lincolnshire, as part of a $6.8 billion investment package that will see it expand its London-based Google DeepMind research center for AI research in science and healthcare. These projects will support over 8,250 jobs and help Google enhance its Maps, Cloud, and search tools in the UK.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="oGqaWHG28MBTNkp9YXSDvF" name="googlewaltham" alt="Google Waltham Data Center shown on Google Maps in 3D." src="https://cdn.mos.cms.futurecdn.net/oGqaWHG28MBTNkp9YXSDvF.jpg" mos="" align="middle" fullscreen="" width="1600" height="900" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">Google's new Watlham-based data center will use a new deal between Google and Shell to expand Google's battery-based energy storage in the UK, too. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Google)</span></figcaption></figure><p>OpenAI <a data-analytics-id="inline-link" href="https://openai.com/index/introducing-stargate-uk/" target="_blank">announced Stargate UK</a> in partnership with Nvidia and UK-based Nscale. Together they're developing several new AI data centers beginning at the site of a former coal power station in Northumberland, north-east England. This is one of the UK's newly designated <a data-analytics-id="inline-link" href="https://www.gov.uk/government/news/north-east-england-set-for-billions-in-investment-and-thousands-of-jobs-as-uk-and-us-ink-tech-partnership" target="_blank">"AI Growth Zones,"</a> which are designed to ease the building of data centers and revitalize under-invested areas of the UK.</p><p>Backed by an additional $13.5 billion in investment from financial firm Blackstone, the area already has an established wind power presence, with further plans to develop solar energy and battery storage facilities to reduce the environmental impact of these new developments.</p><p>To power the new data centers, OpenAI and Nscale will be importing tens of thousands of graphics cards from Nvidia. OpenAI said that it would "offtake up to 8,000 GPUs in Q1 2026 with the potential to scale to 31,000 GPUs over time."</p><p>That's just the start, though. In <a data-analytics-id="inline-link" href="https://nvidianews.nvidia.com/news/nvidia-and-united-kingdom-build-nations-ai-infrastructure-and-ecosystem-to-fuel-innovation-economic-growth-and-jobs" target="_blank">its announcement, Nvidia</a> claimed it was in talks to provide up to 60,000 Grace Blackwell GPUs to the UK, as well as an additional 120,000 Blackwell GPUs for AI data centers in the UK. Over 20,000 of those will be invested in the new supercomputer Nscale is developing in Essex, with Microsoft now joining the project to provide additional investment.</p><p><a data-analytics-id="inline-link" href="https://www.bbc.co.uk/news/articles/c7016ljre03o" target="_blank">Microsoft's UK investment could well be the largest</a>. With over $30 billion promised over the next four years, Microsoft pledged at least half of that towards AI infrastructure, and the rest to expanding Microsoft's existing activities in the country, including gaming and Windows services.</p><p>There is also <a data-analytics-id="inline-link" href="https://www.gov.uk/government/news/us-uk-pact-will-boost-advances-in-drug-discovery-create-tens-of-thousands-of-jobs-and-transform-lives" target="_blank">a range of investments in the 10s to multiple hundreds of millions of dollars</a> from ARM, Coreweave, ScaleAI, DataVita, TechUK, Pathfinder, Salesforce, and Blackstone, among others. They're driving further investment into quantum computing, medicine, space exploration, digital security, and more.</p><p>As if in anticipation of concerns over power and water usage at the range of new data centers, the UK government also announced new UK and U.S. partnerships over the development of nuclear energy. Under the scheme, companies will be able to acquire licenses to build nuclear reactors faster in the UK. It will also facilitate greater research into the development of commercial fusion power.</p><h2 id="the-balancing-act-2">The balancing act</h2><p>From a purely economic perspective, it's hard to find fault in all these announcements. Any economy can benefit enormously from tens of billions of dollars of outside investment, and especially when that comes with closer ties to some of the world's most valuable companies, which are all spending big to ensure their own gravy trains keep on rolling.</p><p>But it's all a delicate balancing act for the UK government. While the news of AI investment is indeed positive for the country from an economic perspective, whether or not these investments turn into tangible, usable resources for the country and its AI efforts remains to be seen. Regardless of the outcome, this scale of planning is exactly what Nvidia CEO Jensen Huang wants: to build AI infrastructure across the globe.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/uk-cosies-up-to-big-tech-with-usd42-billion-data-center-and-ai-investment-deal
The UK government has secured tens of billions of dollars of investment from a range of major tech companies in a deal that comes at a time of particular political pressure in the UK and may well help drive the growth the UK so desperately needs.
P4jdwnTQgpiXEFxxQapvWa
Wed, 17 Sep 2025 12:23:08 +0000 Tech Industry
Jon Martindale
Getty Images/WPA Pool
UK Prime Minister Keir Starmer in front of the Union Jack.
UK Prime Minister Keir Starmer in front of the Union Jack.
<![CDATA[ Asus ProArt PA32QCV 6K professional monitor review: Plenty of pixels, color, and brightness ]]>
<p>When <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/4k-definition,37642.html">4K</a> monitors first appeared more than 10 years ago, my first thought was, “How long before we have 6K and 8K?” Surprisingly, 4K is still the highest resolution available in the mainstream, but there are a few monitors out there featuring panels with higher resolution and pixel density. I looked at a 5K Asus ProArt screen last year, the PA27JCV. It has 218ppi density (5120x2880) and an impressive feature set worthy of creatives’ attention for around $800.</p><p>The Asus ProArt line now includes a 6K monitor, the PA32QCV. It has the same 218ppi from a 32-inch panel with 6016x3384 resolution, 600 nits peak brightness for SDR and HDR, an IPS panel with over 1,600:1 native contrast, wide gamut color, and plenty of color modes for any industry standard you might need for video, gaming, or photo production. Let’s take a look.</p><h2 id="asus-proart-pa32qcv-specs-2">Asus ProArt PA32QCV Specs</h2><div ><table><tbody><tr><td class="firstcol " ><p>Panel Type / Backlight</p></td><td
><p>IPS / W-LED, edge array</p></td></tr><tr><td class="firstcol " ><p>Screen Size / Aspect Ratio</p></td><td
><p>32 inches / 16:9</p></td></tr><tr><td class="firstcol " ><p>Max Resolution and Refresh Rate</p></td><td
><p>6016x3384 @ 60 Hz</p></td></tr><tr><td class="firstcol empty" ></td><td
><p>FreeSync and G-Sync compatible</p></td></tr><tr><td class="firstcol " ><p>Native Color Depth and Gamut</p></td><td
><p>10-bit / DCI-P3</p></td></tr><tr><td class="firstcol " ><p>Response Time (GTG)</p></td><td
><p>5ms</p></td></tr><tr><td class="firstcol " ><p>Brightness (mfr)</p></td><td
><p>600 nits</p></td></tr><tr><td class="firstcol " ><p>Contrast (mfr)</p></td><td
><p>1,500:1</p></td></tr><tr><td class="firstcol " ><p>Speakers</p></td><td
><p>2x 2w</p></td></tr><tr><td class="firstcol " ><p>Video Inputs</p></td><td
><p>1x DisplayPort 1.4 w/DSC</p></td></tr><tr><td class="firstcol empty" ></td><td
><p>1x HDMI 2.1, 2x Thunderbolt 4.0</p></td></tr><tr><td class="firstcol " ><p>Audio</p></td><td
><p>3.5mm headphone output</p></td></tr><tr><td class="firstcol " ><p>USB 3.2</p></td><td
><p>1x up, 3x down</p></td></tr><tr><td class="firstcol " ><p>Power Consumption</p></td><td
><p>41.4w, brightness @ 200 nits</p></td></tr><tr><td class="firstcol " ><p>Panel Dimensions</p><p> WxHxD w/base</p></td><td
><p>28.1 x 19-24.2 x 9.5 inches</p><p> (714 x 483-615 x 241mm)</p></td></tr><tr><td class="firstcol " ><p>Panel Thickness</p></td><td
><p>1.8 inches (46mm)</p></td></tr><tr><td class="firstcol " ><p>Bezel Width</p></td><td
><p>Top/sides: 0.28 inch (7mm)</p><p> </p></td></tr><tr><td class="firstcol empty" ></td><td
><p>Bottom: 0.67 inch (17mm)</p></td></tr><tr><td class="firstcol " ><p>Weight</p></td><td
><p>20.5 pounds (9.3kg)</p></td></tr><tr><td class="firstcol " ><p>Warranty</p></td><td
><p>3 years</p></td></tr></tbody></table></div><p>Despite its cutting-edge specs, the PA32QCV keeps things simple, meaning the price isn’t too high; $1,299 at this writing. The main missing feature is a whole array Mini LED with local dimming. Edge lighting is the tech used here, but there’s no shortage of brightness. The HDR rating is VESA DisplayHDR 600, and you get the same peaks for SDR. I measured almost 650 nits in my tests, and that was from both full field and window patterns. There is dynamic dimming with a few options to tailor the speed and ratio.</p><p>Though the PA32QCV can be used for gaming, it is limited to 60 Hz (however, there is Adaptive-Sync and overdrive). You also get HDR10 but not Dolby Vision. HDR modes include multiple luminance curves and OSD calibration controls.</p><p>The big draw is a group of precise color modes. Rather than calling them things like Racing or FPS, they are termed by their color standard. You get everything currently in standard use from sRGB to BT.2020. The native color gamut tops out at around 100% of DCI-P3. Each mode is factory calibrated, and you can tweak them further using the OSD or Asus’ DisplayWidget Center. You can also do an auto calibration using Portrait Displays’ Calman software and a meter of your choice.</p><p>In addition to the tremendous pixel density, the PA32QCV employs other features to improve image quality. One element that LCDs struggle with is the anti-glare layer. This often reduces clarity and perceived color saturation, so Asus has included a technology called LuxPixel, which gives you the benefits of an optically clean screen that also rejects ambient light. It works as advertised and has the further advantage of completely hiding any visible pixel structure.</p><p>There are numerous convenience features, including KVM, USB ports, two Thunderbolt inputs, and an ambient light sensor that can be engaged to control brightness during changes in the viewing environment. The stand is super solid and fully adjustable for tilt, height, swivel, and rotation. Asus has demonstrated many times that pro monitors don’t have to cost $5,000. The PA32QCV is a perfect example of this philosophy, with a reasonable price tag and very high performance.</p><h2 id="assembly-and-accessories-2">Assembly and Accessories</h2><p>The PA32QCV’s stand, base, and panel ship in fully recyclable packaging that uses molded cardboard pulp to protect the contents. The parts assemble without tools into a quality piece that feels premium in every way. The cable bundle includes IEC power, HDMI, and Thunderbolt/USB-C. You also get a small microfiber cleaning cloth.</p><h2 id="product-360-2">Product 360</h2><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:94.20%;"><img id="93KHvApYZoxdTa6aPsP6Qd" name="a-front" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/93KHvApYZoxdTa6aPsP6Qd.jpg" mos="" link="" align="" fullscreen="" width="1000" height="942" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Asus)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:93.00%;"><img id="ehjYxLgQq5gPQyAqWhh7Qd" name="a-angle" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/ehjYxLgQq5gPQyAqWhh7Qd.jpg" mos="" link="" align="" fullscreen="" width="1000" height="930" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Asus)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:100.00%;"><img id="vJmkwivfiVnAo52aJcbjMd" name="a-back" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/vJmkwivfiVnAo52aJcbjMd.jpg" mos="" link="" align="" fullscreen="" width="1000" height="1000" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Asus)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:52.60%;"><img id="bqzsNeRbDP8qVLSfsi2TNd" name="a-inputs" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/bqzsNeRbDP8qVLSfsi2TNd.jpg" mos="" link="" align="" fullscreen="" width="1000" height="526" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Asus)</span></figcaption></figure></div></div></div><p>The PA32QCV maintains Asus’ ProArt styling with equal measures of form and function. The front is all screen, with a super-thin, flush bezel around the top and sides, measuring just 7mm, and a 17mm strip at the bottom. It’s just large enough to accommodate a row of control keys plus a tiny joystick and a small power LED. The screen’s LuxPixel tech is evidenced by a complete lack of reflections from ambient light and a crisply saturated image with no visible pixel structure.</p><p>The stand is a pole-shaped upright with a cable hole in the middle. It attaches to a large base plate for a wobble-free package. Ergonomics include 5.2 inches of height, 5/23 degrees tilt, 30 degrees swivel, and a 90-degree portrait mode. The panel is a bit thinner than other 32-inch monitors I’ve encountered at just 1.8 inches deep. It features a 100mm VESA pattern on the back for aftermarket mounts, with fasteners included. Asus also makes a desk clamp available that interfaces with the upright.</p><p>Inputs are plentiful and include one each of DisplayPort 1.4 and HDMI 2.1. Two Thunderbolt 4.0 ports provide 96 watts of power and allow two PA32QCVs to be daisy-chained. USB is supported by two Type-C and two Type-A ports along with a KVM setup in the OSD. A pair of integrated speakers plays high frequencies politely with two watts of power.</p><h2 id="osd-features-2">OSD Features</h2><p>The PA32QCV’s OSD is extensive but logically laid out. It will be familiar to Asus ProArt users and is based on industry-standard color modes. It also includes calibration controls, HDR options, KVM, Asus QuickFit, and a host of other convenience features.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.60%;"><img id="EDGuTajC8KaiChEpnZvcXA" name="osd1" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/EDGuTajC8KaiChEpnZvcXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="616" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.60%;"><img id="xiKCqSJrUeAWzX8TA7yDXA" name="osd2" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/xiKCqSJrUeAWzX8TA7yDXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="616" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.80%;"><img id="GmJHNMgjTsK4Q3JNmErfWA" name="osd3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/GmJHNMgjTsK4Q3JNmErfWA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="618" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.70%;"><img id="LDFE4gDst3HAAawRCzhAXA" name="osd4" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/LDFE4gDst3HAAawRCzhAXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="617" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 5 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.30%;"><img id="hR5k5NGdJVqdBRLkL4gLXA" name="osd5" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/hR5k5NGdJVqdBRLkL4gLXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="613" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 6 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.20%;"><img id="kHDhfxTTLDnZSTJuZkdSXA" name="osd6" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/kHDhfxTTLDnZSTJuZkdSXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="612" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 7 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.10%;"><img id="3KT6eZYJ5yrTqYCKdvKwWA" name="osd7" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/3KT6eZYJ5yrTqYCKdvKwWA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="611" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 8 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.20%;"><img id="kBmZe3ecRzPeRNyTVvUQXA" name="osd8" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/kBmZe3ecRzPeRNyTVvUQXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="612" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 9 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.50%;"><img id="YYBFCRbLNuwXkvqQ4THSXA" name="osd9" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/YYBFCRbLNuwXkvqQ4THSXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="615" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 10 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:60.60%;"><img id="ozYRSghtB8wovqdwYebWXA" name="osd10" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/ozYRSghtB8wovqdwYebWXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="606" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 11 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:61.20%;"><img id="NtA5wTVmxG5rQHtMHQc3XA" name="osd11" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/NtA5wTVmxG5rQHtMHQc3XA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="612" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 12 of 12</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:59.40%;"><img id="aQ2wFsqkbPCW8VRd33XUXA" name="osd13" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/aQ2wFsqkbPCW8VRd33XUXA.jpg" mos="" link="" align="" fullscreen="" width="1000" height="594" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The OSD begins with the color modes, and there are seven for SDR and three for HDR, plus two user memories. Native is the default, and it is equivalent to Display P3 with around 100% coverage of that gamut, D65 white point and 2.2. gamma. P3 includes Display P3, Cinema P3, and M-Model, which correspond to macOS standards. You also get DICOM for medical imaging equipment. HDR10 signals get a choice of three different luminance (EOTF) curves. PQ Optimized is the default and best option there.</p><p>To calibrate, you can choose from fixed color temps by Kelvin value. Gamma comes with five presets from 1.8 to 2.6 in 0.2 increments. RGB tuning is a precise two-point grayscale control that can alter any of the existing picture modes except sRGB. Black level affects how low the backlight goes when dynamic dimming is engaged. Deep means it will turn off when there is no signal.</p><p>In the Image menu are sharpness and trace-free options. The latter is Asus’ term for overdrive, and it works best on its default setting of 60. In practice, there’s only so much that can be done at 60fps. You can reduce motion blur, but it won’t be eliminated. Looking for Adaptive-Sync? I’m getting to it, keep reading.</p><p>The PA32QCV includes plenty of PIP and PBP options for viewing two or three video inputs at once. Each window can have separate color settings and be sized. QuickFit is a staple on all ProArt monitors, and it is super handy for document creation and video production. You can put markers and framing limits on the screen to help with composition during live shoots or when cropping in postproduction.</p><p>Dynamic Dimming is a field dimming feature that doubles contrast for SDR content and takes HDR’s range from 1,600:1 to almost 10,000:1. Remember that the PA32QCV has Adaptive-Sync? It’s in the Settings menu under the heading MediaSync. Confusing, yes. Not only is it apart from other video processing options, but it’s also called a term only used by Asus. But now that you’ve read this, you know, and can tell your friends.</p><p>KVM gets its own sub-menu and it’s very easy to set up bindings between USB ports and video inputs. That way, you can control multiple systems with a single set of input devices. The two shortcut menus refer to two of the control keys on the front bezel. They give quick access to a variety of different functions.</p><h2 id="asus-proart-pa32qcv-calibration-settings-2">Asus ProArt PA32QCV Calibration Settings</h2><p>Typically, ProArt monitors don’t need calibration out of the box. Just pick your desired color mode and go. My sample was a bit off the mark for grayscale though, with slight green errors. I suspect this is because I received an early production sample. Color and gamma were spot-on in every mode. To verify the monitor’s operation, I calibrated the Native mode with excellent results. My settings are below, though I suspect you won’t need them. The PA32QCV can be easily calibrated in any of its modes with Calman’s autocal feature using a meter of your choice or with the one Asus makes available that works with all ProArt monitors.</p><p>In HDR mode, there are three luminance curves, called PQ (Perceptual Quantization). Optimized is the default and best option there.</p><div ><table><tbody><tr><td class="firstcol " ><p>Picture Mode</p></td><td
><p>Native</p></td></tr><tr><td class="firstcol " ><p>Brightness 200 nits</p></td><td
><p>86</p></td></tr><tr><td class="firstcol " ><p>Brightness 120 nits</p></td><td
><p>50</p></td></tr><tr><td class="firstcol " ><p>Brightness 100 nits</p></td><td
><p>41</p></td></tr><tr><td class="firstcol " ><p>Brightness 80 nits</p></td><td
><p>32</p></td></tr><tr><td class="firstcol " ><p>Brightness 50 nits</p></td><td
><p>19 (min. 10 nits)</p></td></tr><tr><td class="firstcol " ><p>Contrast</p></td><td
><p>80</p></td></tr><tr><td class="firstcol " ><p>Gamma</p></td><td
><p>2.2</p></td></tr><tr><td class="firstcol " ><p>Color Temp User</p></td><td
><p>Gain – Red 219, Green 194, Blue 205</p></td></tr><tr><td class="firstcol empty" ></td><td
><p>Bias – Red 200, Green 200, Blue 200</p></td></tr></tbody></table></div><h2 id="setup-and-hands-on-2">Setup and Hands-on</h2><p>Calibrating the PA32QCV initially is unnecessary unless you want to create a custom setup that falls outside industry standards for grayscale, gamma and color gamut. You only need to select your desired mode, and it will deliver that spec with extreme accuracy. That said, I found my sample had slightly less precise grayscale tracking than other ProArt displays I’ve reviewed. Errors averaged around 3dE, which tells me I likely received a pre-production sample. Other ProArt displays I’ve reviewed were around 1dE for grayscale. Gamma and color gamut results were nearly perfect in all color modes except for BT.2020, which the monitor isn’t actually capable of. Its max color volume is around 100% of P3. I summarize all the results in the test notes on the next three pages.</p><p>The sRGB mode is brightness limited to 80 nits so as an alternative, you can pick Rec.709, which lets you select from four color temps and five gamma values. P3 offers three options. The cinema version with a D63 color temp and 2.6 gamma, Display P3 with D65 and 2.2, and M-Model, which matches the standard used by macOS. This is a new addition to the ProArt toolkit. Alternatively, you can use Native, which corresponds to Display P3 with a D65 color point and 2.2 gamma. Adobe RGB is there for photographers, along with BT.2020 mode, which has selectable gamma and color temp.</p><p>The HDR10 mode has three possible PQ curves. I found PQ Optimized to be the most accurate in testing, but you may wish to change it for the sake of the content you’re creating. You can choose DCI-P3 or Rec.2020 color and adjust the color temp with a single set of RGB sliders.</p><p>In use, the PA32QCV is incredibly competent and flexible. For those who enjoy a colorful picture, the default Native mode is fine for everyday tasks like writing or web browsing. When photo editing tops the to-do list, just pick the necessary standard from the presets. If you need a different gamma or color temp, say Rec.709 with a sepia tone for that vintage Hollywood look, just pick one of the fixed Kelvin values. You can do the same thing with gamma in all modes except sRGB.</p><p>For a totally DIY standard, there are two settings memories labeled User that can be used for any combination you like. The only limitation here is in the BT.2020 mode where coverage tops out at around 74%. The PA32QCV is not a Quantum Dot display, so it stops at DCI-P3, which it covers just under 100% of.</p><p>The only thing I recommend avoiding here is full motion gaming. The PA32QCV maxes at 60 Hz and though there is overdrive (TraceFree) available, I am far too spoiled by fast refresh screens to even consider gaming at 60fps. Motion blur is significant. And if you use Adaptive-Sync, TraceFree is off the table. Static games like Myst look great thanks to that insanely high pixel density. So, if lush graphics are your thing, there is no Ultra HD monitor that will deliver the smooth rendering of the PA32QCV.</p><p>I was also impressed by the panel’s high contrast. You won’t mistake it for an OLED, but it has greater dynamic range than other IPS panels, 1,600:1 in fact. If you engage the dimming option, it jumps to over 3,000:1 for SDR and almost 10,000:1 for HDR. Black levels are very good, and highlights are even better with peaks near 650 nits.</p><p><strong>Takeaway:</strong> As long as you keep moving content to a fixed frame rate, as you would when editing video, the PA32QCV is a great-looking monitor. It’s bright and colorful for sure and delivers better blacks than typical IPS panels. For content creation, it represents supreme flexibility with near-perfect accuracy in every color mode. No tweaking is required in any of the presets. Even if you just want a nice monitor for everyday use, it isn’t super expensive and it just works.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p><p>Comparing the PA32QCV to speedy gaming monitors isn’t fair, so for this review, I’ll be sharing test results and commenting on them relative to the expectations of a reference-level professional display.</p><h2 id="pixel-response-and-input-lag-2">Pixel Response and Input Lag</h2><p><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/4"><strong>Click here</strong></a><strong> to read up on our pixel response and input lag testing procedures.</strong></p><ul><li><strong>Response Time </strong>Full black to white transition – 16ms</li><li><strong>Absolute Input Lag </strong>Full black to white transition – 56ms</li></ul><p>The PA32QCV is not meant to be a gaming monitor, but it does include Adaptive-Sync, which improves motion processing. It’s unfortunate that you can’t use overdrive and AS at the same time though. With only 60 Hz available, you won’t want to engage in anything too frenetic. Exploring game environments is an amazing experience, but shooters will look quite blurry if you’re used to speedy screens like I am.</p><p><strong>Test Takeaway: </strong>The PA32QCV’s video processing isn’t game-focused, but since it’s marketed as a content creation tool, it should have a faster refresh rate and a good overdrive that can be used with Adaptive-Sync. That would allow creators to evaluate their game titles on a single display.</p><h2 id="viewing-angles-2">Viewing Angles</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:66.20%;"><img id="AT5QdK8ArChuU7tJKhAuVA" name="PA32QCV viewing" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/AT5QdK8ArChuU7tJKhAuVA.jpg" mos="" align="middle" fullscreen="" width="1000" height="662" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>I did a double-take when I took the above photos. You’d think you’re looking at an OLED here, not an LCD. Asus’s LuxPixel technology obviously works, and I won’t be surprised to see it appear on other brands’ displays in the future. The side view has no change in color, brightness or gamma. Like, none. This is phenomenal performance. The top view is more typical of IPS screens with reduced brightness and red tint. But a serious step forward has been made by the PA32QCV and Asus.</p><h2 id="screen-uniformity-2">Screen Uniformity</h2><p><strong>To learn how we measure screen uniformity,</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/4"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/4"><strong>click here.</strong></a></p><ul><li><strong>Screen Uniformity Deviation From Center </strong>0% Black Field – 9.44%</li></ul><p>The PA32QCV doesn’t have uniformity compensation like some professional screens, but given the above result, I have no complaints. This is typical IPS monitor performance.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p><p><strong>To read about our monitor tests in-depth, please check out</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>Display Testing Explained: How We Test PC Monitors.</strong></a> <strong>We cover brightness and contrast testing on</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/2"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/2"><strong>page two.</strong></a></p><h2 id="maximum-backlight-level-2">Maximum Backlight Level</h2><ul><li><strong>Maximum White Luminance </strong>Native Mode – 648.9998 nits</li><li><strong>Maximum Black Luminance </strong>Native Mode – 0.4111 nit</li><li><strong>Maximum Contrast Ratio </strong>Native Mode – 1,578.7:1</li></ul><p>The PA32QCV is very bright whether dynamic dimming is engaged or not. I measured the same peaks from full field and 25% window patterns. Dimming only affects the black level, and if you use it, the contrast ratio rises to around 3,000:1. The brightness slider is very precise with 400 clicks of resolution. You can turn it down all the way to 10 nits if you like. I noted that the peak changed depending on picture mode. The above result was from Native.</p><h2 id="after-calibration-to-200-nits-2">After Calibration to 200 nits</h2><p>Since my PA32QCV sample showed slight green errors in the grayscale tests, I calibrated the Native mode using the RGB sliders with the peak value set to 200 nits.</p><ul><li><strong>Calibrated Contrast Ratio (200 nits) </strong>– 1,602.6:1</li><li><strong>16-point ANSI Contrast Ratio</strong> – 1,553.7:1</li></ul><p>The PA32QCV demonstrated consistent performance in all modes. Though the peak values changed, the contrast ratio was always around 1,600:1. This is as it should be for a professional display. ANSI contrast also remained solid. The PA32QCV has greater native dynamic range than typical IPS monitors with excellent black levels thanks to the dynamic dimming option.</p><p><strong>Test Takeaway: </strong>The PA32QCV delivers more depth and contrast than typical IPS LCD monitors. You can get better performance from an OLED or Mini LED, but at a higher price. 1,600:1 is enough range to render solid blacks and saturated color. And there is more than enough light output to use it outdoors in a production setting.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p><p>To verify the PA27JCV’s factory calibration, I measured the modes that will be most commonly used, P3 (cinema and display), sRGB, Adobe RGB, BT.709, and BT.2020. At the end of this page, there’s a summary of all the test results for each mode.</p><h2 id="grayscale-and-gamma-tracking-2">Grayscale and Gamma Tracking</h2><p><strong>Our grayscale and gamma tests use Calman calibration software from</strong><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong>Portrait Displays</strong></a><strong>. We describe our grayscale and gamma tests in detail</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/3"><strong> here.</strong></a></p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="vwX4rTtCfaBhXvkNokL5MP" name="PA32QCV gray sRGB" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/vwX4rTtCfaBhXvkNokL5MP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="URGqkCrjTdJPRZ4arq25MP" name="PA32QCV gray Adobe" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/URGqkCrjTdJPRZ4arq25MP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="UN75RYhZQoc9bEBJssvyLP" name="PA32QCV gray 2020" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/UN75RYhZQoc9bEBJssvyLP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="AyVtV5M2XrDpRmkKxQT6MP" name="PA32QCV gray P3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/AyVtV5M2XrDpRmkKxQT6MP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 5 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="ZX6HysxA9JwdCyuWQNzNMP" name="PA32QCV gray Cinema P3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/ZX6HysxA9JwdCyuWQNzNMP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 6 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="RXmEaKrPYF7Kyjq9bzvyLP" name="PA32QCV gray 709" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/RXmEaKrPYF7Kyjq9bzvyLP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 7 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:605px;"><p class="vanilla-image-block" style="padding-top:107.77%;"><img id="NYoah65pauWUnnKrsFN5MP" name="PA32QCV gray native post" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/NYoah65pauWUnnKrsFN5MP.jpg" mos="" link="" align="" fullscreen="" width="605" height="652" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div></div></div><p>All the average error values are around 3dE, which tells me this PA32QCV is an early or pre-production sample. Other ProArt monitors I’ve reviewed are closer to 1dE. The green errors seen in the charts above can be adjusted away using the OSD. To confirm this, I calibrated the Native mode, represented by the last chart and its invisible error of 1.30dE. The only exception to this is sRGB mode, which is fixed at 80 nits with all color controls grayed out.</p><p>Gamma tracks perfectly in every case and uses the correct value for each mode. BT.709 and BT.2020 use the power function at 2.4. sRGB, Adobe RGB, and Display P3 use the power function at 2.2. Cinema P3 uses the power function at 2.6. I calibrated Native also using the power function at 2.2</p><h2 id="color-gamut-accuracy-2">Color Gamut Accuracy</h2><p><strong>Our color gamut and volume testing use</strong><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong>Portrait Displays’</strong></a><strong> Calman software. For details on our color gamut testing and volume calculations,</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/3"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/3"><strong>click here.</strong></a></p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="zrmHB7ctAoqfopH4cfNKva" name="PA32QCV color sRGB" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/zrmHB7ctAoqfopH4cfNKva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="FBR8Pq96VLvxmW352xDMva" name="PA32QCV color Adobe" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/FBR8Pq96VLvxmW352xDMva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="bUX7DjSXMX9M6JwrQQKWva" name="PA32QCV color 2020" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/bUX7DjSXMX9M6JwrQQKWva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="83HxsvXGVTjZ5fhxc7YHva" name="PA32QCV color P3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/83HxsvXGVTjZ5fhxc7YHva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 5 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="8QGtctqM9LsXeLMgZnfDva" name="PA32QCV color Cinema P3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/8QGtctqM9LsXeLMgZnfDva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 6 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="7qU56PbAEhzyHQJ5CP4Dva" name="PA32QCV color 709" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/7qU56PbAEhzyHQJ5CP4Dva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 7 of 7</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:490px;"><p class="vanilla-image-block" style="padding-top:104.08%;"><img id="byx84F6a66giTaCgqpiHva" name="PA32QCV color native post" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/byx84F6a66giTaCgqpiHva.jpg" mos="" link="" align="" fullscreen="" width="490" height="510" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div></div></div><p>The color charts all show precision with average errors under 2dE in all cases except BT.2020, which rendered 2.66. This is solely due to the lack of gamut volume, as the PA32QCV is a P3 monitor with no Quantum Dot tech. However, inner targets are on point. The only issue that can be seen in any chart is the slightly green white point that I spoke of earlier.</p><h2 id="grayscale-gamma-and-color-gamut-test-summary-2">Grayscale, Gamma and Color Gamut Test Summary</h2><p>Here are the grayscale, gamma and gamut results in a summary table. Error values are referenced to the Delta E 2000 spec. Gamma range refers to the difference between the highest and lowest value. Gamma Average is the percentage deviation from the standard for each color mode.</p><div ><table><tbody><tr><td class="firstcol empty" ></td><td
><p><strong>Grayscale Error</strong></p></td><td
><p><strong>Gamma Range</strong></p></td><td
><p><strong>Gamma Average</strong></p></td><td
><p><strong>Gamma Actual</strong></p></td><td
><p><strong>Gamut Error</strong></p></td><td
><p><strong>Gamut Volume</strong></p></td></tr><tr><td class="firstcol " ><p><strong>sRGB</strong></p></td><td
><p>2.86dE</p></td><td
><p>0.05</p></td><td
><p>0.91%</p></td><td
><p>2.22</p></td><td
><p>1.41</p></td><td
><p>99.38%</p></td></tr><tr><td class="firstcol " ><p><strong>Adobe RGB</strong></p></td><td
><p>3.40dE</p></td><td
><p>0.06</p></td><td
><p>0.91%</p></td><td
><p>2.22</p></td><td
><p>1.88</p></td><td
><p>88.22%</p></td></tr><tr><td class="firstcol " ><p><strong>BT.2020</strong></p></td><td
><p>3.17dE</p></td><td
><p>0.06</p></td><td
><p>0.42%</p></td><td
><p>2.41</p></td><td
><p>2.66</p></td><td
><p>72.72%</p></td></tr><tr><td class="firstcol " ><p><strong>Display P3</strong></p></td><td
><p>3.66dE</p></td><td
><p>0.05</p></td><td
><p>0.45%</p></td><td
><p>2.21</p></td><td
><p>1.56</p></td><td
><p>99.58%</p></td></tr><tr><td class="firstcol " ><p><strong>Cinema P3</strong></p></td><td
><p>3.42dE</p></td><td
><p>0.06</p></td><td
><p>0.38%</p></td><td
><p>2.59</p></td><td
><p>1.52</p></td><td
><p>99.48%</p></td></tr><tr><td class="firstcol " ><p><strong>BT.709</strong></p></td><td
><p>3.47dE</p></td><td
><p>0.06</p></td><td
><p>0.00%</p></td><td
><p>2.40</p></td><td
><p>1.53</p></td><td
><p>99.53%</p></td></tr><tr><td class="firstcol " ><p><strong>Native calibrated</strong></p></td><td
><p>1.30dE</p></td><td
><p>0.06</p></td><td
><p>0.45%</p></td><td
><p>2.21</p></td><td
><p>0.77</p></td><td
><p>99.70% </p></td></tr></tbody></table></div><p><strong>Test Takeaway: </strong>The PA32QCV has superb gamut and gamma accuracy with a few slight grayscale tracking issues seen in my review sample. Given the performance I’ve seen from other ProArt monitors, I conclude that this is an anomaly. At any rate, one can correct any errors easily using the available calibration methods.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p><p><strong>Our HDR benchmarking uses</strong><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong> </strong></a><a data-analytics-id="inline-link" href="https://www.portrait.com/"><strong>Portrait Displays’</strong></a><strong> Calman software. To learn about our HDR testing, see our breakdown of</strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking/5"><strong> how we test PC monitors.</strong></a></p><p>The PA32QCV supports HDR10 signals by switching automatically. There are three PQ options available, each with a slightly different luminance curve.</p><h2 id="hdr-brightness-and-contrast-2">HDR Brightness and Contrast</h2><ul><li><strong>HDR White Luminance</strong> – 644.9141 nits</li><li><strong>HDR Black Level</strong> – 0.0660 nit</li><li><strong>HDR Sequential Contrast</strong> – 9,771.3:1</li></ul><p>To find the highest possible contrast ratio, I turned on the dynamic dimming option with its default parameters. At nearly 10,000:1, the PA32QCV delivers superb HDR image quality. Black levels are deep with clear detail, which highlights pop with texture. The best option is PQ Optimized, which, as you’ll see below, delivers the correct luminance tracking.</p><h2 id="grayscale-eotf-and-color-2">Grayscale, EOTF and Color</h2><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:750px;"><p class="vanilla-image-block" style="padding-top:63.47%;"><img id="vohsufRCKgN8TgYSQRCsLP" name="PA32QCV HDR Gray EOTF" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/vohsufRCKgN8TgYSQRCsLP.jpg" mos="" link="" align="" fullscreen="" width="750" height="476" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:500px;"><p class="vanilla-image-block" style="padding-top:86.00%;"><img id="5WWkU3NYkatYBcN8e67Pva" name="PA32QCV HDR P3" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/5WWkU3NYkatYBcN8e67Pva.jpg" mos="" link="" align="" fullscreen="" width="500" height="430" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:500px;"><p class="vanilla-image-block" style="padding-top:86.00%;"><img id="yHqvzpepPnpDnK7THNMHva" name="PA32QCV HDR 2020" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/yHqvzpepPnpDnK7THNMHva.jpg" mos="" link="" align="" fullscreen="" width="500" height="430" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Portrait Displays Calman)</span></figcaption></figure></div></div></div><p>The grayscale result has no issues to report aside from a touch too much blue around 60 and 65% brightness. The luminance curve starts a tad light but meets the reference line by 10% and correctly transitions to tone-mapping at the 70% step.</p><p>The DCI-P3 color result shows some undersaturation, which is also likely to be a sample-specific issue. The PA32QCV is fully capable of rendering all of this gamut as the SDR tests showed. In practice, HDR color looks a bit muted though there is no shortage of brightness. The BT.2020 test shows the same behavior with general undersaturation until color runs out at 82% red, 65% green and 95% blue.</p><p><strong>Test Takeaway: </strong>The PA32QCV has more HDR brightness and contrast than typical IPS monitors with edge backlighting. Dynamic dimming is very effective and takes the ratio up to nearly 10,000:1 without penalty. HDR grayscale and EOTF tracking is on point but color in my sample was slightly muted.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p><p>There is no escaping the fact that higher pixel density means a sharper and smoother image. When you paint a picture with dots, you can’t have too many. 4K has been, and still is the gold standard up to the 32-inch panel size. But inevitably, someone will find a way to pack even more dots into the same area.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1000px;"><p class="vanilla-image-block" style="padding-top:66.60%;"><img id="GYTpjWpG5xL3ASxJWoanMd" name="a-final" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/GYTpjWpG5xL3ASxJWoanMd.jpg" mos="" align="middle" fullscreen="" width="1000" height="666" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Asus)</span></figcaption></figure><p>The Asus ProArt PA32QCV sports the same 218ppi that I saw in last year’s PA27JCV, but has a 32-inch panel instead of 27. It’s hard to describe how cool it is to get right up to the screen and still be unable to see the pixels. And with the addition of LuxPixel technology, there is no change in quality when viewing from the sides, nor do ambient light reflections affect the picture.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1280px;"><p class="vanilla-image-block" style="padding-top:82.03%;"><img id="SzVqJUMRGyjrbmvY8UmH3g" name="a-main" alt="Asus ProArt PA32QCV" src="https://cdn.mos.cms.futurecdn.net/SzVqJUMRGyjrbmvY8UmH3g.jpg" mos="" align="middle" fullscreen="1" width="1280" height="1050" attribution="" endorsement="" class="expandable"></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>The PA32QCV sticks to the ProArt model of correctly termed picture modes so it’s super easy to set up and use. Just pick the standard you need and go. My sample had slight grayscale errors, which in any other monitor would be a non-issue. But it was a tad less precise than other ProArt screens. Fixing this was easy since I could adjust RGB values independently for each mode. And the flexibility of Calman autocal or Asus DisplayWidget Center means there are multiple ways to tune the monitor. I also noted that the PA32QCV was one of the brightest and most contrasty IPS screens I’ve seen to date. It hit 650 nits in SDR and HDR, full field and window pattern, and topped 1,600:1 natively.</p><p>At $1,299, the Asus ProArt PA32QCV is a relative bargain among professional monitors. It doesn’t have fast refresh or Mini LED, but it still delivers precise performance. If you need more pixel density than 4K offers, it’s definitely worth checking out.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-gaming-monitors,4533.html"><strong>Best Gaming Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reference/how-we-test-pc-monitors-benchmarking"><strong>How We Test PC Monitors</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/monitor-buying-guide,5699.html"><strong>How to Buy a PC Monitor</strong></a></p>
https://www.tomshardware.com/monitors/asus-proart-pa32qcv-32-inch-6k-professional-monitor-review
Asus ups the pixel density ante with its 6K ProArt PA32QCV. This 32-inch IPS display has 6016x3384 resolution, 218ppi, HDR10, DisplayHDR 600 and color modes for every industry standard. It serves creatives with precision at a relatively low price.
Raan7pjXHAiSv2DKeuY8r3
Wed, 17 Sep 2025 12:00:00 +0000 Monitors
Christian Eberle
Tom&#039;s Hardware
Asus PA32QCV
Asus PA32QCV
<![CDATA[ Hack to the Future — here's how you can write BASIC code on a modern-day PC ]]>
<p>The Beginner’s All-Purpose Symbolic Instruction Code, BASIC, is where I started my coding journey. Sat, aged four or five in front of a Commodore 16, I typed in lines of words and numbers which made up an application or sound effect. Sometimes they worked, often they did not. The words that I typed, along with “syntax error,” meant nothing to a five-year-old child who wanted sugar-coated cereal and Transformers cartoons, but I persevered.</p><p>Fast forward to the 21st century, and I still use BASIC from time to time. I write BASIC on a Commodore 64 and a ZX Spectrum that I recently renovated. I’ve even written <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/raspberry-pi-pico-basic-controlled-neopixels">BASIC on a Raspberry Pi Pico</a> to control a series of NeoPixels.</p><p>Recently, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/bill-gates-48-year-old-microsoft-6502-basic-goes-open-source" target="_blank">Microsoft open-sourced its MOS,6502 BASIC</a> from 1978, and that got me thinking about writing BASIC on a PC. Sure, I remember QBasic and the gorillas.bas game. I loved tweaking that game on my 486 DX33 back in the 1990s,
but I wanted to write BASIC on my Windows 10 PC in 2025.</p><p>I can’t use MOS6502 BASIC without spending a lot of time getting it to work on my PC, so what can I use instead? It turns out that there is, and it is called <a data-analytics-id="inline-link" href="https://www.qb64phoenix.com/" target="_blank"><u>QB64 Phoenix Edition,</u></a> and it looks and feels just like QBasic, but with many more features.</p><ul><li>Realtime input error checking</li><li>Online and offline help system</li><li>Syntax highlighting</li><li>Automatic source formatting</li><li>Debugging</li><li>Compiles native binaries for Windows, macOS and Linux</li></ul><p>QB64 Phoenix Edition (QB64 PE) is a fresh offshoot of the original QB64 project, which seemed to die out in the early 2020s. The project’s goal is to keep the spirit of the old application alive and to provide more people with access to running BASIC on their computers. QB64 PE is cross-platform and it has compatibility with QBasic and QuickBasic 4.5 code. But QB64 PE also gives us an extended BASIC and OpenGL, meaning that we can create applications/games with graphics and sound.</p><p>So let's take a look at QB64 PE and create our own BASIC project.</p><h2 id="getting-started-with-qb64-pe-2">Getting Started with QB64 PE</h2><p>It really couldn’t be any simpler to get started with QB64 PE.</p><p><strong>1. Go to the </strong><a data-analytics-id="inline-link" href="https://www.qb64phoenix.com/"><u><strong>QB4 PE project page</strong></u></a><strong> and download the package for your operating system.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1022px;"><p class="vanilla-image-block" style="padding-top:33.46%;"><img id="stkPJXAqq3TYA7d25LzWpS" name="qb1" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/stkPJXAqq3TYA7d25LzWpS.jpg" mos="" align="middle" fullscreen="" width="1022" height="342" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>2. Extract the file to a directory.</strong></p><p><strong>3. Navigate to that directory and double left click on the qb64pe.exe application.</strong></p><div class="inlinegallery
mosaic-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:622px;"><p class="vanilla-image-block" style="padding-top:13.18%;"><img id="SFtZoFMytDTRNub5gVW8oS" name="qb2" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/SFtZoFMytDTRNub5gVW8oS.jpg" mos="" link="" align="" fullscreen="" width="622" height="82" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1274px;"><p class="vanilla-image-block" style="padding-top:109.26%;"><img id="PYVZv3eqgfso4CS7XEBssS" name="qb-ui.JPG" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/PYVZv3eqgfso4CS7XEBssS.jpg" mos="" link="" align="" fullscreen="" width="1274" height="1392" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The QB64 PE user interface is very much like QBasic. We have the menu at the top, the coding area in the middle, and a status/output/debugging area at the bottom. Our project will see us working with the File and Run menu.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1274px;"><p class="vanilla-image-block" style="padding-top:109.26%;"><img id="gNtNq8QMX27GSGtWKHJKrS" name="qb3.JPG" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/gNtNq8QMX27GSGtWKHJKrS.jpg" mos="" align="middle" fullscreen="" width="1274" height="1392" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>On first boot, QB64 PE will tell us that the application and any executables made by it can be falsely identified by your anti-virus package. You can optionally whitelist the directory, but I have not had any issues in my testing.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1262px;"><p class="vanilla-image-block" style="padding-top:103.65%;"><img id="88yjGmNbfvkDgS8j9ggA6T" name="wiki" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/88yjGmNbfvkDgS8j9ggA6T.jpg" mos="" align="middle" fullscreen="" width="1262" height="1308" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>QB64 PE is an awesome application, and I urge you to dig into the <a data-analytics-id="inline-link" href="https://qb64phoenix.com/qb64wiki/index.php/Main_Page"><u>gloriously in-depth documentation</u></a> (which is where I found how to show images) and learn more about QB64 PE.</p><h2 id="a-short-history-of-basic-2">A short history of BASIC</h2><p>The BASIC language has been with us since 1964, and it was developed as a high-level (easy-to-read) language by John G Kemeny, chairman of the Dartmouth College Math Department. The name BASIC came from Thomas Kurtz.</p><p>The structure of BASIC is meant to be over-simplified on purpose. Each line of BASIC is read by the compiler and turned into bytecode, which the machine can then run. But BASIC can be compiled or interpreted, depending on the version you are using. For example, on the Commodore 64, we see Commodore 64 BASIC V2, a version of Microsoft BASIC, which has a limited number of keywords.</p><h2 id="the-project-goal-to-make-a-simple-game-2">The Project Goal: To Make A Simple Game</h2><p>Learning BASIC, or any coding language, really, is best done by creating a project. I could sit here and teach you about core programming concepts, or we could have some fun and make a simple game. The game in question is inspired by Usborne’s 1980s BASIC coding books, specifically Computer Space Games, which I adored as a child.</p><p>The game is “Escape from planet LXF329,” and the goal of the game is to take off and escape a group of aliens who are trying to capture the spaceship. Essentially, this is a number-guessing game, but with a sci-fi theme.</p><ul><li>Learn the BASIC syntax</li><li>Learn how to display images</li><li>Use conditional statements</li><li>Create variables for integers and strings</li><li>Get user input</li></ul><p>You may have spotted “Learn how to display images,” and yes, I will show you how to display a static image on the screen using QB64 PE. In the interest of full disclosure, the images used in the game were generated using Adobe Firefly, an AI service. Why? I could’ve used stock images or spent some time in GIMP and Inkscape, but I didn’t have the time, nor the talent, so Adobe Firefly did the work for me.</p><p>We’ll start by creating the starting screen, an image that advertises the game and sets the scene.</p><p><strong>1. Create a new blank document and click on File >> Save and save the project as space.bas.</strong> Remember to save often.</p><p>2. Create a new screen object, setting the screen to 1024 x 1024 pixels and 32-bit color, then set the window title to ESCAPE FROM PLANET LXF329”.</p><pre class="line-numbers language-basic" language="basic" ><code>Screen _NewImage(1024, 1024, 32)_Title "ESCAPE FROM PLANET LXF329"</code></pre><p><strong>3. Create a variable, myImage& and store your image.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>myImage& = _LoadImage("title.png")</code></pre><p><strong>4. Create an error handler to check that the image has been loaded correctly.</strong> This is basically a conditional check that checks for the loaded file in the variable. If there is nothing there, 0, then it will print an error message.</p><pre class="line-numbers language-basic" language="basic" ><code>If myImage& = 0 Then
Print "Error loading image!"
EndEnd If</code></pre><p><strong>5. Put the image onto the screen at position 0,0 (top left) then pause the code, waiting for the user to press a key.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>_PutImage (0, 0), myImage&Sleep</code></pre><p><strong>6. Save the code, and click on Run >> run Only (no EXE) to start the code. Click OK in the dialog to start.</strong> You should see the image appear on the screen. <strong>Press any key to close the window.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1279px;"><p class="vanilla-image-block" style="padding-top:109.30%;"><img id="pRxWSaRuacNynXdW5qY73T" name="qb5" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/pRxWSaRuacNynXdW5qY73T.jpg" mos="" align="middle" fullscreen="" width="1279" height="1398" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>7. Create a label, START: </strong>Labels enable us to write code that can jump around to different sections by using a Go To command. You may be familiar with using numbers and jumping to a numbered line. Here ,we are not using numbers, so labels will do the same job.</p><pre class="line-numbers language-basic" language="basic" ><code>START:</code></pre><p><strong>8. To begin the game code, clear the screen (CLS) and then use a series of print statements to print a narrative</strong> to get the reader up to speed on the game mechanics and story.</p><pre class="line-numbers language-basic" language="basic" ><code>ClsPrint "ESCAPE FROM PLANET LXF329"Print "Your vessel, the USS TOMSHARDWARE has landed on LXF329"Print "on a routine survey mission"PrintPrint "But the evil aliens, led by HOAL are after your blood!"PrintPrint "Calculate the thrust necessary to take-off and escape"Print "the planet's gravity!"PrintPrint "You only have ten seconds until the aliens burst into"Print "the starship and lay waste to your crew!"</code></pre><p><strong>9. Ensure that the game uses pseudo-random numbers.</strong> If we don’t do this then the game will pick the same numbers each time.</p><pre class="line-numbers language-basic" language="basic" ><code>Randomize Timer</code></pre><p><strong>10. Create two variables</strong>, g (gravity) and w (weight), which are random integers, multiplied by 20 and 40, respectively. BASIC uses LET to create variables.</p><pre class="line-numbers language-basic" language="basic" ><code>Let g = Int(Rnd * 20)Let w = Int(Rnd * 40)</code></pre><p><strong>11. Create a third variable to store the correct thrust to leave the planet.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>Let r = g * w</code></pre><p><strong>12. For debug purposes, print the answer to the screen. </strong>Later, comment this out using the REM (remark) keyword.</p><pre class="line-numbers language-basic" language="basic" ><code>Print r</code></pre><p>Change to this for the final game</p><pre class="line-numbers language-basic" language="basic" ><code>REM Print r</code></pre><p><strong>13. Print the planet’s gravity and then ask the user to make their thrust calculation.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>Print "Planet Gravity = "; gPrint "Type in thrust to escape: "</code></pre><p><strong>14. Using a for loop, we give the player ten guesses before the aliens enter the ship.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>For c = 1 To 10</code></pre><p><strong>15. Stored the player’s guess in a variable, f.</strong> That value is compared to the answer, r. If the thrust is too high or low, the for loop repeats until the player runs out of guesses. If the guess is correct, then the game goes to the ENDGAME label.</p><pre class="line-numbers language-basic" language="basic" ><code>For c = 1 To 10
Input f
If f > r Then Print "Thrust too high";
If f < r Then Print "Thrust too low";
If f = r Then GoTo ENDGAMENext c</code></pre><p><strong>16. Print “the bad ending” to the screen. </strong>This section runs if the player fails to make the correct calculations, and then the for loop ends, throwing the user into this nightmare scenario.</p><pre class="line-numbers language-basic" language="basic" ><code>PrintPrint "The aliens have entered the starship and you and your"Print "crew are now their prisoners!"Print</code></pre><p><strong>17. Add a graphic to show your ship losing against the alien onslaught.</strong> You will need to create a PNG file, stored in the same directory as the game file. This is the same code as used for the start screen. Sleeping for 5 is important; otherwise, there is a bug where the screen automatically closes and ends the game.</p><pre class="line-numbers language-basic" language="basic" ><code>Screen _NewImage(1024, 1024, 32)_Title "YOU DIED!"myImage& = _LoadImage("die.png")If myImage& = 0 Then
Print "Error loading image!"
EndEnd If_PutImage (0, 0), myImage&Sleep 5</code></pre><p><strong>18. Using a GoTo, send the player to the REPLAY section of code.</strong></p><pre class="line-numbers language-basic" language="basic" ><code>GoTo REPLAY</code></pre><p><strong>19. Print a message to the user to say that they have won. Then show an image on the screen.</strong> The ENDGAME label is where the successful player is sent.<strong> </strong>They are rewarded with a message and an escape image showing them blasting off into space!</p><pre class="line-numbers language-basic" language="basic" ><code>Print "You have successfully taken off!"Print "The aliens burn in the wake of your engines"Screen _NewImage(1024, 1024, 32)_Title "YOU WON!"myImage& = _LoadImage("escape.png")If myImage& = 0 Then
Print "Error loading image!"
EndEnd If_PutImage (0, 0), myImage&Sleep 5</code></pre><p><strong>20. Create a means to ask the player if they would like to try again.</strong> The player’s input is stored as a variable, a. But note that the variable contains a string ($) which can be y or n. If it is y, the game goes back to the START label. Otherwise, the game stops. We use the REPLAY label to identify what the code is for and to direct the player through the game.</p><pre class="line-numbers language-basic" language="basic" ><code>REPLAY:Print "Would you like to try again? Press y or n"Input a$If a$ = "y" Then
GoTo STARTElse
StopEnd If</code></pre><p><strong>21. Save the code, and click on Run >> run Only (no EXE) to start the code. Click OK in the dialog to start.</strong></p><p><strong>22. Run the game a few times, win and lose.</strong> Remember that the answer is printed to the screen, so make sure to comment that out when letting your friends have a go.</p><h2 id="complete-code-listing-2">Complete Code Listing</h2><pre class="line-numbers language-basic" language="basic" ><code>Screen _NewImage(1024, 1024, 32)_Title "ESCAPE FROM PLANET LXF329"myImage& = _LoadImage("title.png")If myImage& = 0 Then
Print "Error loading image!"
EndEnd If_PutImage (0, 0), myImage&SleepSTART:ClsPrint "ESCAPE FROM PLANET LXF329"Print "Your vessel, the USS TOMSHARDWARE has landed on LXF329"Print "on a routine survey mission"PrintPrint "But the evil aliens, led by HOAL are after your blood!"PrintPrint "Calculate the thrust necessary to take-off and escape"Print "the planet's gravity!"PrintPrint "You only have ten seconds until the aliens burst into"Print "the starship and lay waste to your crew!"Randomize TimerLet g = Int(Rnd * 20)Let w = Int(Rnd * 40)Let r = g * wPrint rPrint "Planet Gravity = "; gPrint "Type in thrust to escape: "For c = 1 To 10
Input f
If f > r Then Print "Thrust too high";
If f < r Then Print "Thrust too low";
If f = r Then GoTo ENDGAMENext cPrintPrint "The aliens have entered the starship and you and your"Print "crew are now their prisoners!"PrintScreen _NewImage(1024, 1024, 32)_Title "YOU WON!"myImage& = _LoadImage("die.png")If myImage& = 0 Then
Print "Error loading image!"
EndEnd If_PutImage (0, 0), myImage&Sleep 5GoTo REPLAYENDGAME:Print "You have successfully taken off!"Print "The aliens burn in the wake of your engines"Screen _NewImage(1024, 1024, 32)_Title "YOU WON!"myImage& = _LoadImage("escape.png")If myImage& = 0 Then
Print "Error loading image!"
EndEnd If_PutImage (0, 0), myImage&Sleep 5REPLAY:Print "Would you like to try again? Press y or n"Input a$If a$ = "y" Then
GoTo STARTElse
StopEnd If</code></pre><h2 id="sharing-your-work-2">Sharing your work!</h2><p>If you want to share the game with your friends, then you can! Just bear in mind that the resulting executable is bound to the OS it was created with. Additionally, as QB64 PE notes, your executable may be flagged as a false positive by your antivirus.</p><p><strong>1. Click on Run >> Make EXE Only. You can also click on Run >> Start to compile and run the code. This way you get both the executable, and the code will run in the editor.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:548px;"><p class="vanilla-image-block" style="padding-top:49.82%;"><img id="imjPFBbd2XWxRMRbZSSCpS" name="exe1" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/imjPFBbd2XWxRMRbZSSCpS.jpg" mos="" align="middle" fullscreen="" width="548" height="273" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>2. Click OK to compile the executable into the qb64pe folder</strong>, the same folder where QB64 PE is being run.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:585px;"><p class="vanilla-image-block" style="padding-top:32.48%;"><img id="JYqzN67e9BnXw6tBYv99nS" name="exe2" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/JYqzN67e9BnXw6tBYv99nS.jpg" mos="" align="middle" fullscreen="" width="585" height="190" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>3. Wait for the code to compile. Check the status bar at the bottom of the screen to monitor the progress.</strong> On modern systems this will take seconds.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1270px;"><p class="vanilla-image-block" style="padding-top:16.77%;"><img id="yWBBvsYVU3j8v8nNtomHpS" name="exe3" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/yWBBvsYVU3j8v8nNtomHpS.jpg" mos="" align="middle" fullscreen="" width="1270" height="213" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>4. Navigate to the folder with the compiled game code.</strong> I scanned my compiled code using Microsoft Defender and Malwarebytes, and nothing nasty was found.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1024px;"><p class="vanilla-image-block" style="padding-top:70.31%;"><img id="u7sLFfo7sJMiPr6vg2KXpS" name="exe4.JPG" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/u7sLFfo7sJMiPr6vg2KXpS.jpg" mos="" align="middle" fullscreen="" width="1024" height="720" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><strong>5. Double click on the executable to run the game.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1272px;"><p class="vanilla-image-block" style="padding-top:54.01%;"><img id="VLUzeJjeHe6GTGmqGwMVFT" name="game-small" alt="BASIC 2025" src="https://cdn.mos.cms.futurecdn.net/VLUzeJjeHe6GTGmqGwMVFT.gif" mos="" align="middle" fullscreen="" width="1272" height="687" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">The images used in the game are AI generated using Adobe Firefly </span><span class="credit" itemprop="copyrightHolder">(Image credit: The images used in the game are AI generated using Adobe Firefly)</span></figcaption></figure>
https://www.tomshardware.com/software/programming/hack-to-the-future-heres-how-you-can-write-basic-code-on-a-modern-day-pc
BASIC was the Python of its day and it inspired many bedroom coders to spend hours in their room, hacking around to make games and tools. Now you can do the same in the 21st century.
iqZoxKqL6xBngcrDieFPsG
Wed, 17 Sep 2025 11:49:35 +0000 Programming
Software
Les Pounder
AI generated using Adobe Firefly
BASIC 2025
BASIC 2025
<![CDATA[ 'Beyond EUV' chipmaking tech pushes Soft X-Ray lithography closer to challenging Hyper-NA EUV — 'B-EUV' uses new resist chemistry to make smaller chips ]]>
<p>Researchers at Johns Hopkins University have unveiled a new approach to chipmaking that uses lasers with a 6.5nm ~ 6.7nm wavelength — also known as Soft X-rays — that could increase the resolution of lithography tools to 5nm and below, reports <a data-analytics-id="inline-link" href="https://cosmosmagazine.com/science/engineering/microchip-beyond-extreme-uv/" target="_blank">Cosmos,</a> citing a paper published in <a data-analytics-id="inline-link" href="https://www.nature.com/articles/s44286-025-00273-z" target="_blank">Nature</a>.</p><p>The scientists call their method 'beyond-EUV' — suggesting that their technology could replace industry-standard EUV lithography — but the researchers admit they are currently years away from building even an experimental B-EUV tool.</p><h2 id="soft-x-rays-can-challenge-hyper-na-on-paper-2">Soft X-Rays can challenge Hyper-NA. On paper</h2><p>The most advanced chips nowadays are made using EUV lithography, which operates at a wavelength of 13.5 nm and can produce features as small as 13nm (Low-NA EUV of 0.33 numerical aperture), 8nm (<a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/manufacturing/asml-fires-back-at-accusations-that-its-next-gen-high-na-euv-chipmaking-tools-are-too-expensive">High-NA EUV</a> of 0.55 NA), or even 4nm ~ 5nm (<a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/manufacturing/asml-explores-hyper-na-chipmaking-tools-as-the-next-step-in-shrinking-transistors-tools-would-debut-in-2030-but-significant-technology-and-cost-hurdles-remain">Hyper-NA EUV</a> on 0.7 – 0.75 NA) at the cost of extreme complexity of the lithography systems that have very advanced optics that cost hundreds of millions of dollars.</p><p>By using a shorter wavelength, researchers from Johns Hopkins University can get an intrinsic resolution boost even with lenses with moderate NA. However, they face many challenges with B-EUV.</p><p>Firstly, B‑EUV light sources are not yet ready. Various researchers have tried <a data-analytics-id="inline-link" href="https://www.researchgate.net/publication/240395264_Reflective_multilayer_optics_for_67_nm_wavelength_radiation_sources_and_next_generation_lithography">multiple methods</a> of <a data-analytics-id="inline-link" href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-33-4-8806&id=568351">generating 6.7 nm wavelength radiation</a> (e.g., gadolinium laser-produced plasma), but there is no industry-standard approach. Secondly, these shorter wavelengths — due to their high photon energy — interact poorly with traditional photoresist materials used in chipmaking. Thirdly, because 6.5nm ~ 6.7nm wavelength light is absorbed rather than reflected by pretty much everything, multilayer-coated mirrors for this type of radiation haven't been produced before.</p><div ><table><tbody><tr><td class="firstcol " ><p>Lithography Type</p></td><td
><p>Wavelength</p></td><td
><p>Achievable Resolution</p></td><td
><p>Photon Energy</p></td><td
><p>Numerical Aperture (NA)</p></td><td
><p>Notes </p></td></tr><tr><td class="firstcol " ><p>g-line (Pre-DUV)</p></td><td
><p>436 nm</p></td><td
><p>500 nm</p></td><td
><p>2.84 eV</p></td><td
><p>0.3</p></td><td
><p>Uses mercury vapor lamps; legacy nodes; low resolution. </p></td></tr><tr><td class="firstcol " ><p>i-line (Pre-DUV)</p></td><td
><p>365 nm</p></td><td
><p>350 nm</p></td><td
><p>3.40 eV</p></td><td
><p>0.3</p></td><td
><p>Used for early CMOS. </p></td></tr><tr><td class="firstcol " ><p>KrF DUV</p></td><td
><p>248 nm</p></td><td
><p>90 nm</p></td><td
><p>5.00 eV</p></td><td
><p>0.7 - 1.0</p></td><td
><p>Used from ~130 nm to 90 nm; excimer laser source; still used in backend layers. </p></td></tr><tr><td class="firstcol " ><p>ArF DUV</p></td><td
><p>193 nm</p></td><td
><p>65 nm (dry) - 45 nm (immersion + multipatterning)</p></td><td
><p>6.42 eV</p></td><td
><p>Up to 1.35 (immersion)</p></td><td
><p>Most advanced DUV; still essential in multi-patterned 7 nm–5 nm nodes; used for many layers in 2nm nodes. </p></td></tr><tr><td class="firstcol " ><p>EUV</p></td><td
><p>13.5 nm</p></td><td
><p>13 nm (native), 8 nm (multi-patterning)</p></td><td
><p>92 eV</p></td><td
><p>0.33</p></td><td
><p>In volume production for 5nm - 2nm nodes. Will be used for years to come. </p></td></tr><tr><td class="firstcol " ><p>High-NA EUV</p></td><td
><p>13.5 nm</p></td><td
><p>8 nm (native), 5 nm (extended)</p></td><td
><p>92 eV</p></td><td
><p>0.55</p></td><td
><p>First tools: ASML EXE:5200B; targets beyond 2 nm-class nodes; reduced field size, higher cost. </p></td></tr><tr><td class="firstcol " ><p>Hyper-NA EUV (future)</p></td><td
><p>13.5 nm</p></td><td
><p>4 nm or better (theoretical)</p></td><td
><p>92 eV</p></td><td
><p>0.75 or more</p></td><td
><p>Future tech; requires exotic mirrors and ultra-high precision engineering. </p></td></tr><tr><td class="firstcol " ><p>Soft X-ray / B-EUV</p></td><td
><p>6.5 nm - 6.7 nm</p></td><td
><p>less than 5 nm (theoretical)</p></td><td
><p>185-190 eV</p></td><td
><p>0.3 - 0.5 (expected)</p></td><td
><p>Experimental; high-energy photons; new metal-organic resist chemistries under test.</p></td></tr></tbody></table></div><p>Finally, these lithography tools must be designed from scratch, and currently, there is no ecosystem to support the designs with components and consumables. To sum up, building a B-EUV machine (or Soft X-ray machine?) requires breakthroughs in light sources, projection mirrors, resists, and even consumables like pellicles or photomasks.</p><h2 id="solving-challenges-one-at-a-time-2">Solving challenges one at a time</h2><p>Researchers at Johns Hopkins University, led by Professor Michael Tsapatsis, explored how certain metals can improve the interaction between B-EUV (around 6 nm wavelength) light and resist materials used in chipmaking (i.e., they did not work on other challenges associated with Soft X-rays).</p><p>The team discovered that metals like zinc are able to absorb B-EUV light and emit electrons, which then trigger chemical reactions in organic compounds called imidazoles. These reactions make it possible to etch very fine patterns onto semiconductor wafers.</p><p>Interestingly, while zinc performs poorly with traditional 13.5nm EUV light, it becomes highly effective at shorter wavelengths, highlighting how important it is to match the material with the right wavelength.</p><p>To apply these metal–organic compounds to silicon wafers, the researchers developed a technique called chemical liquid deposition (CLD). This method creates thin, mirror-like layers of a material called aZIF (amorphous zeolitic imidazolate frameworks), growing at a rate of 1nm per second. CLD also allows for fast testing of different metal–imidazole combinations, making it easier to discover the best pairings for different lithography wavelengths. While zinc is well suited for B-EUV, the team noted that other metals might perform better at different wavelengths, offering flexibility for future chipmaking technologies.</p><p>This approach gives manufacturers a toolbox of at least 10 metal elements and hundreds of organic ligands to create custom resists tailored to specific lithography platforms, the researchers disclosed.</p><h2 id="summary-2">Summary</h2><p>Although the researchers did not solve the full stack of B-EUV challenges (e.g., source power, masks), they advanced one of the most critical bottlenecks: finding resist materials that can work with 6nm wavelength light. They created the CLD process to apply thin, uniform films of amorphous zeolitic imidazolate frameworks (aZIFs) onto silicon wafers. They experimentally showed that certain metals (like zinc) can absorb Soft X-ray light and emit electrons that trigger chemical reactions in imidazole-based resists.</p><p>There are plenty of challenges to be solved with B-EUV, and the technology doesn't have a clear path to the mass market. However, the CLD process can be used pretty widely, both in semiconductor and non-semiconductor applications.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/beyond-euv-chipmaking-tech-pushes-soft-x-ray-lithography-closer-to-challenging-hyper-na-euv-b-euv-uses-new-resist-chemistry-to-make-smaller-chips
Researchers at Johns Hopkins University have developed a new resist chemistry and deposition method optimized for 6.5 nm B-EUV light, marking a key step toward future Soft X-ray lithography. However, major challenges like light sources and tool infrastructure remain unresolved.
PnxwP79RqxCPRMQwwEebJP
Wed, 17 Sep 2025 11:38:04 +0000 Semiconductors
Tech Industry
Manufacturing
ashilov@gmail.com (Anton Shilov)
Anton Shilov
Micron
Micron
Micron
<![CDATA[ China bans its biggest tech companies from acquiring Nvidia chips, says report — Beijing claims its homegrown AI processors now match H20 and RTX Pro 6000D ]]>
<p>The Cyberspace Administration of China (CAC), the country’s top internet regulator, has reportedly banned its biggest tech companies, including ByteDance and Alibaba, from buying Nvidia’s AI chips. According to the <a data-analytics-id="inline-link" href="https://www.ft.com/content/12adf92d-3e34-428a-8d61-c9169511915c"><em>Financial Times</em></a>, the CAC said that these institutions should stop testing the new RTX Pro 6000D and cancel their orders, even though several companies had already indicated their interest in purchasing tens of thousands of these GPUs, which were <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-pro-6000d-b40-blackwell-gpus-reportedly-set-to-supersede-banned-h20-accelerators-in-china">set to replace the H20</a> after it was banned (but before it was unbanned again). This goes against the initial reports that <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidias-china-exclusive-rtx-6000d-reportedly-gets-lukewarm-reception-in-china-due-to-hobbled-performance-could-leave-nvidia-with-huge-backlog-of-unwanted-gpus">reception for the more affordable AI China-specific GPU was lukewarm</a> —
instead, it turns out that the central government was blocking the purchase of these graphics cards. This new ban comes just weeks after companies were directed to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/china-tells-tech-giants-to-halt-nvidia-h20-orders-after-u-s-officials-addiction-remark-chinese-leaders-call-lutnicks-comments-insulting">stop ordering Nvidia H20 chips</a>, too.</p><p>Beijing reportedly believes that homegrown AI chip makers, like Huawei and Cambricon, now produce chips that have comparable performance to Nvidia’s China-only products. And although Team Green might still have an advantage with its software stack, other Chinese tech giants like Tencent are <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/tencent-goes-public-with-pivot-to-chinese-chips">pushing to build their own infrastructure</a> to replace that. Because of these developments, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/chinas-chip-champions-ramp-up-production-of-ai-accelerators-at-domestic-fabs-but-hbm-and-fab-production-capacity-are-towering-bottlenecks">China’s chip makers are ramping production</a> in anticipation of the glut of orders coming from companies that need AI chips but can’t purchase Nvidia products.</p><p>When approached for comment, Nvidia directed us to remarks made by CEO Jensen Huang in London on Wednesday morning. "We can only be in service of a market if the country wants us to be," adding, "I’m disappointed with what I see. But they have larger agendas to work out, between China and the US, and I’m understanding of that. We are patient about it. We’ll continue to be supportive of the Chinese government and Chinese companies as they wish.” Huang told reporters in London on Wednesday that he hopes to discuss Nvidia's ability to do business in China with President Trump during the latter's state visit to the UK.</p><p>This news comes soon after the country accused Nvidia of breaking its anti-monopoly law, with the chipmaker facing fines of up to 10% of its China revenue. However, some also believe that Beijing is making these moves to get a more favorable deal from the U.S. in trade negotiations, especially as <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-reportedly-shows-china-specific-b30-chips-with-80-percent-of-the-performance-of-the-standard-blackwell-gpu-to-the-u-s-government-nvidia-ceo-says-approval-is-still-up-in-the-air">export approval for its Blackwell-based B30 chips</a>, which perform up to 80% of its latest products, is still up in the air.</p><p>On the other hand, some Chinese industry leaders believe that this move is part of the central government’s effort to break free from American technology and boost its homegrown semiconductor industry. “The message is now loud and clear,” one executive told the <em>Financial Times</em>. “Earlier, people had hopes of renewed Nvidia supply if the geopolitical situation improves. Now it’s all hands on deck to build the domestic system.”</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em>Tom's Hardware on Google News</em></u></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em>add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/artificial-intelligence/china-bans-its-biggest-tech-companies-from-acquiring-nvidia-chips-says-report-beijing-claims-its-homegrown-ai-processors-now-match-h20-and-rtx-pro-6000d
Beijing is reportedly telling its biggest tech companies to buy local instead of purchasing Nvidia's latest China-specific AI chips.
XGT2o274VFJMkM9nsr3MzD
Wed, 17 Sep 2025 11:26:57 +0000 Artificial Intelligence
Tech Industry
editors@tomshardware.com (Jowi Morales)
Jowi Morales
Shutterstock
China
China
<![CDATA[ These are the top free Windows tools that I use on a daily basis to boost my productivity ]]>
<p>You don’t need to spend big money for the best applications, and here is proof! I’ve collated a list of the best free applications for creating content, writing code, making bootable USB drives, and, most essential of all, entertainment.</p><p>These are all of the apps that I commonly use when making content on <em>Tom’s Hardware,</em> and sometimes my overly neglected blog. All of these applications are for Windows-based machines, but many are also available for Linux and macOS devices.</p><p>So let's dive in and learn a little more about the apps that I use.</p><h3 class="article-body__section" id="section-creative-tools"><span>Creative Tools</span></h3><h2 id="screentogif-2">ScreenToGIF</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1762px;"><p class="vanilla-image-block" style="padding-top:66.40%;"><img id="nJvYp4UeJUjfbejaaLpRfS" name="screentogif.JPG" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/nJvYp4UeJUjfbejaaLpRfS.jpg" mos="" align="middle" fullscreen="" width="1762" height="1170" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>If you’ve seen a GIF in any of my content, <a data-analytics-id="inline-link" href="https://www.screentogif.com/"><u>ScreenToGIF</u></a> made it. This free tool can capture entire screens or portions of them and render them as an animated GIF or a video file. Not only does ScreenToGIF capture media for my GIFs, but I can also edit them from the expansive menu. Scaling, trimming, optimizing, and features such as watermarks, text, and special effects are just a click away.</p><p>I use ScreenToGIF a lot! Mainly for GIFs, but it works extremely well as a quick way to capture videos for IT support tickets when I need to prove that I found an issue.</p><p>ScreenToGIF can also be used to convert a video to GIF. Just make sure that it isn’t an MOV file; for that, you will need to convert the file using Handbrake, which is also on this list! In ScreenToGIF, I can remove frames, set the FPS, add effects, scan for duplicates, resize the images, and more.</p><p>Output options are as a video file and, of course, GIF. With GIF, there are multiple encoding options and encoders to get the best desired output for your creations.</p><p><a data-analytics-id="inline-link" href="https://www.screentogif.com/"><u>ScreenToGIF</u></a> is awesome and I’ve been using it for over four years now and it has proven to be a solid performer for my workflow.</p><h2 id="gimp-2">GIMP</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:970px;"><p class="vanilla-image-block" style="padding-top:54.74%;"><img id="4Li4w4g66Ng3SCc7Cg7wbS" name="gimp" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/4Li4w4g66Ng3SCc7Cg7wbS.jpg" mos="" align="middle" fullscreen="" width="970" height="531" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>I’ve used <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/video-editing-graphic-design/five-best-photoshop-alternatives-tested-image-editing-for-free" target="_blank"><u>many different bitmap image editors;</u></a> heck, I trained on Adobe Photoshop back in the 1990s, but something always brings me back to <a data-analytics-id="inline-link" href="https://www.gimp.org/" target="_blank"><u>GIMP</u></a>. It's not the name, clearly. But the GNU Image Manipulation Programme has plenty of features for this writer.</p><p>First of all, this isn’t Photoshop. You can make it appear to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/make-gimp-look-and-feel-like-photoshop"><u>work like Photoshop</u></a>, but I’d recommend learning to use the default interface, unless you are transitioning from Photoshop. GIMP can do it all — you just have to learn how it works, but it doesn’t take too long. GIMP feels a little slower than Photoshop; that could be a mix of performance and user expectation.</p><p>GIMP supports Photoshop file formats, along with all the usual suspects, including RAW images. We can work with multiple layers, effects, and filters to tweak our compositions. You can write your own plugins using Python or C/C++ and call GIMP from the command line/terminal to batch edit images without the GUI.</p><p><a data-analytics-id="inline-link" href="https://www.gimp.org/"><u>GIMP</u></a> is free and well worth investing your time and effort into. If not, there are <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/video-editing-graphic-design/five-best-photoshop-alternatives-tested-image-editing-for-free"><u>plenty of other image editors</u></a> that you can try out.</p><h2 id="inkscape-2">Inkscape</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1326px;"><p class="vanilla-image-block" style="padding-top:103.32%;"><img id="BFvmF9ypbdfEbgVUoNNndS" name="inkscape.JPG" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/BFvmF9ypbdfEbgVUoNNndS.jpg" mos="" align="middle" fullscreen="" width="1326" height="1370" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Adobe Illustrator is where I learned my craft back in the 1990s. Along with Adobe Photoshop and Aldus Pagemaker, it's no wonder that I seemed on track for a career in journalism. But the problem with Adobe software is the cost. If you are a professional, then the cost is a business expense, but if you are only an occasional user, then that cost is hard to swallow.</p><p><a data-analytics-id="inline-link" href="https://inkscape.org/"><u>Inkscape</u></a> is a viable and, dare I say, excellent alternative to Illustrator. It works with Illustrator files and SVG (Scalable Vector Graphics) files that are commonly used on the web. Inkscape is a joy to use, and I can annotate images, create diagrams ,and even prepare SVG files that I ultimately <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/design-and-3d-print-custom-cases"><u>use to make 3D printable objects.</u></a></p><p><a data-analytics-id="inline-link" href="https://inkscape.org/"><u>Inkscape</u></a> is a wonderful tool, and you should add it to your setup right away.</p><h3 class="article-body__section" id="section-useful-tools"><span>Useful Tools</span></h3><h2 id="notepad-2">Notepad++</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2144px;"><p class="vanilla-image-block" style="padding-top:52.19%;"><img id="2LJ5L7c8mbshqrzsotwbeS" name="notepad++.JPG" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/2LJ5L7c8mbshqrzsotwbeS.jpg" mos="" align="middle" fullscreen="" width="2144" height="1119" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>For this entry, I have Avram Piltch to thank. <a data-analytics-id="inline-link" href="https://notepad-plus-plus.org/"><u>Notepad++</u></a> was something that I was aware of, but never really used. You see, I used to swear by Microsoft’s Visual Studio Code for all of my coding projects, but it is a little overkill for some.<br>Notepad++, as its name suggests, is as light as the built-in Notepad, but it has an excellent awareness of different programming languages, and it makes short work of opening the majority of text files, including my personal favorite, Markdown.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:628px;"><p class="vanilla-image-block" style="padding-top:49.04%;"><img id="hiKhPokdEMMtZTPk5iZvaS" name="notepad-syntax" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/hiKhPokdEMMtZTPk5iZvaS.jpg" mos="" align="middle" fullscreen="" width="628" height="308" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Using a plugin for Markdown, I can preview what I am writing, before it gets published to my blog. When coding in other languages, Notepad++ provides syntax highlighting, a handy feature for most coders.</p><p><a data-analytics-id="inline-link" href="https://notepad-plus-plus.org/"><u>Notepad++ </u></a>is more than a note taking tool, it is a development tool that no coder should do without.</p><h2 id="rufus-2">Rufus</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:474px;"><p class="vanilla-image-block" style="padding-top:151.69%;"><img id="Tsdw4kePT39GZ7XZaSJxaS" name="rufus.JPG" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/Tsdw4kePT39GZ7XZaSJxaS.jpg" mos="" align="middle" fullscreen="" width="474" height="719" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Over the years, I have made a lot of bootable USB sticks for single-board computers such as the Raspberry Pi, LattePanda, and, of course, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/laptops/why-i-still-use-a-lenovo-thinkpad-that-debuted-in-2011-the-x220-helps-me-stay-focused-on-my-most-important-tasks" target="_blank"><u>my elderly Lenovo X220</u></a>. To make these bootable sticks, I’ve used Raspberry Pi Imager, Etcher, and even the dd Linux command. But Rufus is the one app that I keep coming back to.</p><p><a data-analytics-id="inline-link" href="https://rufus.ie/en/"><u>Rufus</u></a> is a free download, and it can write an ISO / IMG file to a USB stick for later use on a machine. It can also be used to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/how-to/clean-install-windows-11"><u>customize a Windows 11 install disk</u></a> to bypass TPM requirements.</p><p>Simple to use, Rufus hides a lot of features in plain sight, activating specific features according to your needs. Take, for example, the extended Windows 11 tweaks for TPM, RAM requirements, and so on.</p><p><a data-analytics-id="inline-link" href="https://rufus.ie/en/"><u>Download Rufus</u></a> and throw it on a spare USB flash drive, for those times when you really need to make a bootable USB disk, without the hassle of dd. Alternatively, take a look at <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/pc-building/i-created-a-pc-repair-kit-that-i-can-take-on-the-road-here-are-the-tools-that-come-in-handy-when-youre-in-a-pinch"><u>Ventoy</u></a>, which can store multiple bootable operating systems on a single USB drive.</p><h3 class="article-body__section" id="section-entertainment-and-media"><span>Entertainment and Media</span></h3><h2 id="vlc-2">VLC</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1913px;"><p class="vanilla-image-block" style="padding-top:61.63%;"><img id="FD9uKJDJ5qNhmWWbiiStgS" name="vlc" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/FD9uKJDJ5qNhmWWbiiStgS.jpg" mos="" align="middle" fullscreen="" width="1913" height="1179" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><a data-analytics-id="inline-link" href="https://www.videolan.org/"><u>VLC</u></a> is the backbone of my productivity. After ripping my CDs to FLAC, I throw them onto my NAS, and from there, my Windows desktop, Linux laptop, and Android smartphone can access the files via VLC.</p><p>Video playback via VLC is always a joy, and the interface is simple, but to the point where I can use it in my sleep. I even use VLC's screengrab tool to screenshot images from a video capture card that I use to record installing different operating systems on single-board computers.</p><p>Got a malformed media file? VLC doesn’t care; it will play it. YouTube link or BBC iPlayer stream? VLC will play it. An obscure web format from 20 years ago? Sure. VLC just gets on with it. Still got your physical media? VLC will play your CDs and DVDs</p><p>Without VLC, I’d probably get less work done; without my music, there is no work! So <a data-analytics-id="inline-link" href="https://www.videolan.org/"><u>download it for yourself</u></a> right now.</p><h2 id="handbrake-2">Handbrake</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1081px;"><p class="vanilla-image-block" style="padding-top:74.01%;"><img id="bPNsLpb9UgZGxog4zWtWdS" name="handbrake" alt="Windows Tools" src="https://cdn.mos.cms.futurecdn.net/bPNsLpb9UgZGxog4zWtWdS.jpg" mos="" align="middle" fullscreen="" width="1081" height="800" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p><a data-analytics-id="inline-link" href="https://handbrake.fr/"><u>Handbrake </u></a>has saved my bacon on more than a few occasions. This is the tool that you need to transcode audio/video media when you want it to play on an older device, a device that has a specialized hardware decoder, or you want to publish to YouTube.</p><p>Handbrake has a frightening amount of options, but stick with the presets and you’ll be good.</p><p>Handbrake can be used on single files, or multiple files can be added to a queue, each with its own specific configuration. Then we just run Handbrake over the queued files and let it do its thing.</p><p>Advanced users can integrate Handbrake’s CLI interface to automate batch processes, handy for when we are backing up our DVD collection to a NAS. Users have created their own batch scripts to run Handbrake and download cover art and subtitles for their content, automating the process of archiving their physical media to a NAS.</p><p>Handbrake is one of those apps that we don’t always need, but when we need to convert video files, everybody uses Handbrake, so <a data-analytics-id="inline-link" href="https://handbrake.fr/"><u>grab a free copy now</u></a>.</p>
https://www.tomshardware.com/software/windows/these-are-the-top-six-free-windows-tools-that-i-use-on-a-daily-basis
You don’t need to spend any money nor commit piracy to get great software, and here is the proof!
eUL33SezjxRQ42M9zZoRUd
Wed, 17 Sep 2025 11:16:58 +0000 Windows
Software
Operating Systems
Les Pounder
Pexels OpenClipArt
Windows Tools
Windows Tools
<![CDATA[ Apple prepping touchscreen OLED MacBook Pro for 2026 — new report claims model will incorporate on-cell touch tech for the first time ]]>
<p>A new report from top Apple insider Ming-Chi Kuo <a data-analytics-id="inline-link" href="https://x.com/mingchikuo/status/1968249865940709538" target="_blank">claims</a> that the company will finally introduce touchscreen technology to its Mac lineup, beginning with an OLED MacBook Pro set to enter mass production in late 2026.</p><p>Kuo made the revelation on X early on Wednesday morning. "MacBook models will feature a touch panel for the first time, further blurring the line with the iPad,"
he noted. "This shift appears to reflect Apple’s long-term observation of iPad user behavior, indicating that in certain scenarios, touch controls can enhance both productivity and the overall user experience."</p><p>According to Kuo, a new OLED MacBook Pro is expected to enter mass production "by late 2026." The information — which, of course, is unofficial — could indicate a launch in Q4 2026 or possibly early 2027. The former seems likely, given that Apple generally launches new Mac models in the fall and has been previously tipped to be exploring an annual release cycle for Macs more in line with its iPhone launch schedule.</p><p>Kuo further notes that Apple is planning a more affordable MacBook powered by an A-series iPhone processor. He says this is slated for mass production in 4Q25, which could indicate a launch very soon. He notes a second-generation version of this MacBook could come in 2027 and that Apple is considering touch screen support for that model.</p><p>Apple's current MacBook Pro family was unveiled in October 2024 and sports the M4 family of Apple silicon chips. While its Liquid Retina XDR display offers 120Hz refresh rates, OLED technology remains a key tech that is set to grace the Apple MacBook lineup. Further previous leaks from the supply chain have hinted at MacBook Pro models with OLED displays coming in 2026, lining up nicely with Kuo's latest prediction.</p><p>Apple has famously eschewed touchscreen tech on its laptops, an aversion that dates back to Steve Jobs' tenure as CEO. Jobs famously blasted the concept, telling an audience in 2010 that "touch surfaces don't want to be vertical," citing user fatigue and terrible ergonomics.</p><p>If Kuo is right about the touch screen MacBook in 2026 (his track record is extremely solid), then that would signal a true change in Mac design philosophy from Apple, which many users have been clamoring for over generations of MacBook launches.</p><p>Apple's M5 MacBook series is next in the lineup. Previously, industry sources had tipped them for a release at the end of this year; however, latterly Kuo has pointed to a <a data-analytics-id="inline-link" href="https://mingchikuo.craft.me/UeiC07s0qRrd1L" target="_blank">2026 launch</a>. It's possible Kuo's OLED touch screen predictions relate to this lineup, but it seems more likely the change will be reserved for the next generation M6 processors.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/laptops/macbooks/apple-prepping-touchscreen-oled-macbook-pro-for-2026-new-report-claims-new-model-will-incorporate-on-cell-touch-tech-for-the-first-time
A new inside report claims Apple will release a touch screen MacBook in late 2026 or early 2027.
mqTnkMyrir3KkhBvQuV6SS
Wed, 17 Sep 2025 11:13:07 +0000 Macbooks
Laptops
stephen.warwick@futurenet.com (Stephen Warwick)
Stephen Warwick
Apple
Apple MacBook Pro
Apple MacBook Pro
<![CDATA[ How TSMC managed to increase efficiency of ASML's EUV tools: System-level optimizations and in-house pellicles —chipmaker boosted EUV-driven wafer production by 30x over six years while reducing power consumption by 24% ]]>
<p>TSMC is by far the largest operator of ASML's EUV lithography tools in the industry, with a second-to-none supply chain of both hardware and raw materials. The company's requirements for EUV pellicles (a thin membrane that protects the photomask, which acts as a stencil for chip patterns) have gotten incredibly high. The requirements are so extreme that TSMC intends to retrofit one of its 200-mm fabs to produce proprietary EUV pellicles exclusively, according to <a data-analytics-id="inline-link" href="https://www.digitimes.com.tw/tech/dt/n/shwnws.asp?CnlID=1&Cat=40&id=0000732130_PCY2S1112LWX501INK4C1">DigiTimes</a>.</p><p>However, TSMC's proprietary pellicles, which outperform ASML's own offering, are just the tip of the iceberg, as TSMC pushes efforts to improve the efficiency of its fabs and ASML's EUV lithography tools.</p><p>When TSMC first deployed EUV in 2019 on its N7+ process for Huawei's HiSilicon Kirin 9000-series processors for smartphones, it already controlled 42% of the global install base of EUV lithography machines,
despite TSMC not being the first foundry to formally announce the use of EUV tools.</p><p>By 2020, as ASML accelerated shipments and introduced its N5 process technology, which uses EUV for several layers, TSMC captured 50% market share of all EUV machines; this increased to 56% in mid-2024, with 130 machines to its name. Now, TSMC likely controls around 200 EUV machines globally, across many of its fabs.</p><p>While the number of EUV systems increased at TSMC by over 10 times compared to 2019, the number of wafers the company processes increased by over 30 times over six years, which indicates that TSMC did an incredible job to reduce downtime and service time, while increasing the throughput of its EUV scanners, which ultimately leads to higher productivity.</p><h2 id="tool-productivity-2">Tool productivity</h2><p>TSMC said at its Technology Symposium in mid-2024 that it had doubled the wafer output per EUV tool per day since 2019 by fine-tuning both the <a data-analytics-id="inline-link" href="https://semiwiki.com/lithography/304326-the-challenge-of-working-with-euv-doses/">exposure dose</a> and the photoresist materials used in its lithography process. But, to define how TSMC has managed such efficiency, we speculate how the company may have achieved this.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="MqQcLuXtcS9FPhQiZeDavC" name="NXE3400_Simplify_seq15_5k.jpg" alt="ASML" src="https://cdn.mos.cms.futurecdn.net/MqQcLuXtcS9FPhQiZeDavC.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: ASML)</span></figcaption></figure><p>On the exposure side, TSMC refined dose-to-size and dose-to-clear thresholds to reduce scanner dwell time per exposure field, while preserving critical dimension (CD) uniformity and ensuring line-edge roughness (LER) according to spec, which enables faster patterning without compromising yield in EUV lithography.</p><p>Typically, lowering these doses reduces the scanner's dwell time per field, enabling more wafers to be processed each day. However, this must be carefully balanced to maintain pattern fidelity, including CD control and LER. TSMC has succeeded, at least if we decoded its description correctly. Since TSMC has not disclosed the exact details, this is speculation, based on publicly available information.</p><p>On the materials side, TSMC upgraded its photoresist systems, possibly adopting high-sensitivity chemically amplified resists (CARs) and potentially incorporating metal-oxide resists (MORs) to improve absorption at 13.5 nm wavelength. These materials can enable lower exposure doses without degrading resolution. However, the company has yet to disclose which materials were used and exactly how they may have been implemented.</p><p>In parallel, TSMC also improved scanner utilization efficiency by deploying <a data-analytics-id="inline-link" href="https://primavera-project.com/wp-content/uploads/2023/02/3.-ASML-Prima-Vera-1Feb2023.pdf">predictive maintenance models</a>, optimizing job scheduling, <a data-analytics-id="inline-link" href="https://pure.tue.nl/ws/files/46934826/846650-1.pdf">servicing tools in advance</a>, <a data-analytics-id="inline-link" href="https://patents.google.com/patent/US10386716B2/en">enhancing vibration control</a>, and improving <a data-analytics-id="inline-link" href="https://www.mdpi.com/2072-666X/16/8/880">cooling performance</a>. These changes reduced unplanned downtime and increased daily tool availability, enabling each EUV system to process more wafers in a stable environment.</p><h2 id="particular-pellicles-2">Particular Pellicles</h2><p>One of the most important advances has been in pellicle technology. These thin membranes protect EUV photomasks (reticles) from contamination, but have long been a bottleneck due to durability and defect issues. ASML itself developed two generations of its reticles, but it appears as though TSMC has managed to outpace them.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1280px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Vu6N9RDjut8Yy6FiGKNSCB" name="Photomask 1.png" alt="Mask" src="https://cdn.mos.cms.futurecdn.net/Vu6N9RDjut8Yy6FiGKNSCB.png" mos="" align="middle" fullscreen="" width="1280" height="720" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Intel)</span></figcaption></figure><p>Back in mid-2024, TSMC reported dramatic improvements of its in-house developed EUV pellicle performance, including a four times longer lifespan, four and a half times more wafer output per pellicle, and an 80x reduction in defects. This likely points to TSMC's full-stack engineering approach that spans materials, mechanics, and fab integration.</p><p>On the materials side, TSMC may have adopted advanced pellicle films such as ultra-thin silicon-based membranes (e.g., <a data-analytics-id="inline-link" href="https://research.ibm.com/publications/fabrication-of-a-full-size-euv-pellicle-based-on-silicon-nitride">SiNx</a>, <a data-analytics-id="inline-link" href="https://pdfs.semanticscholar.org/753d/05ecc56f3f5bd63e942e45418078bb295150.pdf">ZrSi<sub>2</sub></a>) or hybrid multilayers with optimized EUV transmittance, thermal stability, and mechanical strength. These materials withstand EUV radiation, minimize thermal deformation, and reduce outgassing. To further suppress particle adhesion and resist contamination-induced failures, TSMC likely treated the surface with anti-reflective coatings or plasma passivation; however, this is speculation and not officially confirmed.</p><p>There are additional ways to improve the lifespan of pellicles and reduce defects. For example, tighter cleanroom protocols would reduce the chance of particle transfer onto pellicles or reticles. However, TSMC has yet to disclose these methods.</p><h2 id="photomasks-2">Photomasks</h2><p>In addition to pellicles that protect photomasks, TSMC is also refining the photomasks themselves. To meet the A14 node's lithography demands, TSMC improved mask accuracy and defect control to reduce defect density, boost yield, and ultimately increase throughput.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="iHJSp7cXP3UeHRdZqukkZQ" name="intel-ims-photomask-wafer-semiconductor-hero.jpg" alt="Intel" src="https://cdn.mos.cms.futurecdn.net/iHJSp7cXP3UeHRdZqukkZQ.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Intel)</span></figcaption></figure><p>TSMC claims that its engineers had improved CD uniformity, pattern fidelity, and overlay precision for curvilinear features by modifying EUV mask blanks, increasing the resolution of multi-beam writers, and optimizing mask fabrication processes. These steps ensured a more consistent pattern transfer and better alignment across layers.</p><p>Defect control was a major focus, too. TSMC strengthened its pellicle inspection, reticle cleanliness, and developer rinse chemistry to suppress defects like bridging and pattern collapse. TSMC deployed advanced e-beam inspection techniques to detect sub-visible membrane defects and degradation early, enabling predictive maintenance and proactive replacement before catastrophic failures, which improves yields and lowers performance variability.</p><p>In the future, TSMC plans to develop next-generation blank materials and new process flows to support future EUV requirements.</p><h2 id="planarization-2">Planarization</h2><p>Improving photomasks and pellicles are not the only ways to lower defect density, increase yields, and reduce performance variability, particularly for 2nm and sub-2nm-class process technologies, according to TSMC. The company is working to <a data-analytics-id="inline-link" href="https://investor.tsmc.com/sites/ir/annual-report/2024/2024%20Annual%20Report.E.pdf">improve polarization for its A16 and A14 fabrication processes</a>.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="YAQU3zRSbuCHbUYm5L4oD4" name="tsmc-semiconductor-fab-wafer-hero.jpg" alt="TSMC" src="https://cdn.mos.cms.futurecdn.net/YAQU3zRSbuCHbUYm5L4oD4.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>Planarization is crucial in advanced EUV lithography because it ensures a uniformly flat wafer surface, which is critical for maintaining focus and pattern fidelity at sub-2nm nodes like TSMC's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmcs-1-6nm-node-to-be-production-ready-in-late-2026-roadmap-remains-on-track">A16</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmc-unveils-1-4nm-technology-2nd-gen-gaa-transistors-full-node-advantages-coming-in-2028">A14</a>. EUV systems have an extremely shallow depth of focus, which is why any topographical variation could be a source of defocus, CD variation, or LER. Uneven surfaces also lead to non-uniform resist thickness, which affects dose absorption and etch uniformity. Also, overlay errors increase if subsequent layers are patterned on non-planar foundations.</p><p>TSMC likely improves this through advanced chemical mechanical planarization (CMP), optimizing slurry chemistry, pressure profiles, and endpoint detection to achieve tight within-wafer and wafer-to-wafer planarity control.</p><h2 id="energy-efficiency-2">Energy efficiency</h2><p>EUV scanners are known for heavy energy use, and here too TSMC has made progress. It says it reduced power consumption of EUV tools by 24% 'through innovative energy saving techniques.' The company's future target is a 1.5 times improvement in energy efficiency per wafer by 2030.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:64.06%;"><img id="sF5kjc768gySpL2e9YSSqA" name="Engineer-checking-assembly-instructions_48554.jpg" alt="ASML" src="https://cdn.mos.cms.futurecdn.net/sF5kjc768gySpL2e9YSSqA.jpg" mos="" align="middle" fullscreen="" width="2560" height="1640" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: ASML)</span></figcaption></figure><p>Reduction in EUV scanner power consumption was likely achieved through a combination of hardware-level and system-level optimizations, though which optimizations were made has not been disclosed. For example, TSMC could enhance the laser-to-EUV conversion efficiency, where a significant amount of energy is lost. Another key area is thermal management. TSMC likely refined liquid cooling systems, optimized coolant flow rates, and improved heat exchanger design to lower auxiliary power consumption while maintaining thermal stability.</p><p>On the system side of things, firmware and scheduler optimizations may have reduced idle-state energy use and improved synchronization between subsystems, reducing power draw during non-exposure operations. Predictive maintenance and better utilization analytics would help avoid performance degradation from inaccurate positioning, synchronization, or overheating, which prevents inefficient tool operation.</p><h2 id="tsmc-s-position-strengthens-2">TSMC's position strengthens</h2><p>Although TSMC was not the first chipmaker to adopt EUV lithography, it is currently the largest operator of EUV tools in the industry. Since 2019, the company has doubled wafer throughput per tool, reduced scanner power consumption by 24%, and achieved major gains in pellicle performance, including four times the lifespan and 80 times lower defects. To support these advancements, TSMC plans to retrofit a 200 mm fab to manufacture proprietary EUV pellicles that may surpass ASML's own. These efforts reflect TSMC’s broader strategy to control the full EUV stack—from materials to tool optimization.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/how-tsmc-managed-to-increase-efficiency-of-asmls-euv-tools-system-level-optimizations-and-in-house-pellicles-chipmaker-boosted-euv-driven-wafer-production-by-30x-over-six-years-while-reducing-power-consumption-by-24-percent
TSMC has dramatically boosted EUV scanner throughput, pellicle performance, and energy efficiency through deep in-house innovations.
Ei96WAsmMnfG9jHWyhL2vX
Wed, 17 Sep 2025 11:10:06 +0000 Semiconductors
Tech Industry
Manufacturing
ashilov@gmail.com (Anton Shilov)
Anton Shilov
Taiwan Semiconductor Manufacturing Co., Ltd.
TSMC Lobby
TSMC Lobby
<![CDATA[ Latest FSR 4 source code 'leak' lets you run AMD's AI upscaling tech on nearly any GPU — no Linux required ]]>
<p>The latest version of AMD's FidelityFX, typically known as FSR 4, delivers a markedly superior result to FSR 3, making it a big win for those who can run it. But that privileged group is limited to folks with AMD Radeon RX 9000 series GPUs based on the company's RDNA 4 architecture. Or is it? As it turns out, <a data-analytics-id="inline-link" href="https://www.reddit.com/r/radeon/comments/1nhxgd0/fsr_4_working_in_cyberpunk_2077_on_rdna3_7900xtx/" target="_blank">you can actually run FSR 4</a> on nearly any GPU, thanks to AMD itself <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-accidentally-marks-fsr-4-open-source-source-code-reveals-potential-support-for-older-radeon-gpus">leaking the source code</a> last month.</p><p>Strictly speaking, this isn't exactly 'new' news. As far back as June of this year, people were <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/enthusiast-hacks-fsr-4-onto-rx-7000-series-gpu-without-official-amd-support-returns-better-quality-but-slightly-lower-fps-than-fsr-3-1" target="_blank">hacking FSR4 onto last-generation</a> Radeon RX 7000 GPUs, but that trick was fragile and required Linux. Today's method is quite easy and should, in theory, work on virtually any modern GPU in the vast majority of DirectX 12, DirectX 11, and Vulkan games. We'll get to the specifics in a moment, but we should explain exactly what's going on here.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="xZUHUWsCEP2CtHjhdSLuA3" name="fsr4-artifacts" alt="A screenshot of Lizzie's Bar in Cyberpunk 2077." src="https://cdn.mos.cms.futurecdn.net/xZUHUWsCEP2CtHjhdSLuA3.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">Several motion artifacts are visible in this FSR4 screenshot. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware / CDPR)</span></figcaption></figure><p>When AMD open-sourced the FSR SDK, including FSR 4, it <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amds-already-taken-down-mistakenly-released-fsr-4-source-code-but-the-internet-never-forgets-forked-github-repositories-remain-accessible" target="_blank">mistakenly published the full source</a> of FSR 4, not just the SDK portion of it. That meant that anyone could take the FSR 4 code and do whatever they wanted with it, because the source was published under a highly permissive MIT license. Notably, alongside the FP8 version of FSR 4 — that is, the standard version that <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-radeon-rx-9070-xt-review" target="_blank">the Radeon RX 9000 cards</a> normally use — there was also a version built to use the INT8 datatype. INT8 is supported on virtually all modern GPUs, so it is much more compatible.</p><p>That was a source release, so it took some hero to come along and compile the source into a binary form that gamers could actually use. That hero turns out to be /u/AthleteDependent926 on Reddit, who provided the compiled DLL file that users can simply drop into games with FSR 3 support to enable FSR 4.</p><p>It takes a bit of doing; in our testing, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/you-can-upgrade-fsr-3-1-games-to-fsr-4-with-manual-dll-swapping-github-community-discovers-fsr-swapping-works-similar-to-dlss-upgrades" target="_blank">simply swapping the files</a> won't enable FSR 4 the way you might do with DLSS. However, using the OptiScaler mod, you can specifically select FSR 4.0.2 in the mod's UI.</p><p><a data-analytics-id="inline-link" href="https://github.com/optiscaler/OptiScaler" target="_blank">OptiScaler</a> is a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amds-fsr-4-gets-a-big-boost-in-compatibility-as-optiscaler-now-supports-upconverting-any-modern-upscaler-to-fsr-4-with-frame-gen-as-long-as-the-game-isnt-vulkan-based-or-has-anti-cheat" target="_blank">multi-game mod</a> similar to something like ReShade or Special K. Install OptiScaler to the game's executable directory, run the "setup_windows.bat" or "setup_linux.sh" depending on your operating system, and then replace the "amd_fidelityfx_upscaler_dx12.dll" with the one from <a data-analytics-id="inline-link" href="https://www.reddit.com/r/radeon/comments/1nhkkr8/fsr_sdk_leak_contained_fsr_4_files_that_work_on/" target="_blank">/u/AthleteDependent926's Reddit post</a>. After doing so, launch your game, press Insert to open the OptiScaler UI, select "FSR 3.X" as your upscaler, and then in the "FFX Settings," select FSR 4.0.2. It's a little unintuitive, but it absolutely works.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:3840px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Xbsun7xvfQ6v5P5t4yxLKE" name="cyberpunk-2077-fsr4-hack-fsr3-compare" alt="A side-by-side comparison of Cyberpunk 2077 rendered using AMD's FSR3 and FSR4 upscalers." src="https://cdn.mos.cms.futurecdn.net/Xbsun7xvfQ6v5P5t4yxLKE.png" mos="" align="middle" fullscreen="" width="3840" height="2160" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">It's hard to appreciate in a screenshot, but AMD's FSR4 is sharper and less artifact-prone. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware / CDPR)</span></figcaption></figure><p>How do I know? Well, I tested it. First, on a Radeon RX 7800 XT connected to a 4K display, and then on <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-boasts-its-ryzen-ai-max-395-is-up-to-12-2x-faster-than-lunar-lake-in-ai-workloads" target="_blank">a Ryzen AI Max+ 395</a>'s integrated Radeon 8060S connected to a 1440p display. In both cases, performance is a little rough; we saw about 4.1 ms to upscale to 4K on the RX 7800 XT, while the Radeon 8060S takes about 2.3 ms to upscale to 1440p. For those unfamiliar with frame times, 60 FPS equates to a frame time of 16.7 ms. Tacking on an extra 4.1ms for the upscale drops you from 60 to about 48 FPS, but we didn't see that kind of performance from either GPU because we were testing <em>Cyberpunk 2077</em> in RT Ultra mode on Radeon hardware.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:869px;"><p class="vanilla-image-block" style="padding-top:44.42%;"><img id="RhAtg5vhvjTwv2vkiBh3TM" name="fsr4-fsr3-xess-upscalers-performance" alt="Three OptiScaler overlay screenshots showing the performance difference in various upscalers on a Radeon RX 7800 XT." src="https://cdn.mos.cms.futurecdn.net/RhAtg5vhvjTwv2vkiBh3TM.png" mos="" align="middle" fullscreen="" width="869" height="386" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">FSR4 is significantly slower than FSR3, but also offers much better image quality. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Still, performance remained broadly playable on both GPUs, and the final image quality with FSR 4, while decidedly inferior to DLSS 4, is nonetheless an undeniable step up from FSR 3, and in fact also superior to Intel's XeSS—at least, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-xess-technology-demo-and-overview" target="_blank">the DP4a path available to non-Intel GPUs</a>. In <em>Cyberpunk 2077</em>, FSR 4 clearly has fewer artifacts and less aliasing, although it's not flawless; we still saw some trailing on distant objects, and animated textures still throw it for a loop. Only NVIDIA's transformer-based DLSS 4 has resolved those issues.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="DZadCkjLoTnybBf95uq8XV" name="cyberpunk2077-graphics-settings-menu-fsr-30" alt="A screenshot of the graphics options menu in Cyberpunk 2077, showing FSR 3.0 engaged." src="https://cdn.mos.cms.futurecdn.net/DZadCkjLoTnybBf95uq8XV.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">To use FSR 4 with OptiScaler, you'll enable FSR 3 in the game options. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Of course, some of our problems could be down to the fact that this is <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-accidentally-marks-fsr-4-open-source-source-code-reveals-potential-support-for-older-radeon-gpus" target="_blank">a rather hacky way</a> of implementing a fully unsupported upscaler. But regardless, this does seem like a great option to have in the toolbox of Radeon and Arc gamers who don't have access to the latest DLSS models. A great many games have implemented FSR 3 upscaling, and the ability to simply replace that with FSR 4 could be an excellent option if you're already flush with a fine frame rate. Kudos to the enthusiasts and modders who made this trick possible.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/latest-fsr-4-source-code-leak-lets-you-run-amds-ai-upscaling-tech-on-nearly-any-gpu-no-linux-required
As it turns out, with some tweaking, you can actually run FSR 4 on nearly any recent GPU thanks to AMD itself leaking the source code last month.
EtBzqtHyEFibTfT8siuYke
Tue, 16 Sep 2025 17:47:11 +0000 GPUs
PC Components
Zak Killian
AMD
A marketing image for AMD&#039;s FidelityFX Super Resolution
A marketing image for AMD&#039;s FidelityFX Super Resolution
<![CDATA[ Looking Glass demos Hololuminescent Display monitors — sizes range from 16 to 85 inches, starting at $1,500 ]]>
<p>Looking Glass has <a data-analytics-id="inline-link" href="https://lookingglassfactory.com/hld-overview" target="_blank">taken the wraps off</a> its new monitors with Hololuminescent Display (HLD) technology. The firm has been in the holographic displays market for a decade, but it believes its new HLD monitors, which are just 1-inch thick and deliver up to a 4K resolution, can deliver “magical holograms that can be deployed anywhere.” HLD will allow the firm’s immersive light field to be rolled out anywhere standard video screens are used today.</p><div class="youtube-video" data-nosnippet ><div class="video-aspect-box"><iframe data-lazy-priority="low" data-lazy-src="https://www.youtube.com/embed/EtG9O4YGjfw" allowfullscreen></iframe></div></div><p>According to Looking Glass, HLDs “create an immersive three-dimensional stage for all types of content -— without the complexity of traditional 3D pipelines.” They do not need <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/dying-light-eye-tracking-tobii,33473.html">eye tracking technology</a> or special viewing lenses, so they are suitable for viewing by groups. This is a significant quality that could potentially help adoption in traditional digital signage devices.</p><p>For content creators, HLDs are said to work with standard 2D video workflows mixing real-world footage, animation, interactive applications, and AI generation. A demonstration workflow with a green screen, character, and Adobe Premiere Pro is outlined on the HLD <a data-analytics-id="inline-link" href="https://lookingglassfactory.com/how-it-works">How It Works</a> page.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:600px;"><p class="vanilla-image-block" style="padding-top:56.33%;"><img id="BDHhViLYJHQbDgj9hup7Z9" name="HLD_Headphones_1" alt="Looking Glass demos new Hololuminescent Display technology" src="https://cdn.mos.cms.futurecdn.net/BDHhViLYJHQbDgj9hup7Z9.gif" mos="" align="middle" fullscreen="" width="600" height="338" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Looking Glass )</span></figcaption></figure><p>Here's how Looking Glass’ prior Light Field Displays (LFD) compare to these new HLD models.</p><div ><table><thead><tr><th class="firstcol " ><p><strong>Feature</strong></p></th><th
><p><strong>Hololuminescent Displays (HLD)</strong></p></th><th
><p><strong>Light Field Displays (LFD)</strong></p></th></tr></thead><tbody><tr><td class="firstcol " ><p>Content Creation</p></td><td
><p>Standard 2D content pipelines</p></td><td
><p>Specialized 3D software</p></td></tr><tr><td class="firstcol " ><p>Setup Complexity</p></td><td
><p>Easy to intermediate, Plug and Play</p></td><td
><p>Intermediate to advanced 3D software</p></td></tr><tr><td class="firstcol " ><p>Ideal Content</p></td><td
><p>People, products, characters</p></td><td
><p>CAD, medical scans, terrain maps, data visualization</p></td></tr><tr><td class="firstcol " ><p>3D Effect</p></td><td
><p>Fixed holographic stage for holographic depth cues</p></td><td
><p>Multi-view parallax</p></td></tr><tr><td class="firstcol " ><p>Eye Tracking</p></td><td
><p>None</p></td><td
><p>None</p></td></tr><tr><td class="firstcol " ><p>Best For</p></td><td
><p>Digital signage, retail, experiential displays</p></td><td
><p>R&D, medical, engineering, 3D art</p></td></tr><tr><td class="firstcol " ><p>Sizes Available</p></td><td
><p>16”, 27”, 86”</p></td><td
><p>6”, 16”, 27”</p></td></tr></tbody></table></div><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1578px;"><p class="vanilla-image-block" style="padding-top:69.58%;"><img id="5o3t3eR3opjFYSHHsHXVc8" name="HLD-ease-of-use" alt="Looking Glass demos new Hololuminescent Display technology" src="https://cdn.mos.cms.futurecdn.net/5o3t3eR3opjFYSHHsHXVc8.jpg" mos="" link="" align="" fullscreen="" width="1578" height="1098" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Looking Glass )</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="4HAo4qoUA7Si7DTt9ZCRc8" name="HLD-side" alt="Looking Glass demos new Hololuminescent Display technology" src="https://cdn.mos.cms.futurecdn.net/4HAo4qoUA7Si7DTt9ZCRc8.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Looking Glass )</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="cPaVMcfhq4kJiS3QxG9Vc8" name="HLD-hero2" alt="Looking Glass demos new Hololuminescent Display technology" src="https://cdn.mos.cms.futurecdn.net/cPaVMcfhq4kJiS3QxG9Vc8.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Looking Glass )</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Vcx2LYATG6YoBTu9DMsJc8" name="HLD-hero" alt="Looking Glass demos new Hololuminescent Display technology" src="https://cdn.mos.cms.futurecdn.net/Vcx2LYATG6YoBTu9DMsJc8.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Looking Glass )</span></figcaption></figure></div></div></div><p>Looking Glass’s Hololuminescent Displays will be available in Q4, and will start at $1,500 for an FHD 16-inch display (pre-order offer). A 27-inch 4K HLD will ship in November and December of this year, and 86-inch 4K displays will roll out in February 2026, says the firm, but pricing is yet to be disclosed.</p><p>Looking Glass <a data-analytics-id="inline-link" href="https://lookingglassfactory.com/displays-overview" target="_blank">Light Field Displays</a>, for advanced 3D visualization, interaction, and research, will continue to be offered to teams who work in 3D R&D and industrial visualization.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/monitors/looking-glass-demos-hololuminescent-display-monitors-sizes-range-from-16-to-85-inches-starting-at-usd1-500
Looking Glass has taken the wraps off its 'magical' and slim new monitors with Hololuminescent Display (HLD) technology. Models will be available soon, starting from $1,500.
8Ay5ytotN2WBEyh5zMqrY7
Tue, 16 Sep 2025 17:46:18 +0000 Monitors
Mark Tyson
Looking Glass
Looking Glass demos new Hololuminescent Display technology
Looking Glass demos new Hololuminescent Display technology
<![CDATA[ AMD launches four new Ryzen CPUs, including cut-down Zen 4 and Zen 3 models — most only available in global markets ]]>
<p>AMD has quietly released four new Ryzen CPUs without any official acknowledgement beyond adding the specs of each CPU to its website. The new chips are the eight-core Ryzen 7 9700F, six-core Ryzen 5 9500F, six-core Ryzen 5 7400, and six-core Ryzen 5 5600F.</p><p>The Ryzen 7 9700F and Ryzen 5 9500F are new chiplet-style<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-dishes-more-zen-5-details-compact-core-is-25-smaller-than-the-normal-core-new-soc-architecture-disclosed"> Zen 5</a> processors that lack integrated graphics. The 9700F is an eight-core chip featuring 32MB of L3 cache, 65W TDP, 3.8GHz base clock, and 5.5GHz peak boost clock. The 9500F features six Zen 5 CPU cores, 32MB of L3 cache, 65W TDP, a base clock of 3.8 GHz, and a peak boost clock of 5.2 GHz.</p><div ><table><tbody><tr><td class="firstcol empty" ></td><td
><p>Architecture</p></td><td
><p>Cores / Threads</p></td><td
><p>L3 Cache / TDP</p></td><td
><p>Base / Boost Clocks</p></td></tr><tr><td class="firstcol " ><p>Ryzen 7 9700F</p></td><td
><p>Zen 5</p></td><td
><p>8 / 16</p></td><td
><p>32 MB / 65W</p></td><td
><p>3.8 GHz / 5.5 GHz</p></td></tr><tr><td class="firstcol " ><p>Ryzen 5 9500F</p></td><td
><p>Zen 5</p></td><td
><p>6 / 12</p></td><td
><p>32 MB / 65W</p></td><td
><p>3.8 GHz / 5 GHz</p></td></tr><tr><td class="firstcol " ><p>Ryzen 5 7400</p></td><td
><p>Zen 4</p></td><td
><p>6 / 12</p></td><td
><p>16 MB / 65W</p></td><td
><p>3.3 GHz / 4.3 GHz</p></td></tr><tr><td class="firstcol " ><p>Ryzen 5 5600F</p></td><td
><p>Zen 3</p></td><td
><p>6 / 12</p></td><td
><p>32 MB / 65W</p></td><td
><p>3.0 GHz / 4.0 GHz</p></td></tr></tbody></table></div><p>The two chips are essentially F-series versions of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-ryzen-5-9600x-cpu-review">Ryzen 7 9700X </a>and Ryzen 5 9600/9600X that lack integrated graphics. This is especially the case with the 9700F, as it shares the same specs as the 9700X from the cores and cache, all the way down to the base and boost clocks as well. The Ryzen 5 9500F is also very similar to the Ryzen 5 9600/9600X, but both have higher clock speeds, with the 9600 boasting a 200MHz higher clock speed than the 9500F.</p><p>The Ryzen 5 7400 is a new entry-level Zen-4 CPU featuring six cores, 16 MB of L3 cache, 65W TDP, a base clock of 3.3GHz, and a maximum boost clock of 4.3GHz. This CPU is arguably one of the most unorthodox chips to come out from AMD, being one of the very first chips to come out <em>after</em> its F-series counterpart (the<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-silently-introduces-the-ryzen-5-7400f-based-on-raphael-six-zen-4-cores-a-boost-clock-of-4-7-ghz-and-global-availability"> Ryzen 5 7400F </a>has been on the market for several months).</p><p>What's even stranger is the CPU's L3 cache configuration of just 16MB. Traditionally, the 16MB cache limit is targeted at AMD's monolithic APUs, which physically don't hold more than 16 MB of L3 cache. However, the Ryzen 5 7400 is classified with the Raphael codename, meaning it takes advantage of AMD's chiplet-style design, which incorporates 32MB of L3 cache. Apparently, AMD has opted to disable half the L3 cache on this chip, probably as a method of reducing waste on potentially defective Zen 4 dies with defective L3 cache.</p><p>This strange configuration also makes the Ryzen 5 7400 a significantly different processor than its twin-by-name-alone, the Ryzen 5 7400F. While the 7400F lacks integrated graphics, it is a noticeably better processor, boasting a 400MHz higher base clock and boost clock, and 32MB of L3 cache. It could be argued that the Ryzen 5 7400 has more in common with the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/alleged-ryzen-8000g-apu-details-leak-zen-4-zen-4c-and-rdna-3">Ryzen 5 8500G</a>, which has just 16MB of L3 cache, integrated graphics, and six cores, though those cores consist of Zen 4 and<a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/amds-epyc-bergamo-and-zen-4c-detailed-same-as-zen-4-but-denser"> Zen 4c </a>cores.</p><p>The Ryzen 5 5600F is yet another Zen 3 part coming to the market. As the name states, the 5600F is another variant of the 5600/5600X featuring six Zen 3 cores, 32MB of L3 cache, 65W TDP, a 3.5GHz base clock, and a 4.4GHz peak boost clock. This chip is also somewhat unorthodox, sporting the F-series nomenclature. Chips with this nomenclature usually have disabled integrated graphics, but the Ryzen 5000 series does not support integrated graphics at all.</p><p>Apparently, the "F" in this case denotes reduced performance compared to its vanilla counterpart. The Ryzen 5 5600 features a 500MHz higher base clock and 400MHz higher boost clock than the 5600F.</p><p>The new Zen 3 chips are not the only recent re-use of old silicon. Intel has also re-released its <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intels-14nm-desktop-cpus-are-making-a-comeback-chipmaker-inexplicably-resurrects-comet-lake-from-five-years-ago-with-new-core-i5-110">10th Gen Core "Comet Lake"</a> silicon as the Core i5-110 in its Ultra Series 1 line.</p><p>These CPUs, specifically the 7400 and 5600F, continue to demonstrate AMD's commitment to providing as many solutions as possible. The main reason most of the more unorthodox chips exist is for global markets, particularly Asia or Latin America (like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-quietly-launches-a-budget-gaming-beast-ryzen-5-5500x3d-arrives-for-the-latin-american-market">Ryzen 5 5500X3D</a>). The Ryzen 5 7400F is regionally exclusive to China and other Asian markets, the Ryzen 5 5600F is locked to the Asia-Pacific / Japan region, and the Ryzen 7 9700F is locked to North America. The Ryzen 5 9500F is the only chip of the bunch that boasts regional availability.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/cpus/amd-launches-four-new-ryzen-cpus-including-cutdown-zen-4-and-zen-3-models-most-only-available-in-global-markets
AMD has quietly released four new CPUs on three different architectures featuring the Ryzen 7 9700F, Ryzen 5 9500F, Ryzen 5 7400, and Ryzen 5 5600F.
p56z4iiRX8fFLAY3xUTgXG
Tue, 16 Sep 2025 17:25:38 +0000 CPUs
PC Components
editors@tomshardware.com (Aaron Klotz)
Aaron Klotz
AMD
Ryzen 9000
Ryzen 9000
<![CDATA[ Gearbox CEO channels inner Claptrap, offers himself up as personal tech support over rampant Borderlands 4 PC performance issues — 'Would you like help tuning with your personal specification?' ]]>
<p>In the weekend and change since its launch, Borderlands 4 has quickly become notorious as a PC resource hog the likes of which we have never seen before. Now, after days of personally crusading against complaints of poor optimization and performance issues, Gearbox CEO Randy Pitchford has taken to offering personal tech support to players struggling for performance.</p><p>After early reports at the weekend that <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/borderlands-4-launch-marred-by-performance-issues">Borderlands 4 was crushing even the most powerful PCs</a> — the 5090 can't manage native 60fps in some scenarios — publisher 2K put out an <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/pc-gaming/is-borderlands-4-the-new-crysis-official-gpu-setting-recommendations-peg-4k-performance-with-the-rtx-5090-at-60-fps-with-dlss-and-frame-generation-enabled">extensive list of recommended graphics settings for a variety of resolutions on both AMD and Nvidia cards</a>.</p><p>Pitchford's own contribution has been decidedly more controversial. "Every PC gamer must accept the reality of the relationship between their hardware and what the software they are running is doing," he posted on Monday in an X post, which received so much backlash that it got a community note.</p><div class="see-more see-more--clipped"><blockquote class="twitter-tweet hawk-ignore" data-lang="en"><p lang="en" dir="ltr">Every PC gamer must accept the reality of the relationship between their hardware and what the software they are running is doing.<a href="https://twitter.com/cantworkitout/status/1967424826697781446">September 15, 2025</a></p></blockquote><div class="see-more__filter"></div></div><p>In his less philosophical tweets, Pitchford has insisted that many of the Borderlands 4 players experiencing performance issues are simply demanding too much of their hardware, and that many would benefit from turning down the resolution or dialling up frame generation tech like DLSS. However, that hasn't stopped him from moving to offering personal tech support to people struggling.</p><p>"Would you like help tuning with your personal specification?," he asked one user with an RTX 5080 in a tone that will be all too familiar to fans of the franchise. "You should be in good shape," he replied. "Run on that 1440p monitor.
Recommend two inputs into that G8 so you're running it split screen. What FPS are you getting? Vsync off. Disable anti-aliasing. Use DLSS. Multi-frame generation at 4x. nVIDIA Reflex: On. Match your frame rate limiter to your monitor's refresh rate.
You can set everything to very high (but you can gain some more frames if you turn down or off the volumetric fog). Let me know what FPS you get with those settings."</p><p>"At 1440p you should be blazing fast," he continued. Pitchford has responded to plenty of comments about the game's poor performance and optimization with offers of personal tech support, not all of them landing well. "You are being unbelievably insufferable, Randy," one user retorted to his offer. "I'm trying to be helpful," the beleaguered CEO replied, before asking: "What do you think would be helpful? What would you have me do?"</p><p>Pitchford's messaging is certainly more than a little mixed and likely not helping the reception to the game. On the one hand, he has insisted the game is built well and that users are demanding too much of their hardware. On the other hand, Gearbox has pushed out a couple of PC performance patches, and the CEO says they are continuing work <a data-analytics-id="inline-link" href="https://x.com/DuvalMagic/status/1967835152861798890" target="_blank">behind the scenes.</a> Fans of the tenured looter shooter would be remiss not to admit that there's more than a little hint of the desperation that made its one-wheeled protagonist Claptrap an infamous mainstay of the series in his posts.</p><p>Borderlands 4 is the latest installment in Gearbox's popular looter shooter franchise, and in many ways is a hefty departure from previous games. It eschews the setting of homeworld Pandora for the first time, pitting players into a fight for liberation from the Timekeeper, the overlord of the planet Kairos.</p><p>Performance issues aside, fans can expect a return of many of Borderlands' most popular mechanics, including randomly generated loot, humorous dialogue, and prolific violence.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/video-games/pc-gaming/gearbox-ceo-channels-inner-claptrap-offers-himself-up-as-personal-tech-support-over-rampant-borderlands-4-pc-performance-issues-would-you-like-help-tuning-with-your-personal-specification
Gearbox CEO Randy Pitchford has taken to X in a bit to offer personal tech support to Borderlands 4 players struggling for PC performance.
HiKEBAcX9FxsafmfHCJK4R
Tue, 16 Sep 2025 17:17:33 +0000 PC Gaming
Video Games
stephen.warwick@futurenet.com (Stephen Warwick)
Stephen Warwick
Gearbox
Borderlands 4
Borderlands 4
<![CDATA[ Corsair launches gargantuan 3,000W power supply for $599.99 — comes with four native 12V‑2x6 600W GPU cables ]]>
<p>Corsair has introduced the brand's first power supply exceeding 1,600W. The latest WS3000, featuring a capacity of 3,000W and 80 Plus Platinum-certified, is engineered to support systems and workstations equipped with multi-GPU configurations.</p><p>With dimensions measuring 6.9 x 5.9 x 3.4 inches (175 x 150 x 86 mm), the WS3000 constitutes a standard ATX 3.1 power supply that adheres to the PCIe 5.1 specification. Its length of 6.9 inches positions the WS3000 as potentially one of the most compact 3,000W power supplies available, facilitating installation within even conventional ATX cases. Like many contemporary high-end units, the WS3000 is equipped with a modular design, thus simplifying cable management.</p><p>The WS3000 boasts a power capacity of 3,000W and features a single-rail design. This configuration indicates that the power supply provides up to 250A on the +12V rail. It is essential to note that the WS3000 is designed for 220-240V operation; therefore, it is imperative to ensure that your residence is wired for 240V and has a circuit that complies with the specifications. Consequently, the WS3000 employs a C19 power cable, which has a physically larger connector and is rated for a higher current (16A compared to 10A), as opposed to the standard C13 power cable used with typical power supplies.</p><p>The WS3000 is not the first or only Corsair power supply to utilize the C19 power cable. Numerous high-capacity units from the brand, such as the HX1500i and AX1600i, have already employed the C19 power cable.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="FbZr6QT8GeZMHSAzGAv8QN" name="WS3000_BLACK_05_PERSP_REAR.width-540.format-webp" alt="Corsair WS3000" src="https://cdn.mos.cms.futurecdn.net/FbZr6QT8GeZMHSAzGAv8QN.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Corsair)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1955px;"><p class="vanilla-image-block" style="padding-top:56.27%;"><img id="5tfdkzyAmm2muRiQAcj3SN" name="ws3000_01" alt="Corsair WS3000" src="https://cdn.mos.cms.futurecdn.net/5tfdkzyAmm2muRiQAcj3SN.jpg" mos="" link="" align="" fullscreen="" width="1955" height="1100" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Corsair)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.30%;"><img id="JBHYWEJzjx62MwHVzeAcRN" name="WS3000_BLACK_04_PORTS.width-540.format-webp" alt="Corsair WS3000" src="https://cdn.mos.cms.futurecdn.net/JBHYWEJzjx62MwHVzeAcRN.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1081" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Corsair)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="e9o3k8wN8EETjenJSANwQN" name="WS3000_BLACK_13_CABLES.width-1000.format-webp" alt="Corsair WS3000" src="https://cdn.mos.cms.futurecdn.net/e9o3k8wN8EETjenJSANwQN.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Corsair)</span></figcaption></figure></div></div></div><p>The WS3000 leverages a 140mm double-ball-bearing fan for active cooling. However, it does not have the Zero RPM mode found in consumer models. This is because Corsair considers noise reduction a lower priority for the WS3000's use case. Additionally, it does not support iCUE, so you won't be able to monitor or control the WS3000 through Corsair's software.</p><p>Designed to support multi-GPU configurations, the WS3000 is equipped with four native <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/16-pin-power-connector-gets-a-much-needed-revision-meet-the-new-12v-2x6-connector" target="_blank">12V-2x6 </a>power cables, specifically designed for contemporary graphics cards that utilize the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/pcie-5-power-connector-600w-next-gen-amd-nvidia-gpus">12VHPWR</a> power connector. Furthermore, the power supply provides four dual 8-pin PCIe power cables, totaling eight 8-pin PCIe power connectors. Additionally, it includes two 8-pin EPS power connectors intended for high-end or workstation motherboards with power-hungry processors.</p><p>Corsair backs the WS3000 (CP-9020312-NA) with a limited ten-year warranty. The power supply has an MSRP of $599.99; however, we've seen it listed at Central Computer, a U.S. retailer, for <a data-analytics-id="inline-link" href="https://www.centralcomputer.com/corsair-cp-9020312-na-ws3000-3000w-atx-3-1-fully-modular-workstation-power-supply-atx-3-1-80-plus-platinum-certified.html">$549.99,</a> so it's possible to acquire the power supply for below MSRP.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/power-supplies/corsair-launches-gargantuan-3-000w-power-supply-for-usd599-99-comes-with-four-native-12v-2x6-600w-gpu-cables
Corsair launches WS3000, a power supply with a 3,000W capacity for systems with multi-GPU setups.
hwCe3u47JJFicfNJqiJUgA
Tue, 16 Sep 2025 16:57:52 +0000 Power Supplies
PC Components
Zhiye Liu
Corsair
Corsair WS3000
Corsair WS3000
<![CDATA[ Japan to subsidize undersea cable vessels over 'very serious' national security concerns — will front up to half the cost for $300 million vessels bought by NEC ]]>
<p>Japanese officials are set to offer subsidies to NEC, one of the country's biggest tech companies, to purchase cable-laying ships capable of traversing oceans. According to the <a data-analytics-id="inline-link" href="https://www.ft.com/content/8bf18101-4afa-4110-aad8-66fc76c4c70a" target="_blank"><em>Financial Times</em></a>, Tokyo is willing to cover as much as half of the acquisition cost of these vessels. With each ship estimated to cost around $300 million, Japan is seemingly ready to spend half a billion dollars or more to allow NEC to have unfettered access to its own cable-laying vessels, a matter the government now considers of vital importance to national security.</p><p>NEC is one of the largest layers of undersea cables and the biggest one in Asia, having already installed over 400,000 km globally. It currently competes with US-based SubCom, the French government-owned Alcatel Submarine Networks, and China’s HMN Tech. All of these companies have their own fleets, with each of them owning between two and seven vessels. On the other hand, NEC does not own any cable-laying ships and instead leases them from other operators.</p><p>The company currently rents a subsea cable-laying vessel from a Norwegian corporation, with the charter expected to expire next year. Aside from that, it would contract various specialist ships as needed to serve its needs, especially as demand for undersea cables increases within the Indo-Pacific region. The company also occasionally rents smaller cable-laying vessels from Japanese companies NTT and KDDI, but they’re not equipped for traversing oceanic routes and can only work within regional waters.</p><p>Undersea cables are crucial for connecting countries to the rest of the world, and adversaries have increasingly been attacking and sabotaging this relatively unprotected infrastructure. Their placement in international waters means that their destruction isn’t automatically an overt act of war, and the responsible vessels often have murky ownership, making deniability easy. It could also often be chalked up as an accident, so prosecuting offending ships and crews is difficult, if not politically sensitive.</p><p>It has gotten to the point that the Taiwanese Coast Guard is <a data-analytics-id="inline-link" href="https://www.tomshardware.com/networking/taiwan-increases-undersea-cable-protection-patrols-closely-monitoring-96-blacklisted-china-linked-boats">conducting patrols to protect the 24 undersea cables connecting the island</a> to the rest of the world. This came within a year after several high-profile incidents of cuts to undersea internet cables were reported across the globe, starting with a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/two-undersea-internet-cables-connecting-finland-and-sweden-to-europe-have-been-cut-eu-leaders-suspect-sabotage">disruption between Finland and Sweden in November 2024</a>, followed by <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/undersea-power-cable-connecting-finland-and-estonia-experiences-outage-capacity-reduced-to-35-percent-as-finnish-authorities-investigate">outages between Finland and Estonia in December</a>. Then, in January, a Chinese freighter was suspected of <a data-analytics-id="inline-link" href="https://www.tomshardware.com/networking/chinese-freighter-suspected-of-damaging-undersea-internet-cable-connecting-the-us-and-taiwan">damaging an internet cable that links the U.S. and Taiwan</a>, with another ship suspected of <a data-analytics-id="inline-link" href="https://www.tomshardware.com/networking/taiwanese-authorities-detain-fishy-chinese-freighter-suspected-of-cutting-undersea-internet-cable">cutting another cable the following month</a>.</p><p>Because of these incidents, the Japanese government thought that it would be better for NEC to have its own ships. That way, it does not have to rely on charters and rentals, which can bottleneck its operations and prevent it from responding as quickly as possible to cable-laying and cable-repair operations, the report cites officials who say the current lack of ships is a national security risk. "The Japanese government thinks this situation is very serious, so we are thinking we need to make some intervention," one official told <em>FT</em>.</p><p>Nevertheless, NEC purchasing its own vessels, even at subsidized cost, is still a hefty outlay for the company. “Owning a vessel is a huge fixed cost — that’s all well when the market is growing, but when the tech bubble bursts like it did in 2000, then it becomes simply a big cost,” NEC Senior Director for the Submarine Network Division Takahisa Ohta told the <em>Financial Times.</em> “Thankfully, the market is booming now, so one option is to acquire our own ship, and it’s something we’re considering.”</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/networking/japan-to-subsidize-undersea-cable-vessels-over-very-serious-national-security-concerns-will-front-up-to-half-the-cost-for-usd300-million-vessels-bought-by-nec
Japan wants NEC to buy its own undersea cable-laying ships and is considering covering nearly half the purchase cost of these vessels.
PGSEW7ekd7mZ4s374hymu3
Tue, 16 Sep 2025 15:31:32 +0000 Networking
editors@tomshardware.com (Jowi Morales)
Jowi Morales
Shutterstock
Undersea cable vessel
Undersea cable vessel
<![CDATA[ Asus' dual-mode 32-inch dual-mode gaming monitor is on sale for just $500 — 4K and refresh rates up to 320 Hz for $100 off ]]>
<p>Asus is one of the most reliable names when it comes to computer hardware and peripherals. They make excellent gaming monitors, and today's deal is no exception. If you've been looking to get a high refresh rate monitor without sacrificing on sharpness, <a data-analytics-id="inline-link" href="https://www.amazon.com/ASUS-Strix-Gaming-Monitor-XG32UCG/dp/B0F23BB8TW" target="_blank">Asus' XG32UCG is on sale for just $500</a> on Amazon. This is a 4K 32" dual-mode monitor that has a native refresh rate of 160 Hz, which doubles to 320 Hz when you select the FHD (1080p) mode. It usually retails for more, but you can avail a $100 discount right now and snag a great deal.</p><ul><li><a href="https://www.amazon.com/s?k=4k+gaming+monitor&i=electronics&crid=6AQS6C8BGPKR&sprefix=4k+gaming+monito%2Celectronics%2C327" target="_blank">Check out 4K gaming monitors on Amazon</a></li></ul><div class="product star-deal"><a data-dimension112="4bc04008-5581-4d94-9974-8d731d86ffba" data-action="Star Deal Block" data-label="Enjoy the best of both worlds with this dual-mode monitor that can refresh your games at up to 320 times a second at 1080p, or 160 times at 4K. With excellent build quality, customary RGB lighting, and solid connectivity, the XG32UCG is a great gaming monitor that's now available at a matching great price." data-dimension48="Enjoy the best of both worlds with this dual-mode monitor that can refresh your games at up to 320 times a second at 1080p, or 160 times at 4K. With excellent build quality, customary RGB lighting, and solid connectivity, the XG32UCG is a great gaming monitor that's now available at a matching great price." data-dimension25="$499" href="https://www.amazon.com/ASUS-Strix-Gaming-Monitor-XG32UCG/dp/B0F23BB8TW" target="_blank" rel="nofollow"><figure class="van-image-figure "
><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1280px;"><p class="vanilla-image-block" style="padding-top:85.94%;"><img id="nUkXoFxtLjfkpGYtDZkUCF" name="145507" caption="" alt="" src="https://cdn.mos.cms.futurecdn.net/nUkXoFxtLjfkpGYtDZkUCF.webp" mos="" align="middle" fullscreen="" width="1280" height="1100" attribution="" endorsement="" credit="" class=""></p></div></div></figure></a><div><span class="product__star-deal-label">Dual-Mode</span><p>Enjoy the best of both worlds with this dual-mode monitor that can refresh your games at up to 320 times a second at 1080p, or 160 times at 4K. With excellent build quality, customary RGB lighting, and solid connectivity, the XG32UCG is a great gaming monitor that's now available at a matching great price.<a class="view-deal button" href="https://www.amazon.com/ASUS-Strix-Gaming-Monitor-XG32UCG/dp/B0F23BB8TW" target="_blank" rel="nofollow" data-dimension112="4bc04008-5581-4d94-9974-8d731d86ffba" data-action="Star Deal Block" data-label="Enjoy the best of both worlds with this dual-mode monitor that can refresh your games at up to 320 times a second at 1080p, or 160 times at 4K. With excellent build quality, customary RGB lighting, and solid connectivity, the XG32UCG is a great gaming monitor that's now available at a matching great price." data-dimension48="Enjoy the best of both worlds with this dual-mode monitor that can refresh your games at up to 320 times a second at 1080p, or 160 times at 4K. With excellent build quality, customary RGB lighting, and solid connectivity, the XG32UCG is a great gaming monitor that's now available at a matching great price." data-dimension25="$499">View Deal</a></p></div></div><p>The XG32UCG uses a Fast IPS panel that has a 0.3ms (claimed) response time. It also supports G-Sync and AMD's FreeSync. Moreover, it features ELMB-Sync, a rare feature that allows backlight strobing to work with VRR by synchronizing both. That means no weird ghosting or flickering amid fluctuating frame rates. Of course, the hallmark feature here is the dual-mode support, which can be toggled with a simple hotkey button, allowing you to prioritize visual clarity (4K 160Hz) or smoothness (1080p 320Hz) at will.</p><p>Despite lacking local dimming, there's support for HDR400 here, but don't expect striking contrast or blinding brightness since this is not OLED or Mini-LED. Still, you do get 95% coverage of the DCI-P3 color gamut, along with 130% coverage of sRGB. There's plenty of ports onboard too, including DisplayPort 1.4, HDMI 2.1, USB-C with 15W power delivery, and a headphone jack.</p><p>Another highlight of this monitor is the DisplayWidget Center app that allows you to control the OSD right inside Windows, eliminating the need to reach for physical buttons. Asus also markets a few AI features, such as "Dynamic Crosshair" and "Dynamic Shadow Boos,t" but even without these, the XG32UCG is a great all-rounder, made even better at its discounted price.</p><p><em>If you're looking for more savings, check out our </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-deals-on-tech"><em>Best PC Hardware deals</em></a><em> for a range of products, or dive deeper into our specialized </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/features/best-deals-on-ssds"><em>SSD and Storage Deals,</em></a><em> </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/best-hard-drive-deals"><em>Hard Drive Deals</em></a><em>, </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-computer-monitor-deals"><em>Gaming Monitor Deals</em></a><em>, </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-graphics-card-deals-now"><em>Graphics Card Deals</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/features/best-cpu-deals"><em>CPU Deals</em></a><em> pages.</em></p>
https://www.tomshardware.com/pc-components/asus-dual-mode-32-inch-dual-mode-gaming-monitor-is-on-sale-for-just-usd500-4k-and-refresh-rates-up-to-320-hz-for-usd100-off
If you're looking for a monitor that's both sharp and fast, Asus has got you covered with its XG32UCG. This dual-mode gaming monitor can display the best visuals at 4K 160Hz—which is plenty fast already—or give you a genuine competitive edge at 1080p 320Hz. Get it for a discounted price of just $500 now.
ipGm4ce3AmCDe4HRTE5Zoe
Tue, 16 Sep 2025 15:03:43 +0000 PC Components
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
Asus / Future
Asus ROG Strix XG32UCG gaming monitor on sale
Asus ROG Strix XG32UCG gaming monitor on sale
<![CDATA[ Norbauer's $8,000 keyboard waitlist climbs to 9 months — the world's most expensive keyboard is perpetually out of stock ]]>
<p>The self-proclaimed “keyboard dream from the future,” the Norbauer Seneca mechanical keyboard, is one of the most expensive production input devices we have seen. Despite its sky-high price range, spanning $3,600 to $8,090 plus extras, the Seneca is currently out of stock. Moreover, the wait list is a luxury sports car-esque six to nine months, according to the <a data-analytics-id="inline-link" href="https://www.norbauer.co/products/the-seneca?s=31" target="_blank">official site</a>.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:63.13%;"><img id="VZaaiyW3PcpWXqnVhSokBN" name="seneca-main" alt="Norbauer Seneca First Edition" src="https://cdn.mos.cms.futurecdn.net/VZaaiyW3PcpWXqnVhSokBN.jpg" mos="" link="" align="" fullscreen="" width="1600" height="1010" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.norbauer.co/products/the-seneca?s=31" target="_blank">Norbauer</a>)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="7VdghzCdgKyKWC4UDMjhDN" name="titanium-finish" alt="Norbauer Seneca First Edition" src="https://cdn.mos.cms.futurecdn.net/7VdghzCdgKyKWC4UDMjhDN.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.norbauer.co/products/the-seneca?s=31" target="_blank">Norbauer</a>)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="YqQyWndfPdre7bNMRLtvBN" name="assembled" alt="Norbauer Seneca First Edition" src="https://cdn.mos.cms.futurecdn.net/YqQyWndfPdre7bNMRLtvBN.jpg" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.norbauer.co/products/the-seneca?s=31" target="_blank">Norbauer</a>)</span></figcaption></figure></div></div></div><p>We first <a data-analytics-id="inline-link" href="Norbauer’s">reported on the Seneca</a> back in May 2024, ahead of the First Edition’s touted release schedule. At that time, we summed up this premium keyboard’s design as offering a retro-futuristic electro-capacitive keyboard with purportedly silent stabilizers – at a price. We also deep dived into Ryan Norbauer’s quest to optimize key stabilizers, without any trade-offs. And, of course, we stared slack-jawed at the cost of this thing. Who would have guessed that Norbauer & Co. would end up not being able to keep up with the pace of demand?</p><div class="youtube-video" data-nosnippet ><div class="video-aspect-box"><iframe data-lazy-priority="low" data-lazy-src="https://www.youtube.com/embed/N3FEv1qw4_w" allowfullscreen></iframe></div></div><p><em>Above: Adam Savage of MythBusters fame recently interviewed Ryan Norbauer.</em></p><p>So, to help fill the time while you wait for your Seneca order to be fulfilled, let’s take a look at what your (potentially) high-four-figure outlay gets you. In addition to the underlying keyswitch and stabilizer tech, which is a signature feature of the Seneca, Norbauer doesn’t shy away from the use of premium materials and manufacturing methods.</p><p>There are four finish options for the First Edition TKL keyboard, and they are all based on a metal chassis. Three aluminum finishes are available, and these are Oxide Gray, Travertine, and Heatshield. They all look matte and are fingerprint-resistant, providing a solid case for the keyboard mechanism. If you want to push the boat out further, there’s also a raw, uncoated titanium chassis option, with a sandblasted surface.</p><p>For keycaps, Norbauer has looked to the aesthetics of the first personal computers, with a slightly sculpted finish, which is also known as MTNU. The material of choice is double-shot PBT, as used on many of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/peripherals/gaming-keyboards/best-gaming-keyboards">best mechanical keyboards</a> we see in our test labs.</p><p>All these material choices and refinements sound appealing, but even at this astronomical price, there seem to be some compromises that might mean the money-is-no-object Norbauer Seneca isn’t for you.</p><h2 id="missing-features-2">Missing features</h2><p>Let’s start by considering whether you might like to tilt the keyboard forward a little. Would you type more comfortably by increasing the keyboard rake? Norbauer eschews adjustable feet built into the keyboard, and instead offers a “beautiful teak wood” riser that slots under the keyboard, adding a 3° incline and $290. It is claimed this sliver of wood is "precision CNC machined in South Africa." In terms of woodcraft, CNC may be accurate, but it isn't a premium production method (hello IKEA). Norbauer's keyboard riser is basically a kitchen chopping board with an incline.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="7ynbreeC8ePFQLFQzGqHBN" name="290-dollars" alt="Norbauer Seneca First Edition" src="https://cdn.mos.cms.futurecdn.net/7ynbreeC8ePFQLFQzGqHBN.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.norbauer.co/products/the-seneca?s=31" target="_blank">Norbauer</a>)</span></figcaption></figure><p>We also need to consider several modern comforts that the Norbauer Seneca is missing. Many are accustomed to keyboards with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-wireless-keyboards">wireless connectivity options</a>, some level of key backlighting, and additional media keys and knobs for quick and intuitive adjustments. The Seneca doesn’t offer any of these common frills. Also, numpad lovers will be steering clear of this input device.</p><p>Before we go, considering the price and lack of features that some modern computer users might find essential, it might be tempting to assume Norbauer is purposely slow in its production process. The less cynical might suggest this is to ensure consistency and quality, but others may conclude it is a tactic to develop the panache of artificial scarcity.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/peripherals/mechanical-keyboards/norbauers-usd8-000-keyboard-waitlist-climbs-to-9-months-the-worlds-most-expensive-keyboard-is-perpetually-out-of-stock
The premium Norbauer Seneca mechanical keyboard is one of the most expensive input devices we have seen. Despite its sky-high price range, spanning $3,600 to $8,090 plus extras, device buyers face up to a nine-month wait.
ErWaCEQrXG3R9ALpzWG7nF
Tue, 16 Sep 2025 14:24:25 +0000 Mechanical Keyboards
Peripherals
Keyboards
Mark Tyson
Norbauer
Norbauer Seneca First Edition
Norbauer Seneca First Edition
<![CDATA[ Here's how I multi-task in the Linux terminal with Tmux ]]>
<p>Linux users, new and old, have all hit this issue at some point in their careers: We’ve got a terminal session open and it's doing some long and incredibly important task, but we need to do something else. So we just open another terminal, right? Sure, you can do that, even over SSH, but there is a smarter way to do it, and that involves Tmux (Terminal Multiplexer).</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:977px;"><p class="vanilla-image-block" style="padding-top:52.81%;"><img id="aL5DyLjBpaE49MjqAsXe9S" name="detach-attach" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/aL5DyLjBpaE49MjqAsXe9S.gif" mos="" align="middle" fullscreen="" width="977" height="516" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Tmux is a tool that enables you to run, manage, and organize many terminal sessions from one terminal window. We can detach from a running session, leaving it to perform a long task. For example, I am migrating lots of photos from one drive to another on my <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/live/3d-printed-media-server" target="_blank"><u>3D printed server</u></a>. So I am using Tmux to run the copy session, then detaching so that I can log off my PC / sleep / not break the copy process.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:507px;"><p class="vanilla-image-block" style="padding-top:40.43%;"><img id="VHCettDneYTxxbUHUN57pQ" name="tmux-rep" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/VHCettDneYTxxbUHUN57pQ.jpg" mos="" align="middle" fullscreen="" width="507" height="205" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>Tmux uses a Session >> Window >> Pane process to provide a workspace (Session) in which we can have multiple terminal tabs open (Windows), and those windows can be further split into subdivided regions (Panes).</p><p>So how do you get started with Tmux, and what can you do with it?</p><h2 id="creating-your-first-tmux-session-2">Creating Your First Tmux Session</h2><p>In this first section, we will create a Tmux session in which we can work. But before we can use Tmux, we need to install it.</p><p>1. <strong>Open a terminal and update your software repositories, and then install Tmux.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>sudo apt update && sudo apt install tmux</code></pre><p>2. <strong>Run the Tmux command to start a new named session called Test_Session.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux new -s Test_Session</code></pre><p>3. <strong>Use a sleep command to force the terminal to pause for 30 seconds.</strong> We’ll use this command to tie up the Tmux session, simulating it doing a complex, time-consuming task.</p><pre class="line-numbers language-bash" language="bash" ><code>sleep 30</code></pre><p>4. <strong>Press CTRL + B and then d to detach from the session. </strong>You will return to the original terminal window.</p><p>5. <strong>Attach back to the Tmux session.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux attach -t Test_Session</code></pre><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1498px;"><p class="vanilla-image-block" style="padding-top:53.54%;"><img id="Z39FMhkv4xJUhiswovtBKR" name="detach-attach-step" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/Z39FMhkv4xJUhiswovtBKR.gif" mos="" align="middle" fullscreen="" width="1498" height="802" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>6. <strong>Detach from the session by pressing CTRL + B and then d</strong></p><p>7. Create another session called Another_Session. We should now have two sessions running, one we are attached to (Another_Session) and the previous session (Test_Session)</p><pre class="line-numbers language-bash" language="bash" ><code>tmux new -s Another_Session</code></pre><p>8. <strong>List all of the sessions. The attached (current active) session is clearly identified.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux ls</code></pre><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:599px;"><p class="vanilla-image-block" style="padding-top:18.36%;"><img id="FPL9jYeBEQDqo35SGtUZzQ" name="tmux ls" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/FPL9jYeBEQDqo35SGtUZzQ.jpg" mos="" align="middle" fullscreen="" width="599" height="110" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>9. <strong>Switch to the original Test_Session.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux switch -t Test_Session</code></pre><p>10. <strong>List the sessions and you will see that the attached session is now Test_Session.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux ls</code></pre><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:635px;"><p class="vanilla-image-block" style="padding-top:18.74%;"><img id="kiprQESTS8wbwZWeXoCP9R" name="tmux ls attach" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/kiprQESTS8wbwZWeXoCP9R.jpg" mos="" align="middle" fullscreen="" width="635" height="119" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>11. <strong>Kill Another_Session.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux kill-session -t Another_Session</code></pre><div ><table><caption>Tmux Session Cheatsheet</caption><thead><tr><th class="firstcol " ><p>Command</p></th><th
><p>Description</p></th><th
><p>Example</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>tmux</p></td><td
><p>Starts a new Tmux session.</p></td><td
><p>tmux</p></td></tr><tr><td class="firstcol " ><p>tmux new -s name</p></td><td
><p>Starts a new named Tmux session.</p></td><td
><p>tmux new -s File_Copy</p></td></tr><tr><td class="firstcol " ><p>tmux ls</p></td><td
><p>List all of the Tmux sessions.</p></td><td
><p>tmux ls</p></td></tr><tr><td class="firstcol " ><p>tmux detach</p></td><td
><p>Detach from the current session. You can also press CTRL + B and then press D to detach.</p></td><td
><p>tmux detach</p></td></tr><tr><td class="firstcol " ><p>tmux attach -t name</p></td><td
><p>Attach to a running session.</p></td><td
><p>tmux attach -t File_Copy</p></td></tr><tr><td class="firstcol " ><p>tmux switch -t name</p></td><td
><p>Switch to another running Tmux session.</p></td><td
><p>tmux switch -t Resources</p></td></tr><tr><td class="firstcol " ><p>tmux kill-session -t name</p></td><td
><p>Kill a named session.</p></td><td
><p>tmux kill-session -t File_Copy</p></td></tr></tbody></table></div><h2 id="using-tmux-windows-2">Using Tmux Windows</h2><p>Each Tmux window is essentially its own shell, and we can use them to switch between tasks in our overall Tmux session. For example, we could have one window for a long-running session, and another for checking logs.</p><p>Let's start using Windows in our Tmux session.</p><p><br>1. <strong>Attach back to the Tmux session. If it has been killed, use Step 2 in the Session section to re-create it.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux attach -t Test_Session</code></pre><p>2. <strong>Press CTRL + B and then c to create a new Window.</strong> The name of the new Window is the same as the first, bash.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1486px;"><p class="vanilla-image-block" style="padding-top:53.23%;"><img id="og3X7T6GXMbQrYthed9GGR" name="win1" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/og3X7T6GXMbQrYthed9GGR.jpg" mos="" align="middle" fullscreen="" width="1486" height="791" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>3. <strong>Rename the current window to Logs by pressing CTRL + B and then Press Enter when the filename has been changed.</strong> Note that the bottom left Window list has now been updated to show the new name.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="KZZBS5adyQs7VcU56ToDJR" name="win-rename" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/KZZBS5adyQs7VcU56ToDJR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>4. <strong>List all of the Windows by pressing CTRL + B then w. We can select any window using the arrow keys, press Enter to change to that window.</strong> Alternatively you can cycle through the windows by pressing CTRL + B and n (next window) or p for the previous.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="XUeGE9DquoeYSwQEZZUuCR" name="win-list" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/XUeGE9DquoeYSwQEZZUuCR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>5. <strong>Close the current window by pressing CTRL + B and then &.</strong> Here I am closing the Logs window as I no longer require it.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="JTodqZ83R3z4K2jycyvh9R" name="win-kill" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/JTodqZ83R3z4K2jycyvh9R.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><div ><table><caption>Tmux Window Management Cheatsheet</caption><thead><tr><th class="firstcol " ><p>Key combination</p></th><th
><p>Description</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>CTRL + B then press c</p></td><td
><p>Create a new window.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press ,</p></td><td
><p>Rename the current window.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press w</p></td><td
><p>List windows, use arrow keys and Enter to select.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press n</p></td><td
><p>Next window.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press p</p></td><td
><p>Previous window.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press &</p></td><td
><p>Close the current window.</p></td></tr></tbody></table></div><h2 id="using-tmux-panes-to-split-windows-2">Using Tmux Panes to split Windows</h2><p>We can split any window into multiple panes. So if we need to keep an eye on some logs while doing other terminal work, we can!</p><p>1. <strong>Attach back to the Tmux session. If it has been killed, use Step 2 in the Session section to re-create it.</strong></p><pre class="line-numbers language-bash" language="bash" ><code>tmux attach -t Test_Session</code></pre><p>2. <strong>Press CTRL + B then % to split the window vertically</strong>, giving us two equally sized columns.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="n5b5MY74i8YFo5DdNocHHR" name="pane-split-v" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/n5b5MY74i8YFo5DdNocHHR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>3. <strong>Press CTRL + B then “ to split the current pane horizontally. This could be useful for a long command where you need to keep an eye on the output. An rsync file transfer for example.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="49e5Fvod5ZDr3F7QDRidJR" name="pane-split-h" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/49e5Fvod5ZDr3F7QDRidJR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>4. <strong>Press CTRL + B then o to switch between the panes.</strong> Alternatively press CTRL + B then ; to toggle between the last two panes.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="3nXMn7c83JAd6HwhvnrJJR" name="pane-switch" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/3nXMn7c83JAd6HwhvnrJJR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>5. <strong>Press CTRL + B then x to close the currently selected pane. You will need to confirm the closure by pressing Y and Enter.</strong></p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="wSZuVeXHahKamT7LUn7jBR" name="pane-close" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/wSZuVeXHahKamT7LUn7jBR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>6. <strong>Press CTRL + B then q followed by the number of the pane that you wish to jump to. </strong>You need to be quick!</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="yZY8NkPjkN4S5DbitwJo8R" name="pane-number" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/yZY8NkPjkN4S5DbitwJo8R.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>7. <strong>Press CTRL+B then press the arrow keys to resize the currently selected pane.</strong> You will need to repeatedly press the keys to tweak the size.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:836px;"><p class="vanilla-image-block" style="padding-top:60.29%;"><img id="pHdJFHepz24ynbz7Azz3TR" name="pane-resize" alt="Tmux" src="https://cdn.mos.cms.futurecdn.net/pHdJFHepz24ynbz7Azz3TR.gif" mos="" align="middle" fullscreen="" width="836" height="504" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><div ><table><caption>Tmux Pane Management Cheatsheet</caption><thead><tr><th class="firstcol " ><p>Key combination</p></th><th
><p>Description</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>CTRL + B then press %</p></td><td
><p>Split vertically.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press “</p></td><td
><p>Split horizontally.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press o</p></td><td
><p>Switch to the next pane.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press ;</p></td><td
><p>Toggle between the last two panes.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press x</p></td><td
><p>Close current pane.</p></td></tr><tr><td class="firstcol " ><p>CTRL + B then press q</p></td><td
><p>Show pane numbers, press the number to jump to that pane.</p></td></tr><tr><td class="firstcol " ><p>Hold CTRL + B then press ◀▶🔼🔽(Arrow keys)</p></td><td
><p>Resize pane.</p></td></tr></tbody></table></div>
https://www.tomshardware.com/software/linux/heres-how-i-multi-task-in-the-linux-terminal-with-tmux
Terminal Multiplexers are powerful tools for every Linux user’s toolkit, and Tmux is the king that reigns supreme when it comes to productivity and versatility.
Tpb7kF4t4cuq4Ma8yEKR6d
Tue, 16 Sep 2025 14:00:00 +0000 Linux
Software
Operating Systems
Les Pounder
Future / Pexels
Tmux
Tmux
<![CDATA[ Biwin Black Opal X570 2TB SSD Review: Caught In The Middle With You ]]>
<p>When was the last time you really saw a high-end DRAM-less SSD? Everybody knows that high performance and DRAM go together, but that connection is not always as direct as it appears. Manufacturers that sell DRAM-less SSDs are usually doing so to entice a budget buyer and, as such, they usually try to save money on the controller and sometimes on the flash. They also design the drive in a way that looks impressive with its peak performance, which can also be abysmal in edge cases. The write saturation result in our recent TeamGroup MP44Q review is a good example of this.</p><p>Biwin goes a very different direction with the X570, promising full PCIe 5.0 performance with an eight-channel controller that is DRAM-less but has a more restrained cache for generally better sustained performance. This is a bit like having your cake and eating it too: you can have the benefits of a DRAM-less drive, such as lower cost and potentially better efficiency, while also getting the advantages of a fully-fledged eight-channel controller. This means more bandwidth and higher IOPS than you’d get with a standard four-channel DRAM-less solution.</p><p>The <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/crucial-2tb-t500-ssd-review"><u>Crucial T500</u></a> comes to mind as a similar type of hybrid drive in the opposite direction, as it has DRAM but only four channels. In that case, the drive is able to compete with the high-end PCIe 4.0 field while also being suitable for laptop use.</p><p>The X570, therefore, ends up caught in the middle in a way that feels similar to the mid-range, Phison E31T-based SSDs like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/the-crucial-p510-2tb-ssd-review" target="_blank"><u>Crucial P510</u></a>. Why get a PCIe 5.0 drive and not go for 14 GB/s? Well, you might want to save some money and future-proof on your current PCIe 4.0 system. The X570, in contrast, can achieve maximum bandwidth and should also be less expensive than the high-end alternatives, but it also gives up power efficiency over the E31T drives to get there. This is a bit of a push, but there is one final place where the X570 can attain an edge: capacity. An eight-channel controller can address twice as much flash, which makes the X570 attractive at 4TB with the possibility of 8TB for its controller, something which isn’t really possible on the E31T SSD controller. For an audience that is always asking for larger drives, this helps keep the drive in the fight.</p><h2 id="biwin-black-opal-x570-specifications-2">Biwin Black Opal X570 Specifications</h2><div ><table><thead><tr><th class="firstcol " ><p>Product</p></th><th
><p>1TB</p></th><th
><p>2TB</p></th><th
><p>4TB</p></th></tr></thead><tbody><tr><td class="firstcol " ><p><strong>Pricing</strong></p></td><td
><p>N/A</p></td><td
><p>N/A</p></td><td
><p>N/A</p></td></tr><tr><td class="firstcol " ><p><strong>Form Factor</strong></p></td><td
><p>M.2 2280 (Single-sided)</p></td><td
><p>M.2 2280 (Single-sided)</p></td><td
><p>M.2 2280 (Single-sided)</p></td></tr><tr><td class="firstcol " ><p><strong>Interface / Protocol</strong></p></td><td
><p>PCIe 5.0 x4
NVMe 2.0</p></td><td
><p>PCIe 5.0 x4
NVMe 2.0</p></td><td
><p>PCIe 5.0 x4
NVMe 2.0</p></td></tr><tr><td class="firstcol " ><p><strong>Controller</strong></p></td><td
><p>Maxio MAP1806</p></td><td
><p>Maxio MAP1806</p></td><td
><p>Maxio MAP1806</p></td></tr><tr><td class="firstcol " ><p><strong>DRAM</strong></p></td><td
><p>N/A (HMB)</p></td><td
><p>N/A (HMB)</p></td><td
><p>N/A (HMB)</p></td></tr><tr><td class="firstcol " ><p><strong>Flash Memory</strong></p></td><td
><p>YMTC 232-Layer TLC</p></td><td
><p>YMTC 232-Layer TLC</p></td><td
><p>YMTC 232-Layer TLC</p></td></tr><tr><td class="firstcol " ><p><strong>Sequential Read</strong></p></td><td
><p>14,000 MB/s</p></td><td
><p>14,500 MB/s</p></td><td
><p>14,500 MB/s</p></td></tr><tr><td class="firstcol " ><p><strong>Sequential Write</strong></p></td><td
><p>7,300 MB/s</p></td><td
><p>10,000 MB/s</p></td><td
><p>11,000 MB/s</p></td></tr><tr><td class="firstcol " ><p><strong>Random Read</strong></p></td><td
><p>1,600K IOPS</p></td><td
><p>2,000K IOPS</p></td><td
><p>2,000K IOPS</p></td></tr><tr><td class="firstcol " ><p><strong>Random Write</strong></p></td><td
><p>1,000K IOPS</p></td><td
><p>1,400K IOPS</p></td><td
><p>1,500K IOPS</p></td></tr><tr><td class="firstcol " ><p><strong>Security</strong></p></td><td
><p>N/A</p></td><td
><p>N/A</p></td><td
><p>N/A</p></td></tr><tr><td class="firstcol " ><p><strong>Endurance (TBW)</strong></p></td><td
><p>600TB</p></td><td
><p>1,200TB</p></td><td
><p>2,400TB</p></td></tr><tr><td class="firstcol " ><p><strong>Part Number</strong></p></td><td
><p>X570-1TB</p></td><td
><p>X570-2TB</p></td><td
><p>X570-4TB</p></td></tr><tr><td class="firstcol " ><p><strong>Warranty</strong></p></td><td
><p>5-Year</p></td><td
><p>5-Year</p></td><td
><p>5-Year</p></td></tr></tbody></table></div><p>The Biwin Black Opal X570, hereby also referenced as “X570” for brevity, is available at 1TB, 2TB, and 4TB capacities. The drive is currently not readily available in the U.S. market, but it, and drives like it, may be in the future. The relevance of this review is contingent on the unique hardware of such drives: a DRAM-less controller that, thanks to having eight rather than the normal four channels, can fully saturate the PCIe 5.0 interface and support higher capacities.</p><p>The X570's lack of DRAM and need for a DRAM controller also means that the controller can be smaller, allowing four NAND flash packages on the top side, with the drive pulling less power in general use. This also reduces cost and, additionally, older flash could be used as well, opening the door to some unique solutions.</p><p>The X570 is rated for up to 14,500 / 11,000 MB/s for sequential reads and writes and up to 2,000K / 1,500K random read and write IOPS. The warranty is standard at five years with up to 600TB of writes per TB capacity.</p><h2 id="biwin-black-opal-x570-software-and-accessories-2">Biwin Black Opal X570 Software and Accessories</h2><p>Biwin’s site has a download for the Biwin Intelligence Software package, which is an SSD toolbox application. This program has health information for the drive, including S.M.A.R.T. values, and has diagnostics, performance testing, and other functions such as firmware updating. Additionally, the software can be used to migrate data or clone a drive.</p><p>If you prefer not to use this software, we recommend <a data-analytics-id="inline-link" href="https://crystalmark.info/en/download/"><u>CrystalDiskInfo</u></a> for health monitoring, <a data-analytics-id="inline-link" href="https://crystalmark.info/en/download/"><u>CrystalDiskMark</u></a> for benchmarking, <a data-analytics-id="inline-link" href="https://multidrive.io/download"><u>MultiDrive</u></a> for imaging, cloning, and backup on Windows, and <a data-analytics-id="inline-link" href="https://clonezilla.org/downloads.php"><u>Clonezilla</u></a> for a bootable imaging solution.</p><h2 id="biwin-black-opal-x570-a-closer-look-2">Biwin Black Opal X570: A Closer Look</h2><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="4EqWwKYpo8sqCpGNQ9YtFi" name="02" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/4EqWwKYpo8sqCpGNQ9YtFi.jpg" mos="" link="" align="" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="UcCHZ5mhArWqZYE7HwnG7i" name="03" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/UcCHZ5mhArWqZYE7HwnG7i.jpg" mos="" link="" align="" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The X570 is single-sided at all capacities. This increases its compatibility with laptops and mobile devices. The drive is rated at 3.3V @ 2A, which translates to 6.6W with some tolerance – this matches the highest power mode via S.M.A.R.T. at 6.5W. In comparison, the earliest high-end Gen 5 drives based on the Phison E26 controller, such as the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/crucial-t705-2tb-ssd-review" target="_blank"><u>Crucial T705</u></a>, are rated to pull up to 11.5W. This is a significant difference, relevant because drives like the T705 required a heatsink and were not suitable for laptop use.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="TWsNrPqxGGVtzEtqRz2oXB" name="04" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/TWsNrPqxGGVtzEtqRz2oXB.jpg" mos="" link="" align="" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="oq4EZpxXwrBPr5pPFwuKVB" name="06" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/oq4EZpxXwrBPr5pPFwuKVB.jpg" mos="" link="" align="" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="2Q8kEPyi7e4iYHho2ZaDHB" name="05" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/2Q8kEPyi7e4iYHho2ZaDHB.jpg" mos="" link="" align="" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The flash is labeled BW29F4T08EMLCHQM, which can be decoded as Biwin flash with 4Tb or 512GB packages manufactured in week 10 of this year. It’s 232-Layer TLC flash from YMTC, which is extremely prevalent in budget drives and has been proven to be reliable and performant.</p><p>The controller is of more interest. The Maxio MAP1806 is an eight-channel, PCIe 5.0 SSD controller manufactured in the 6nm TSMC process node. This allows it to be more power-efficient than previous 12nm designs. It’s capable of handling up to 3600 MT/s flash, although it’s possible to achieve 14 GB/s with 2,400 MT/s flash. Without DRAM, it has to rely on Host Memory Buffer (HMB) tech, but it still has the benefits of an eight-channel design, whereas all other DRAM-less controllers are four-channel. Running eight channels does mean higher power consumption, but we’ve seen good things out of the SMI SM2508 – see our <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/sandisk-wd-black-sn8100-2tb-ssd-review"><u>Sandisk WD_Black SN8100 review</u></a> – and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/phison-e28-2tb-ssd-review"><u>Phison E28</u></a> controllers, which are also made with the 6nm process node.</p><p>In fact, the lack of DRAM can reduce power consumption in many cases and certainly lowers cost. Sticking with eight channels means that older, 2,400 MT/s flash can be used, which could be less expensive with more flexibility, without losing the ability to use up to at least 64 1Tb dies. This means that 8TB is on the table, with even 16TB technically being possible. That’s a lot of capacity for a DRAM-less drive. Having eight channels also means a higher level of parallelization with higher, more consistent throughput.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-ssds,3891.html"><strong>Best SSDs</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-external-hard-drive-ssd,5987.html"><strong>Best External SSDs</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ssd-for-steam-deck"><strong>Best SSD for the Steam Deck</strong></a></p><h2 id="comparison-products-2">Comparison Products</h2><p>The Biwin Black Opal X570 has stiff competition from high-end PCIe 5.0 SSDs and has to slot itself above the mid-range options, so we arranged our group of test SSDs accordingly. With Phison’s E26 now becoming obsolete, the X570 is one possible replacement, as are drives with newer controllers but older flash, like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/acer-predator-gm9000-2tb-ssd-review" target="_blank"><u>Acer Predator GM9000</u></a>. Phison has its updated <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/phison-e28-2tb-ssd-review"><u>E28 controller</u></a> on the way, but we haven’t tested retail drives with the new controller yet.</p><p>In this case, Silicon Motion has beaten them to the punch with its comparable SM2508 controller. This controller awed us with its high power efficiency, and retail drives have been impressive. These include the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/sandisk-wd-black-sn8100-2tb-ssd-review"><u>Sandisk WD_Black SN8100</u></a> and the Crucial T710, drives that use different TLC flash. Samsung has kept its proprietary controller on the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/samsung-9100-pro-ssd-review"><u>9100 Pro</u></a>. To cap things off, we have mid-range, Phison E31T-based drives with the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/the-crucial-p510-2tb-ssd-review"><u>Crucial P510</u></a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/corsair-mp700-elite-ssd-review"><u>Corsair MP700 Elite</u></a>. These two drives are also using different TLC flash, so the comparisons cover all areas.</p><p>Lastly, we wanted to give an impression of how a high-end DRAM-less Gen 5 drive like the X570 compares to the best DRAM-equipped Gen 4 drives. Our stand-in here for the latter is the excellent <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/samsung-990-pro-ssd-review"><u>Samsung 990 Pro</u></a>. If you’re coming from a PCIe 3.0 or DRAM-less PCIe 4.0 drive, the gap will be even more significant, and a drive of the 990 Pro’s class – among which we would have the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/wd-black-sn850x-ssd-review-back-in-black"><u>WD Black SN850X</u></a> and the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/crucial-2tb-t500-ssd-review"><u>Crucial T500</u></a> – is probably as low as you should go if you’re gunning for a high-performance drive.</p><h2 id="trace-testing-3dmark-storage-benchmark-2">Trace Testing — 3DMark Storage Benchmark</h2><p>Built for gamers, 3DMark’s Storage Benchmark focuses on real-world gaming performance. Each round in this benchmark stresses storage based on gaming activities including loading games, saving progress, installing game files, and recording gameplay video streams. Future gaming benchmarks will be DirectStorage-inclusive and we also include notes about which drives may be future-proofed.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="aRkzBiNocUHpzuinniefyV" name="ALLSSD-3DMLatency" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/aRkzBiNocUHpzuinniefyV.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="UNQyhEiWWNBRjfuDpDQazV" name="ALLSSD-3DMMBps" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/UNQyhEiWWNBRjfuDpDQazV.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="iwq6UzFHfRy3yw7e9kubzV" name="ALLSSD-3DMPoints" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/iwq6UzFHfRy3yw7e9kubzV.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>When we look at 3DMark, we’re mostly looking at the latency results as these can give an idea of drive responsiveness, which, for gaming, most closely aligns with load times. The benefits will differ from game to game, with many seeing no advantage at all, while others can load a second or two faster with the best drives. This is not something the average user will notice or care about, but if you’re looking at PCIe 5.0 drives, you probably want to take it into consideration.</p><p>In this case, the X570 performs closer to the mid-range DRAM-less PCIe 5.0 drives based on the Phison E31T controller, like the Crucial P510 or the Corsair MP700 Elite. We would expect the X570 to be more expensive than these due to controller complexity, but not by a lot. It will also probably lean more towards higher capacities where the fixed cost of the controller is less impactful, meaning it could be competitive, especially by offering a 4TB SKU out of the gate. This will save you money over the high-end drives with DRAM while maintaining the high bandwidth that they have, coupled with reasonably good game load performance that matches any of the mid-range options.</p><h2 id="trace-testing-pcmark-10-storage-benchmark-2">Trace Testing — PCMark 10 Storage Benchmark</h2><p>PCMark 10 is a trace-based benchmark that uses a wide-ranging set of real-world traces from popular applications and everyday tasks to measure the performance of storage devices. The results are particularly useful when analyzing drives for their use as primary/boot storage devices and in work environments.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="dNPenHM5bQhAeh5S9tBdye" name="ALLSSD-PCM10Latency" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/dNPenHM5bQhAeh5S9tBdye.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="X8D8toXJ9C7EMgWfBa2eye" name="ALLSSD-PCM10BW" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/X8D8toXJ9C7EMgWfBa2eye.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="n63f23AjFW4GkxLXjzXize" name="ALLSSD-PCM10Score" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/n63f23AjFW4GkxLXjzXize.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>In PCMark 10, which is the application-oriented benchmark complement to 3DMark, the X570 fares a little better. Here it remains past the mid-range PCIe 5.0 drives but still falls short of the high-end. This still means it beats any drive below its class, which, when coupled with lower pricing, could make it a reasonable alternative. This puts the most pressure on the mid-range drives like the P510 and MP700 Elite, but again, this would be felt hardest at higher capacities.</p><p>For lower capacities, those drives still make sense, although you need a certain amount of flash to push PCIe 5.0 bandwidth. In other words, you could compromise with the lower-end drives at 1TB or maybe 2TB, but if you want 4TB, then the X570 presents a better case.</p><p>If you need less space than 1TB, you should probably go with a PCIe 4.0 solution. If you need more, that is 8TB, then the venerable <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/wd-black-sn850x-8tb-ssd-review-the-no-compromise-8tb-champion"><u>WD Black SN850X</u></a> still makes a lot of sense. If you want Gen 5 performance, though, you could wait for the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/samsungs-fastest-consumer-ssd-raises-its-capacity-cap-8tb-9100-pro-to-arrive-in-september"><u>Samsung 9100 Pro’s</u></a> 8TB SKU, but that’s likely to cost an arm and a leg.</p><p>This leaves the door open to an 8TB drive based on the MAP1806 controller – perhaps the X570 could even add an 8TB SKU down the road, which is quite possible. That might be easier with denser, 2Tb flash dies, which would probably mean QLC flash over TLC, but we’ll have to wait and see. There probably is a place for such a drive, but with QLC flash and such high bandwidth potential, there would probably be a need for a multi-stage write cache, as used by the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/micron-2600-qlc-ssd-uses-flexible-caching-to-offer-tlc-like-performance-7-200-mb-s-reads-and-6-500-mb-s-writes-push-the-limits-of-pcie-4-0" target="_blank"><u>Micron 2600</u></a>.</p><h2 id="console-testing-playstation-5-transfers-2">Console Testing — PlayStation 5 Transfers</h2><p>The PlayStation 5 is capable of taking one additional PCIe 4.0 or faster SSD for extra game storage. While any 4.0 drive will technically work, Sony recommends drives that can deliver at least 5,500 MB/s of sequential read bandwidth for optimal performance. In our testing, PCIe 5.0 SSDs don’t bring much to the table and generally shouldn’t be used in the PS5, especially as they may require additional cooling. Check our <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ps5-ssds"><u>Best PS5 SSDs</u></a> article for more information.</p><p>Our testing utilizes the PS5’s internal storage test and manual read/write tests with over 192GB of data both from and to the internal storage. Throttling is prevented where possible to see how each drive operates under ideal conditions. While game load times should not deviate much from drive to drive, our results can indicate which drives may be more responsive in long-term use.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:88.54%;"><img id="JbHfaqo36A3u5GkWncYbqf" name="PS5E28-CopyFromMBps" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/JbHfaqo36A3u5GkWncYbqf.png" mos="" link="" align="" fullscreen="" width="1920" height="1700" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:88.54%;"><img id="kzqZHmKC4C8XBapmfQZeqf" name="PS5E28-CopyToMBps" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/kzqZHmKC4C8XBapmfQZeqf.png" mos="" link="" align="" fullscreen="" width="1920" height="1700" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:88.54%;"><img id="7LK9yqBGVm3ZfNABqMbdqf" name="PS5E28-PS5ReadTest" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/7LK9yqBGVm3ZfNABqMbdqf.png" mos="" link="" align="" fullscreen="" width="1920" height="1700" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>We can’t really recommend the X570 for the PS5 as there are less expensive options that offer a comparable experience. If you’re intending to move the drive over to a PC later, it can do in a pinch, though.</p><h2 id="transfer-rates-diskbench-2">Transfer Rates — DiskBench</h2><p>We use the DiskBench storage benchmarking tool to test file transfer performance with a custom, 50GB dataset. We write 31,227 files of various types, such as pictures, PDFs, and videos to the test drive, then make a copy of that data to a new folder, and follow up with a reading test of a newly-written 6.5GB zip file. This is a real world type workload that fits into the cache of most drives.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="fmawD9civtc6nELYCXdpvn" name="ALLSSD-DiskBench50Copy" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/fmawD9civtc6nELYCXdpvn.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="EAnDEWvggoC2bUjrDNvxvn" name="ALLSSD-DiskBench50Write" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/EAnDEWvggoC2bUjrDNvxvn.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="LQhqL5WPpPzXwe6Tojqyvn" name="ALLSSD-DiskBench65Read" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/LQhqL5WPpPzXwe6Tojqyvn.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>What’s PCIe 5.0 without the bandwidth? The X570 demonstrates that it can beat any PCIe 4.0 drive, but it doesn’t really offer anything compelling in the PCIe 5.0 realm. We would like to test it at 4TB to see how it does there against specific drives. The GM9000 beats it handily at 2TB, but a drive with the same hardware at 4TB – such as the Lexar NM1090 Pro, featured in an upcoming review – can actually perform worse, with results closer to the 2TB X570. Likewise, the mid-range drives like the P510 and MP700 Elite also perform roughly at the level of the X570, but those drives top out at 2TB right now.</p><p>All of this is to argue, again, that the X570 and drives like it <em>could </em>be a compelling option at 4TB. You’ll still get better performance out of the best PCIe 5.0 drives, but once you factor in cost, the X570 could become more interesting.</p><h2 id="synthetic-testing-atto-crystaldiskmark-2">Synthetic Testing — ATTO / CrystalDiskMark</h2><p>ATTO and CrystalDiskMark (CDM) are free and easy-to-use storage benchmarking tools that SSD vendors commonly use to assign performance specifications to their products. Both of these tools give us insight into how each device handles different file sizes and at different queue depths for both sequential and random workloads.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="56CUmPmW5wEQvA8xNXCRGJ" name="ALLSSD-ATTOLinRead" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/56CUmPmW5wEQvA8xNXCRGJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="fNXThTmrSexKP6EcVRmFGJ" name="ALLSSD-ATTOLinWrite" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/fNXThTmrSexKP6EcVRmFGJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="etzGWh6jfe82McUiPEyJGJ" name="ALLSSD-ATTOLogRead" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/etzGWh6jfe82McUiPEyJGJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="sA29RsRgJLk9Qs75EbJSFJ" name="ALLSSD-ATTOLogWrite" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/sA29RsRgJLk9Qs75EbJSFJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 5 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="WMEifScXrssdZv5C9zjxDJ" name="ALLSSD-CDMRandWriteIOPSQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/WMEifScXrssdZv5C9zjxDJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 6 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="zP8NNd5vPYzUEEw8VKsrDJ" name="ALLSSD-CDMSeqWriteQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/zP8NNd5vPYzUEEw8VKsrDJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 7 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="afht7fff2BZbrZWY4PJoDJ" name="ALLSSD-CDMSeqReadQD8" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/afht7fff2BZbrZWY4PJoDJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 8 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Hvu4WVvdjt4ydGmCNKbnDJ" name="ALLSSD-CDMSeqWriteQD8" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/Hvu4WVvdjt4ydGmCNKbnDJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 9 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="QHEV83KkyqoVvj4foMqrCJ" name="ALLSSD-CDMSeqReadQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/QHEV83KkyqoVvj4foMqrCJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 10 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Ar4uJyDWowbhRmLaHM8oCJ" name="ALLSSD-CDMRandWriteLatencyQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/Ar4uJyDWowbhRmLaHM8oCJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 11 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="LPEhdhtD43y93ShYSFwkCJ" name="ALLSSD-CDMRandReadIOPSQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/LPEhdhtD43y93ShYSFwkCJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 12 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="nWokrvwqKTakvr9pf3knCJ" name="ALLSSD-CDMRandReadIOPSQD256" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/nWokrvwqKTakvr9pf3knCJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 13 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="cxnMDvDdfqkgdzN7PGbqCJ" name="ALLSSD-CDMRandWriteIOPSQD256" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/cxnMDvDdfqkgdzN7PGbqCJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 14 of 14</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="dyWuAvLmGtRVa7ustAqMAJ" name="ALLSSD-CDMRandReadLatencyQD1" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/dyWuAvLmGtRVa7ustAqMAJ.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>We see nothing unusual in the X570’s ATTO results aside from the fact that it can’t quite hit the high notes that high-end PCIe 5.0 drives like the WD_Black SN8100 can. It does perform better than the MP700 Elite and P510, though, and also may outpace any of the Phison E26-based drives like the MP700 Pro SE. Realistically, it’s best to move on from the E26 and look at newer controllers with older flash for comparison instead. These are the ones that might be a little less expensive. A good example would be the Acer Predator GM9000 or Lexar NM1090 Pro. These do beat the X570 generally, but have the added cost of DRAM.</p><p>The X570 doesn’t fare much differently in CDM’s sequential results, at least at the queue depth of 1. This is the most common queue depth for regular file transfers. The X570 performs better at higher queue depths, particularly for reads, but it can’t quite keep up with the very best drives in terms of writes. To some extent, this can be blamed on the flash, but the use of that flash is part of the drive’s appeal if it helps keep the price down. Still, we suspect that with newer TLC, the X70 would perform better.</p><p>Unfortunately, the drive doesn’t perform very well when we look at random performance, particularly QD1 for 4K. These results probably preclude it from ever being a truly good drive, as it really should do better here. With different flash it might be better, and maybe this controller needs some firmware work, too. In any case, while it performs just dandy for games and storage, it isn’t as compelling for a primary storage solution. This is more of a secondary drive. This works at 4TB and would work at 8TB, possibly even with QLC flash, but this drive is a harder sell at lower capacities.</p><h2 id="sustained-write-performance-and-cache-recovery-2">Sustained Write Performance and Cache Recovery</h2><p>Official write specifications are only part of the performance picture. Most SSDs implement a write cache, which is a fast area of pseudo-SLC (single-bit) programmed flash that absorbs incoming data. Sustained write speeds can suffer tremendously once the workload spills outside of the cache and into the "native" TLC (three-bit) or QLC (four-bit) flash. Performance can suffer even more if the drive is forced to fold, which is the process of migrating data out of the cache in order to free up space for further incoming data.</p><p>We use Iometer to hammer the SSD with sequential writes for 15 minutes to measure both the size of the write cache and performance after the cache is saturated. We also monitor cache recovery via multiple idle rounds. This process shows the performance of the drive in various states as well as the steady state write performance.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="J566aXXv2VQuS6BBnsrYXX" name="ALLSSD-WriteSaturation-900s" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/J566aXXv2VQuS6BBnsrYXX.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="UfRg2WvqTB2tbKwmhzqNWX" name="ALLSSD-WriteSaturation-150s" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/UfRg2WvqTB2tbKwmhzqNWX.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="YLDuJvCwWZQpvbTCNUZTTX" name="ALLSSD-WriteSaturation-AvgMBps" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/YLDuJvCwWZQpvbTCNUZTTX.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>The 2TB X570 writes at just over 9.9 GB/s in the fast, single-bit pSLC cache mode for over 34 seconds. This is a 340GB cache, which is neither super large nor super small, reminiscent of the T710s. After the cache is exhausted, the drive writes in a TLC mode at between 3.6 and 3.7 GB/s. Finally, the drive hits a folding mode – where it is forced to move data over to empty the cache, reducing the speed of new incoming data – with a speed around 1.1 GB/s. The actual steady state performance is around 3.3 GB/s, which is not bad at all. This definitely feels more like an eight-channel drive, which gives it an edge over many drives like the MP700 Elite, but that does hurt power efficiency.</p><p>In terms of peak performance, it’s closer to early E26 drives like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/corsair-mp700-ssd-review" target="_blank"><u>Corsair MP700,</u></a> which is disappointing in a way, but the higher and more consistent TLC mode performance puts it clearly ahead of that early adopter technology. The X570 also outperforms the MP700 Elite and P510 in all modes, which is crucial for it to do in order to remain competitive.</p><h2 id="power-consumption-and-temperature-2">Power Consumption and Temperature</h2><p>We use the Quarch HD Programmable Power Module to gain a deeper understanding of power characteristics. Idle power consumption is an important aspect to consider, especially if you're looking for a laptop upgrade as even the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ultrabooks-premium-laptops"><u>best ultrabooks</u></a> can have mediocre stock storage. Desktops may be more performance-oriented with less support for power-saving features, so we show the worst-case.</p><p>Some SSDs can consume watts of power at idle while better-suited ones sip just milliwatts. Average workload power consumption and max consumption are two other aspects of power consumption but performance-per-watt, or efficiency, is more important. A drive might consume more power during any given workload, but accomplishing a task faster allows the drive to drop into an idle state more quickly, ultimately saving energy.</p><p>For temperature recording we currently poll the drive’s primary composite sensor during testing with a ~22°C ambient. Our testing is rigorous enough to heat the drive to a realistic ceiling temperature.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="JJuW8sBpQhWt7aPrysBH8o" name="X570" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/JJuW8sBpQhWt7aPrysBH8o.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="vcHWAAizSiib3boKBEUNQo" name="ALLSSD-QuarchMaxPower" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/vcHWAAizSiib3boKBEUNQo.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="8Z7q8Crc3WfmiyKBi9ZLQo" name="ALLSSD-QuarchIdlePower" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/8Z7q8Crc3WfmiyKBi9ZLQo.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 4 of 4</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="SGx7pcmcUhDCTDEkJzq9Ro" name="ALLSSD-QuarchAvgPower" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/SGx7pcmcUhDCTDEkJzq9Ro.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>Is the X570 efficient? Yes. Is it as efficient as it needs to be? Not really. While the drive is largely an improvement over the fastest PCIe 4.0 drives, its power efficiency is lackluster when compared to newer PCIe 5.0 options. It’ll beat E26-based drives like the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/crucial-t705-2tb-ssd-review"><u>Crucial T705</u></a> in efficiency, but it has the same high idle power consumption issues that such drives have. Our idle power consumption results are intended for a desktop comparison, not laptop, as laptops should implement power-saving features correctly with most drives not sucking enough power when idle to impact battery life significantly.</p><p>This level of desktop idle power consumption is also not unusual for PCIe 5.0 drives, but an improvement in this area could have been in the X570’s favor. We would like to see something closer to the SN8100, but the flash does limit the X570 to some extent.</p><p>By S.M.A.R.T., the drive’s top power state is at 6.5W, which should be competitive, but in reality, it peaked at 8.48W, which is closer to what we would expect. As a result, the drive isn’t a grand slam for laptops and essentially isn’t taking much less power than it would if it had DRAM. Disappointing, but we think improvements can be made here with newer flash and other optimizations.</p><p>The good news is, the drive is efficient enough that it probably doesn’t need a heatsink. In our testing, the temperature topped out around 60°C, which is 30 degrees below the primary throttling point. As with the MAP1602, it’s likely the controller is a particular hotspot, so some heatspreading could be effective. Utilizing a heatspreader, a low-profile heatsink, or custom thermal padding would help if this drive is used in a laptop or other device where the ambient temperature might be higher.</p><h2 id="test-bench-and-testing-notes-2">Test Bench and Testing Notes</h2><div ><table><caption>Test Bench and Testing Notes</caption><tbody><tr><td class="firstcol " ><p><strong>CPU</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B09FXDLX95">Intel Core i9-12900K</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Motherboard</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B0BG6M53DG/">Asus ROG Maximus Z790 Hero</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Memory</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B0BJ1892HJ">2x16GB G.Skill DDR5-5600 CL28</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Graphics</strong></p></td><td
><p>Intel Iris Xe UHD Graphics 770</p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>CPU Cooling</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B07PB24DN2">Enermax Aquafusion 240</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Case</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B08412JPCH">Cooler Master TD500 Mesh V2</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Power Supply</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B0BXFQ6XPB">Cooler Master V850 i Gold</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>OS Storage</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B0BJ116VV2">Sabrent Rocket 4 Plus-G 2TB</a></p></td><td
></td></tr><tr><td class="firstcol " ><p><strong>Operating System</strong></p></td><td
><p><a href="https://www.amazon.com/dp/B09V71FYGS">Windows 11 Pro</a></p></td><td
></td></tr></tbody></table></div><p>We use an Alder Lake platform with most background applications such as indexing, Windows updates, and anti-virus disabled in the OS to reduce run-to-run variability. Each SSD is prefilled to 50% capacity and tested as a secondary device. Unless noted, we use active cooling for all SSDs.</p><h2 id="biwin-black-opal-x570-bottom-line-2">Biwin Black Opal X570 Bottom Line</h2><p>The Biwin Black Opal X570 is a unique drive, and on that basis alone, it’s worth a closer look. A DRAM-less, eight-channel controller hasn’t made a lot of sense in the past, as drives usually fall into one of two extremes: a budget, four-channel solution without DRAM, or an eight-channel monster with plenty of DRAM. This can impact other aspects of the drive, such as flash choice – QLC makes more sense on a budget drive, but the higher average density means it’s best at higher capacities. DRAM-less drives also usually have massive pSLC caches with terrible sustained performance after the cache is exhausted. The X570 changes this up as it uses TLC flash with a moderately-sized cache, and the eight-channel controller lifts up its bandwidth and IOPS potential.</p><p>In addition, this design opens the door to higher capacities not only from the channel count being doubled, but also the smaller DRAM-less controller allows for more NAND flash packages. This gives it a real boost over the mid-size PCIe 5.0 drives and also opens the door to 8TB drives down the road, and even fast QLC-based drives.</p><p>We’ve found in our review, though, that the performance with TLC flash is closer to early PCIe 5.0 drives, and the X570 cannot really compete with the high-end, DRAM-equipped options. This means it needs to be priced right and should lean more heavily on its capacity advantage. It’s definitely more powerful than the P510 and MP700 Elite, but feels like a luxury secondary drive when we’re looking at this price range.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="2Q8kEPyi7e4iYHho2ZaDHB" name="05" alt="Biwin Black Opal X570 2TB SSD" src="https://cdn.mos.cms.futurecdn.net/2Q8kEPyi7e4iYHho2ZaDHB.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>If there’s one thing that really hammers this home, it’s the relatively tame power efficiency. A DRAM-less drive should be more efficient, and if you want to throw this in a laptop for some reason, it’s not particularly looking better than faster DRAM-equipped options. Future optimization with this controller and the use of new flash should improve things, but for now, this drive makes more sense as a speedy game and data drive. That makes sense, since using older flash pairs nicely with the budget approach. It makes it difficult to shoehorn this drive into the marketplace now that more efficient and faster drives are available. The X570 would have been inspirational if it came out against only the E26 SSD controller.</p><p>Then there’s the question of putting this up against less expensive PCIe 4.0 options. In our opinion, you can probably get away with PCIe 4.0 for games and certainly for the PS5. Many laptops also currently top out at PCIe 4.0. However, if you have a more modern system with two or more PCIe 5.0 M.2 slots, the X570 is a compelling choice for a secondary drive.</p><p>Being able to move data around at these speeds is pretty ridiculous, and we think that underlines that this drive is best at higher capacities. Its performance is not lacking, although we would like to see improvements in latency. That would be possible with BiCS8 or new flash from SK hynix, but Maxio controllers are more commonly paired with YMTC or Micron flash.</p><p>Regardless, the X570 is not a bad drive by any means, but it’s definitely a niche storage solution that may pique the interest of enthusiasts. Other drives with this hardware will be coming out, and we might see variations on the flash and maybe higher capacities as well, so stay tuned.</p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-ssds,3891.html"><strong>Best SSDs</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-external-hard-drive-ssd,5987.html"><strong>Best External SSDs</strong></a></p><p><strong>MORE: </strong><a data-analytics-id="inline-link" href="https://www.tomshardware.com/best-picks/best-ssd-for-steam-deck"><strong>Best SSD for the Steam Deck</strong></a></p>
https://www.tomshardware.com/pc-components/ssds/biwin-black-opal-x570-2tb-ssd-review
The Biwin Black Opal X570 is a unique drive, running with an eight-channel control without DRAM. Its performance is not bad, but the drive may have only niche applications.
uTGwxEWtpYpRo4Kpj8bnU4
Tue, 16 Sep 2025 14:00:00 +0000 SSDs
PC Components
Storage
Shane Downing
Tom&#039;s Hardware
Biwin Black Opal X570 2TB SSD
Biwin Black Opal X570 2TB SSD
<![CDATA[ Chinese giant Tencent announces domestic AI chip push — says it has fully adapted infrastructure to support homegrown silicon in blow to Nvidia ]]>
<p>Tencent says it has <a data-analytics-id="inline-link" href="https://www.scmp.com/tech/big-tech/article/3325713/tech-war-tencent-pushes-adoption-chinese-ai-chips-mainland-cuts-reliance-nvidia" target="_blank">“fully adapted” its AI computing infrastructure</a> to support Chinese-designed processors, in a move that shifts one of the country’s biggest buyers of Nvidia chips closer to home-grown hardware, as reported by SCMP. The announcement came at the company’s Global Digital Ecosystem Summit on September 16, where Tencent Cloud president Qiu Yuepeng confirmed the firm is now using “mainstream domestic chips” and building infrastructure around them.</p><p>While Tencent stopped short of naming the specific silicon in use, the phrasing suggests that production deployments are involved, not just experimentation. Senior executive vice-president Dowson Tong Tao-sang added that the company is working with “multiple domestic chip companies” to apply “the most suitable hardware” to each scenario, and that long-term strategic investment will focus on optimizing hardware-software co-design to lower the cost of compute.</p><p>Tencent’s announcement comes just a day after China’s State Administration for Market Regulation said <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/china-accuses-nvidia-of-anti-monopoly-law-violations-raising-prospect-of-heavy-fines-company-could-be-fined-10-percent-of-revenue-from-china">Nvidia had violated antitrust rules</a> and the terms of approval for its 2019 acquisition of Mellanox Technologies. The regulator did not elaborate but confirmed the investigation remains active. This adds another layer of uncertainty for U.S. firms selling into China’s cloud and AI sectors, which are already under tight export restrictions from Washington.</p><p>For Tencent, the company now has to factor in both geopolitics and supply continuity into its decision-making. Company president Martin Lau Chi-ping said in August that Tencent already has enough training chips in stock and “many options” for inference, suggesting that the firm has already diversified procurement. But adapting software to support non-Nvidia architectures is a deeper shift that Tencent appears to be leaning into, mirroring earlier signals from AI start-up DeepSeek, which said in August its V3.1 model was tuned for the next wave of domestic accelerators.</p><p>The most likely candidate for those deployments is <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/huawei-already-has-a-new-chip-to-rival-nvidia-ai-gpus">Huawei’s Ascend platform</a>, which has already been adopted at scale by ByteDance and is supported by an increasingly mature stack built around the MindSpore framework. But whether Ascend or other domestic chips can sustain large-scale training remains an open question, especially as U.S. officials estimate that Huawei will only be able to produce around 200,000 AI chips next year.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><em> add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/tencent-goes-public-with-pivot-to-chinese-chips
Tencent says it has “fully adapted” its AI computing infrastructure to support Chinese-designed processors
nWrPJNM9jrFjUbkjbhoT69
Tue, 16 Sep 2025 13:48:30 +0000 Semiconductors
Tech Industry
Manufacturing
lukejamesalden@gmail.com (Luke James)
Luke James
Tencent
Tencent - Chinese internet giant
Tencent - Chinese internet giant
<![CDATA[ Microsoft will force install the Copilot AI app for users with desktop versions of 365 apps like Word and Excel — coming October, with no way to opt out for personal users ]]>
<p>Microsoft has announced that it will automatically install the Microsoft 365 Copilot AI app for users who have a desktop version of Microsoft 365 suite apps installed on their system, such as Word, Excel, and PowerPoint. According to <a data-analytics-id="inline-link" href="https://www.bleepingcomputer.com/news/microsoft/microsoft-to-force-install-the-microsoft-365-copilot-app-in-october/"><em>BleepingComputer</em></a>, the rollout will begin next month and is expected to be completed halfway through November, affecting all Windows PCs worldwide, except those in the European Economic Area (EEA).</p><p>“Starting in October 2025, Microsoft will begin automatically installing the Microsoft 365 Copilot app on Windows devices that have Microsoft 365 desktop client apps,” the company said on the <a data-analytics-id="inline-link" href="https://www.bleepingcomputer.com/news/microsoft/microsoft-to-force-install-the-microsoft-365-copilot-app-in-october/" target="_blank">Microsoft 365 message center</a>. “This app provides a centralized entry point for accessing Copilot experiences and AI-powered capabilities across Microsoft 365. This change simplifies access to Copilot and ensures users can easily discover and engage with productivity-enhancing features.”</p><p>Unfortunately, it seems that most personal users will have no way of opting out of this feature. But if you’re a system administrator, you can opt your organization out of this by disabling the automatic installation of Microsoft 365 Copilot in the Microsoft 365 Apps admin center.</p><p>This update is part of Redmond’s push for the wider adoption of its Copilot AI app. Just this July, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/browsers/edge-browsers-new-copilot-mode-lets-you-talk-to-ai-about-your-tabs-if-you-opt-in-but-its-only-free-for-a-limited-time">Microsoft Edge browser introduced a Copilot Mode</a> that can interact with your open tabs and find information you’re looking for. Furthermore, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/microsoft-office/microsoft-365-sees-43-percent-price-hike-thanks-to-copilot-existing-customers-safe-until-renewal">Microsoft bundled Copilot with the Microsoft 365 subscription</a>, resulting in a 43% price hike.</p><p>And while this might be a welcome development for those who use AI tools, it will most likely be seen as an annoyance by those who don’t use Copilot or AI in general. After all, if you use AI apps and even subscribe to one, you likely already have it installed on your computer. But for those who aren’t interested, they will likely just see this as another piece of bloatware that Microsoft is forcing down their throats.</p><p>The software giant is <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/microsoft-surprises-analysts-with-massive-usd80b-ai-investment-plans-for-2025">spending billions of dollars on AI investments</a>, and it likely wants users to start paying for services to recoup some of the cash it spent. However, statistics say that the AI adoption rate isn’t going as planned, with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-adoption-rate-is-declining-among-large-companies-us-census-bureau-claims-fewer-businesses-are-using-ai-tools">large companies reducing their reliance</a> on these tools. It has even gotten to the point that an economist <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-bubble-is-worse-than-the-dot-com-crash-that-erased-trillions-economist-warns-overvaluations-could-lead-to-catastrophic-consequences">warned of an AI bubble</a> that will be worse than the dot-com crash of 2000 when it bursts.</p><p>Unless you have an administrator who manages your Microsoft 365 subscription (which isn’t true for most personal users), it seems that the only way to avoid getting Microsoft 365 Copilot automatically installed on your computer is to not use Microsoft 365. Otherwise, you’ll just have to ignore it and add the app to the list of disabled apps in Windows’ Startup.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em>Tom's Hardware on Google News</em></u></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em>add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/software/microsoft-office/microsoft-will-force-install-the-copilot-ai-app-for-users-with-desktop-versions-of-365-apps-like-word-and-excel-coming-october-with-no-way-to-opt-out-for-personal-users
Microsoft 365 users will now have Copilot installed on their systems, whether they like it or not.
56zKgaWzNsDu8xtzZvt8gZ
Tue, 16 Sep 2025 12:53:41 +0000 Microsoft Office
Software
Applications
editors@tomshardware.com (Jowi Morales)
Jowi Morales
Tom&#039;s Hardware
screenshot of Microsoft 365 Copilot installed on Windows 11
screenshot of Microsoft 365 Copilot installed on Windows 11
<![CDATA[ Nvidia's unreleased 'GTX 2080 Ti' surfaces online with 12 GB VRAM and 384-bit memory bus — engineering sample has better specs than the final retail 'RTX' version ]]>
<p>Nvidia released the RTX 2080 Ti as part of its "Turing" lineup of GPUs back in 2018. It was the flagship offering at that moment, bringing ray tracing to the masses for the first time. While Nvidia released an RTX 2080 Super as well, as well as a higher-end RTX Titan, today we've spotted a previously unseen variant of this family: the GTX 2080 Ti. Yes, that's not a typo; someone on Reddit has come across a "GTX" 2080 Ti engineering sample that not only works, but actually has upgraded specs compared to the retail 2080 Ti.</p><blockquote class="reddit-card"
><a href="https://www.reddit.com/r/nvidia/comments/1nhpjtj/got_my_hands_on_a_engineering_gtx_2080ti">Got my hands on a engineering GTX 2080ti.</a> from <a href="https://www.reddit.com/r/nvidia">r/nvidia</a></blockquote><script async src="//embed.redditmedia.com/widgets/platform.js" charset="UTF-8"></script><p>User <a data-analytics-id="inline-link" href="https://www.reddit.com/r/nvidia/comments/1nhpjtj/got_my_hands_on_a_engineering_gtx_2080ti/" target="_blank"><em>u/Substantial-Mark-959</em></a> got their hands on a faulty Founder's Edition GPU from a friend for a possible repair job, only to quickly find out that it's rather unusual. Instead of saying "GeForce RTX" across the shroud, it says "GeForce GTX," despite being a 2080 Ti. They tried to flash different VBIOSes and ultimately ended up getting the card to work with a Founder's Edition BIOS and modified driver. Once up and running, even more interesting things surfaced.</p><p>Inside GPU-Z, the card shows 12 GB of VRAM, whereas the standard 2080 Ti only shipped with 11 GB. Not only that, but it seems to have more ROPs, shader units, and TMUs than the normal 2080 Ti, too, despite featuring the same TU102 die. The memory bus has also been upgraded from 352-bit to 384-bit, which consequently brings the memory bandwidth closer to almost 700 GB/s — a notable improvement over the 616 GB/s that the 2080 Ti actually shipped with. All of these increments beg the question: Does it perform better?</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:386px;"><p class="vanilla-image-block" style="padding-top:140.93%;"><img id="wPyTEBrwFuotmsb8BNvHdT" name="got-my-hands-on-a-engineering-gtx-2080ti-v0-ja4phit7fdpf1" alt="GTX 2080 Ti 12 GB engineering sample" src="https://cdn.mos.cms.futurecdn.net/wPyTEBrwFuotmsb8BNvHdT.webp" mos="" link="" align="" fullscreen="" width="386" height="544" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: u/Substantial-Mark on Reddit)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1705px;"><p class="vanilla-image-block" style="padding-top:75.01%;"><img id="pULrW24HoUPifyT9rjzTmT" name="got-my-hands-on-a-engineering-gtx-2080ti-v0-ukm9aykk9dpf1" alt="GTX 2080 Ti 12 GB engineering sample" src="https://cdn.mos.cms.futurecdn.net/pULrW24HoUPifyT9rjzTmT.webp" mos="" link="" align="" fullscreen="" width="1705" height="1279" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: u/Substantial-Mark on Reddit)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:595px;"><p class="vanilla-image-block" style="padding-top:77.82%;"><img id="AFxVhPdmbPrRyr5WUZEKdT" name="got-my-hands-on-a-engineering-gtx-2080ti-v0-13b0oo6chdpf1" alt="GTX 2080 Ti 12 GB engineering sample" src="https://cdn.mos.cms.futurecdn.net/AFxVhPdmbPrRyr5WUZEKdT.webp" mos="" link="" align="" fullscreen="" width="595" height="463" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: u/Substantial-Mark on Reddit)</span></figcaption></figure></div></div></div><p>The 12 GB GTX 2080 Ti scored 9,116 points in the Superposition benchmark, which is fairly in line with a normal 2080 Ti, suggesting that perhaps the modified driver or the VBIOS isn't actually utilizing the extra cores properly. The extra gigabyte of VRAM wouldn't make much of a difference on its own. Unfortunately, the user didn't benchmark more games or synthetic workloads except for Port Royal to test ray tracing, which ran unremarkably. However, this at least confirms there are RT Cores aboard this engineering sample.</p><p>The card's existence could point towards a last-minute change from Nvidia, where they pivoted from the GTX branding to RTX to market ray tracing. We'll never know for sure, but the whole endeavor was so unique that a curator from TechPowerUp ended up adding this GTX 2080 Ti <a data-analytics-id="inline-link" href="https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-ti-12-gb.c3938" target="_blank">to their database</a>, enshrining the 2080 Ti in GPU history forever.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em> Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/nvidias-unreleased-gtx-2080-ti-surfaces-online-with-12-gb-vram-and-384-bit-memory-bus-engineering-sample-has-better-specs-than-the-final-retail-rtx-version
A purported engineering sample for Nvidia's RTX 2080 Ti has surfaced online, except it's a "GTX" 2080 Ti with 12 GB VRAM and upgraded specs across the board. The card still has its RT cores and performs similarly to a regular 2080 Ti. It was discovered by a Reddit user who was repairing the GPU for a friend, and now it's been added to the TPU database, immortalizing it.
WzqctpDkj9qRaiEqQNMNiW
Tue, 16 Sep 2025 12:42:38 +0000 GPUs
PC Components
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
Nvidia
GeForce RTX 2080 Ti Founders Edition
GeForce RTX 2080 Ti Founders Edition
<![CDATA[ Intel Core Ultra 3 205 delivers impressive results in early review — reportedly surpasses previous-gen Core i3-14100 and Core i5-14400 ]]>
<p>The Core Ultra 3 205 represents the lower end of Intel’s current generation of Arrow Lake desktop processors. While the CPU is not officially available for purchase yet, an early review by Korean reviewer Bulls Lab gives us an idea about its capabilities. The entry-level CPU features a hybrid architecture with four P-cores that can boost up to 4.9 GHz and four E-cores capable of going up to 4.4 GHz, giving the chip competitive clock speeds for an entry-level processor.</p><p>The reviewer tested the Core Ultra 3 205 by pairing it with a budget H810 motherboard along with 32GB of DDR5 memory. By the looks of it, the processor is capable of delivering good performance for everyday computing and can handle multiple browser tabs, as well as 8K YouTube videos at low CPU usage. In terms of power draw, the chip can draw up to 65W, and it is recommended to use a third-party CPU cooler instead of the stock Intel heatsink for better thermal performance.</p><div class="youtube-video" data-nosnippet ><div class="video-aspect-box"><iframe data-lazy-priority="low" data-lazy-src="https://www.youtube.com/embed/4N1qGZ-AeR0" allowfullscreen></iframe></div></div><p>The reviewer also ran synthetic benchmark tests to quantify the performance of the CPU, where it scored 13,394 points in Cinebench R23’s multi-core test, a 48% jump over the Core i3-14100. In terms of single-core performance, the Core Ultra 3 205 achieved 1,983 points, outperforming both the Core i3-14100 and the Core i5-14400.</p><p>Furthermore, the iGPU solution on the Core Ultra 3 205 is significantly superior to what’s offered on previous-gen Raptor Lake Refresh chips. As a result, it not only surpasses the Core i3-14100 and Core i5-14400 in 3DMark Time Spy, but also delivers performance comparable to the Core Ultra 5 225, since both feature the same 2 Xe-cores. While the integrated GPU is not powerful enough to run demanding game titles, it can handle less resource-intensive games such as DOTA and Valorant.</p><p>Considering the performance, the Core Ultra 3 205 is shaping up to be a solid entry-level option, especially for budget gaming builds. As always, pricing is going to play a big role in its appeal, with Bulls Lab suggesting the CPU is listed at 199,000 Won (approx $140), which is in line with previous reports that suggested a $150 price tag. The reviewer also points to a pre-built PC with the Core Ultra 3 205, 8GB RAM, and a 500GB SSD listed at 499,000 Won, which is roughly around $360. <br><br>Intel is yet to officially list the processor on its retail channels, and early sightings have mostly been limited to overseas markets like South Korea. Based on <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/quad-core-arrow-lake-cpu-listed-for-usd150-overseas-core-ultra-3-205-may-not-be-directly-available-in-retail-though">earlier reports</a>, the chip may end up primarily in pre-built systems or with OEM and system-integrators rather than being offered as a standalone boxed CPU. This would make it difficult for DIY PC builders to get their hands on one.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/pc-components/cpus/intel-core-ultra-3-205-delivers-impressive-results-in-early-review-reportedly-surpasses-previous-gen-core-i3-14100-and-core-i5-14400
Intel's Core Ultra 3 205 has impressed in early testing, with decent performance scores surpassing previous Intel budget picks.
fUA4MTpn8Yk5RJzYjPDSiZ
Tue, 16 Sep 2025 12:33:36 +0000 CPUs
PC Components
editors@tomshardware.com (Kunal Khullar)
Kunal Khullar
Intel
Core ultra 200S CPU
Core ultra 200S CPU
<![CDATA[ Nvidia's China-exclusive RTX 6000D reportedly gets lukewarm reception in China due to hobbled performance — could leave Nvidia with huge backlog of unwanted GPUs ]]>
<p>Nvidia's RTX6000D, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-pro-6000d-b40-blackwell-gpus-reportedly-set-to-supersede-banned-h20-accelerators-in-china">China-first card initially designed to fill the void left by the banned (and then unbanned) Nvidia H20</a>, has received very little interest in China, <a data-analytics-id="inline-link" href="https://www.reuters.com/world/china/nvidias-new-rtx6000d-chip-china-finds-little-favour-with-major-firms-sources-say-2025-09-16/" target="_blank">according to Reuters,</a> amidst ongoing trade tensions. Estimates by JPMorgan and Morgan Stanley suggest Nvidia may be on track to produce between 1.5 and 2 million of these GPUs before the end of the year, potentially leaving it sitting on a huge stack of unwanted cards.</p><p>The specific array of graphics cards that Nvidia is allowed to sell to Chinese firms has fluctuated wildly in 2025 as the Trump administration has initiated <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/china-tech-companies-scramble-to-ditch-nvidia-as-washington-tightens-export-controls">on-again, off-again tariffs and trade blockages</a>, particularly in relation to high-end technology like GPUs aimed at AI training and inference. To comply with these regulations, Nvidia has churned out Chinese-specific GPUs like <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-5090d-gpu-features-a-magnetic-shroud-and-fans-for-easy-maintenance">the RTX 5090D</a> and H20.</p><p>The RTX6000D is the latest development in this space, and was reportedly initially designed as a solution to the ban on H20 exports to the country. Although the H20 is now available once again, and Nvidia is talking up its B30A replacement based on the newer Blackwell architecture, the RTX6000D was an additional GPU design that could have found favor among AI firms scrambling for GPU power. But with ongoing trade negotiations and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/top-china-silicon-figure-calls-on-country-to-stop-using-nvidia-gpus-for-ai-says-current-ai-development-model-could-become-lethal-if-not-addressed">a major drive within China to prioritize domestically produced chips</a>, Nvidia is said to be struggling to find buyers for the new card.</p><p>The Reuters sources claim the RTX6000D only started shipping this week, but its performance has been rated lower than Nvidia's bog-standard 5090, which isn't available in China. However, it has been readily<a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-companies-allegedly-smuggled-in-usd1bn-worth-of-nvidia-ai-chips-in-the-last-three-months-despite-increasing-export-controls-some-companies-are-already-flaunting-future-b300-availability"> available on blac</a>k and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/china-repurposes-used-nvidia-gpus">grey markets in China</a> for months now, and there are even <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/upgraded-nvidia-rtx-5090-gets-128gb-vram-and-usd13-000-price-tag-super-limited-gpu-is-described-as-a-prototype#:~:text=The%20latest%20to%20join%20the,memory%20than%20your%20entire%20PC.">modded versions doing the rounds</a> with massively expanded memory capacities for even more AI performance.</p><p>The RTX6000D is based on the Blackwell architecture and has a memory bandwidth just under the 1,400 Gbps threshold placed on GPU exports to China. At a reported price of 50,000 yuan, or around $7,000, though, it's a hard sell when comparably performative cards are available in variously dubious markets for less than half of that.</p><p>China has also become increasingly hesitant over Nvidia GPU use in recent months. It <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/u-s-authorities-allegedly-placed-secret-tracking-devices-in-ai-chip-shipments-to-china-report-claims-targeted-shipments-from-dell-and-super-micro-containing-nvidia-and-amd-chips-had-trackers-in-packaging-and-servers-themselves">accused the US of adding tracking hardware to Nvidia GPUs</a> and even summoned major Chinese CEOs to question them over H20 GPU orders. Chinese authorities most recently even <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/china-accuses-nvidia-of-anti-monopoly-law-violations-raising-prospect-of-heavy-fines-company-could-be-fined-10-percent-of-revenue-from-china">accused Nvidia of violating anti-monopoly legislation</a> in a deal it made in 2020.</p><p>China and the US continue to discuss trade in Madrid this week, with major points of contention being the sale of high-end GPUs. If the US does approve the sale of Nvidia's B30A GPU, one that's<a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-next-gen-ai-chip-could-double-the-price-of-h20-if-china-export-is-approved-chinese-firms-still-consider-nvidias-b30a-a-good-deal"> several times faster than the H20 and only around twice the p</a>rice, that could end up as a huge win for Nvidia - even if it might encourage even weaker interest in the RTX6000D.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em> Tom's Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em> add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/nvidias-china-exclusive-rtx-6000d-reportedly-gets-lukewarm-reception-in-china-due-to-hobbled-performance-could-leave-nvidia-with-huge-backlog-of-unwanted-gpus
Nvidia may struggle to sell the reported two million RTX6000D Chinese GPUs it's set to produce this year, as Chinese firms are showing lukewarm interest amidst ongoing trade negotiations and the uncertain future of Nvidia's B30A GPU.
Djgk4V3AgQiqL2s47rEmEn
Tue, 16 Sep 2025 11:20:48 +0000 GPUs
PC Components
Jon Martindale
Getty Images/VCG
Jensen Huang looking surprised in a chat with media.
Jensen Huang looking surprised in a chat with media.
<![CDATA[ Desktop GPU roadmap: Nvidia Rubin, AMD UDNA & Intel Xe3 Celestial ]]>
<p>The GPU landscape has been buzzing with fresh offerings from all three major desktop GPU brands: Nvidia, AMD, and Intel. All three major manufacturers have completed their current family of GPUs, so we can expect more variants or refreshes in the future.</p><p>With the mid-range offerings from both Nvidia and AMD recently hitting the market in the form of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-rtx-5050-puts-blackwell-within-reach-of-more-gamers-at-usd249-entry-level-50-series-launches-in-late-july">RTX 5050</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-radeon-rx-9060-xt-16gb-review">RX 9060</a>, both Team Green and Red now have their eyes set on future architectures and technologies.</p><p>With so much excitement around new chips and architectures, what’s next for all three companies? We break down everything you need to know about their upcoming plans. We will keep this page consistently updated with the latest information to hand, with accurate sourcing and no rumors.</p><h2 id="nvidia-2">Nvidia</h2><div ><table><thead><tr><th class="firstcol " ><p>Architecture</p></th><th
><p>Expected Launch</p></th><th
><p>Node</p></th><th
><p>Power</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>Rubin</p></td><td
><p>Q4 2026/Q1 2027</p></td><td
><p>TSMC N3P</p></td><td
><p>TBC</p></td></tr><tr><td class="firstcol " ><p>Rubin Ultra</p></td><td
><p>H2 2027</p></td><td
><p>TSMC N3P/3N+</p></td><td
><p>TBC</p></td></tr><tr><td class="firstcol " ><p>Feynman</p></td><td
><p>TBC</p></td><td
><p>TSMC N2/Intel</p></td><td
><p>TBC</p></td></tr></tbody></table></div><p>Currently, the Nvidia RTX 50 series represents the consumer manifestation of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-blackwell-architecture-deep-dive-a-closer-look-at-the-upgrades-coming-with-rtx-50-series-gpus"><u>Blackwell architecture</u></a>, which introduced significant architectural enhancements focused on neural rendering, AI acceleration, and ray tracing performance. Built on TSMC's 4NP process node, the Blackwell consumer GPUs highlighted an uplift in AI-accelerated workloads across desktop and laptop platforms. But it wasn't a huge leap in performance across the board.</p><p>Nvidia RTX 50 series GPUs utilize TSMC's custom 4NP process technology, an enhanced variant of the foundry's N4P production node specifically tailored for Nvidia's requirements. This is a continuation of TSMC's 5nm-class manufacturing family, prioritizing mature process reliability over bleeding-edge node adoption, which allows for some degree of cost control.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="Ptr3WvxvdmUijMEpX9iCLK" name="GeForce-RTX-5090-Founders-Edition-09.jpg" alt="Nvidia GeForce RTX 5090 Founders Edition card photos and unboxing" src="https://cdn.mos.cms.futurecdn.net/Ptr3WvxvdmUijMEpX9iCLK.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>The Blackwell consumer architecture incorporates fundamental architectural improvements over Ada Lovelace, including doubled integer math throughput per clock cycle through fully unified FP32 and INT32 cores. The streaming multiprocessor (SM) design has been completely reengineered, with each SM containing 128 CUDA cores, four fifth-generation Tensor cores, one fourth-generation RT core, and four texture units alongside 256KB register files and configurable 128KB L1/shared memory.</p><p>The post-Blackwell era of Nvidia consumer graphics signals a strong shift toward neural rendering-first design philosophy, with three major architectural generations positioned to push the envelope on desktop and laptop GPU capabilities through 2029.</p><p>The <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-announces-rubin-gpus-in-2026-rubin-ultra-in-2027-feynam-after"><u>Rubin, Rubin Ultra, and Feynman architectures</u></a> plan to incorporate advanced manufacturing processes, next-generation memory technologies, and AI acceleration, which are likely to land in future desktop GPUs.</p><h2 id="nvidia-s-rubin-architecture-detailed-2">Nvidia's Rubin architecture detailed</h2><p>Nvidia's Rubin architecture is expected to be the first consumer GPU generation manufactured on TSMC's 3nm-class process technology. Projected to debut in late 2026 with the RTX 60 series, Rubin will likely transition from TSMC's 4NP node utilized by Blackwell to the more advanced <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmcs-3nm-update-n3p-in-production-n3x-on-track"><u>N3P process</u></a>, delivering significant improvements in transistor density and power efficiency.</p><p>As anticipated, the Rubin consumer GPU, powered by TSMC's 3nm node, might provide approximately 15% increased transistor density compared to the 4nm process used for RTX 50 series GPUs. This transition enables TSMC to deliver a claimed 10-15% performance improvement at equivalent power consumption, or offer a 20-30% power reduction at equivalent performance levels. However, whether or not that will hold will have to be confirmed by Nvidia itself.</p><p>Rubin GPUs are expected to debut multiple dies: a flagship (e.g., RB102) for top-end cards (RTX 6090), and cut-down dies (RB103/RB104, etc.) for RTX 6080/6070/6060 series. Consumer variants will likely follow the pattern seen in Blackwell and Ada Lovelace.</p><p>Expect the largest die for halo product, and cut-down dies for enthusiast/mainstream cards. Laptop variants will use further cut-down dies or lower TDP (Max-Q) implementations. Since Nvidia is continually shifting die cut-downs between generations, it's difficult to pinpoint exactly which might end up turning into a specific GPU class.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:3840px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="AYFysytMbhHCqPVq7sbGqX" name="Nvidia keynote 19.jpg" alt="Nvidia data center GPU roadmap 2025 showing Rubin and Rubin Ultra" src="https://cdn.mos.cms.futurecdn.net/AYFysytMbhHCqPVq7sbGqX.jpg" mos="" align="middle" fullscreen="" width="3840" height="2160" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Nvidia)</span></figcaption></figure><p>Data center Rubin dies are targeting up to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidia-unveils-dgx-station-workstation-pcs-gb300-blackwell-ultra-inside"><u>1,800W per AI chip</u></a> at the highest configuration. However, consumer desktop models will likely be dramatically lower.</p><p>To make an educated guess, the projected desktop power demand puts the flagship RTX 6090 likely in the 450–600W range, scaling down to 200W or less for mainstream models. This is an extrapolation from Blackwell and Ada Lovelace scaling, with increased efficiency due to being powered by a 3nm node.</p><p>Nvidia has confirmed that Rubin will use HBM4 in the data center. However, memory configurations for consumer Rubin GPUs are expected to utilize faster GDDR7 variants or potentially introduce GDDR7X memory technology, offering substantial bandwidth improvements over current GDDR7 implementations.</p><p>Nvidia's Rubin architecture for desktops is anticipated to be available for the consumer GeForce lineup (RTX 60 series). There is no official indication that Rubin is data center-only; Nvidia’s executive statements and annual release cadence strongly point toward the lineup's release.</p><p><a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/nvidias-rubin-gpu-and-vera-cpu-data-center-ai-platforms-begin-tape-out-both-chips-in-fab-and-on-track-for-2026">Rubin production is on track for H2 2026</a>, per official Nvidia statements and refuted delay rumors. Consumer cards are expected to be available in late 2026 or early 2027, as of the time of writing.</p><h2 id="rubin-ultra-2027-and-feynman-2028-2">Rubin Ultra (2027) and Feynman (2028)</h2><p>Following Rubin, there is no official confirmation about the consumer implementation of future architectures announced at GTC 2025, as Nvidia is traditionally an enterprise-first company. However, the architectures (<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-shows-off-rubin-ultra-with-600-000-watt-kyber-racks-and-infrastructure-coming-in-2027"><u>Rubin Ultra</u></a> and Feynman) may be used in consumer GPUs.</p><p>Feynman, like Volta (2017), may remain data center-only, but all current Nvidia statements suggest consumer implementations are planned.</p><p>Rubin Ultra, scheduled for the second half of 2027, is slated to be the successor of Rubin. At the data center level, this architecture implements quad-die GPU configurations within single packages, dramatically increasing computational density.</p><p>Rubin Ultra's quad-die implementation requires advanced packaging technologies. Whether or not this layout trickles down to consumer GPUs remains to be seen. Consumer implementations will likely utilize cost-optimized packaging approaches while maintaining the performance advantages of multi-die, or chiplet architectures.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1488px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="N3SihCScF7r2yQPrt69aHT" name="1751451790.jpg" alt="Nvidia 5060Ti" src="https://cdn.mos.cms.futurecdn.net/N3SihCScF7r2yQPrt69aHT.jpg" mos="" align="middle" fullscreen="" width="1488" height="837" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Nvidia )</span></figcaption></figure><p>The gate-all-around field-effect transistor (GAAFET) technology implementation in TSMC's 2nm variant, expected for Rubin Ultra and possibly Feynman, represents a significant departure from FinFET designs, offering enhanced optimization flexibility for either performance or efficiency targets.</p><p>Data center implementations of Rubin Ultra are currently planned to have HBM4/HBM4e memory, but it is unlikely that HBM will end up being the VRAM type used in consumer GPUs based on the Rubin Ultra and Feynman architectures.</p><p>Feynman is the company's most advanced GPU generation currently planned. Limited official information exists regarding Feynman's consumer specifications, though <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/nvidia-enterprise-roadmap-rubin-rubin-ultra-feynman-and-silicon-photonics"><u>data center roadmaps</u></a> provide architectural insights that may apply to consumer implementations.</p><p>Feynman will likely utilize either TSMC's 2nm node (N2) or potentially Intel's advanced foundry processes, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/nvidia-is-reportedly-close-to-adopting-intel-foundrys-18a-process-node-for-gaming-gpus">including <u>18A</u> or 14A nodes</a>. The architecture will likely incorporate seventh-generation Tensor cores and sixth-generation RT cores. Details on Feynman are still light, with Nvidia expected to reveal further details at future events.</p><p>Regarding an anticipated launch timeline, Rubin Ultra may launch in the second half of 2027, while Feynman GPUs are still very far off, so don't expect anything sporting the architecture until H2 2028 / H1 2029, at the very earliest. Be sure to take these dates with a dose of salt, as nothing is confirmed until Nvidia itself says so.</p><h2 id="amd-2">AMD</h2><div ><table><thead><tr><th class="firstcol " ><p>Architecture</p></th><th
><p>Expected Launch</p></th><th
><p>Process Technology</p></th><th
><p>Memory Type</p></th><th
><p>Power </p></th></tr></thead><tbody><tr><td class="firstcol " ><p>UDNA/RDNA 5</p></td><td
><p>Late 2026 - Early 2027</p></td><td
><p>TSMC 3nm / N3E</p></td><td
><p>GDDR7 (up to 32 Gbps)</p></td><td
><p>TBC</p></td></tr><tr><td class="firstcol " ><p>UDNA 2 / RDNA 6</p></td><td
><p>2028+</p></td><td
><p>TBC</p></td><td
><p>GDDR7X or next-gen VRAM</p></td><td
><p>TBC</p></td></tr></tbody></table></div><p>AMD unveiled its <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-rdna-4-radeon-rx-9000-series-gpus-revealed-targeting-mainstream-price-and-performance-with-improved-ai-and-ray-tracing"><u>RDNA 4</u></a> architecture in January 2025, followed by the RX 9000 series of cards in early March. AMD’s primary goal this generation was to target the mainstream with GPUs, in quantity, that were both affordable and performed well.</p><p>Departing from its iconic ‘XX00’ naming style in favor of the ‘X0X0’ convention for the mainstream, aligned AMD's branding style with Nvidia. AMD also elected not to introduce any enthusiast-class GPUs with RDNA 4. As such, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-radeon-rx-9070-xt-review">RX 9070 XT</a>, which likely utilizes the fully-enabled Navi 48 chip (referred to internally as Navi 48 XTX), represents the most powerful GPU we’ll get with RDNA 4.</p><p>AMD has confirmed ongoing R&D for post-RDNA 4 architectures in several presentations, emphasizing continuous improvements in compute density and AI acceleration. Codenames are not yet public, but technical documentation references “Next-Gen RDNA” under the “Growth Driver” umbrella.</p><p>AMD's discrete GPU strategy beyond the current RDNA 4 (RX 9000 series) generation centers on a significant architectural transition, moving from the established Radeon DNA (RDNA) lineage towards a potentially unified architecture, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-xe4-and-amd-gfx13-codenames-surface-for-next-gen-druid-gpus"><u>internally designated GFX13</u></a>. Crucially, AMD has <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-announces-unified-udna-gpu-architecture-bringing-rdna-and-cdna-together-to-take-on-nvidias-cuda-ecosystem">publicly confirmed</a> the development of an architecture following RDNA 4 during its Financial Analyst Day 2022 and subsequent roadmap updates, though specific branding (RDNA 5 vs. UDNA) remains officially unclarified.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:890px;"><p class="vanilla-image-block" style="padding-top:56.29%;"><img id="SbYUJuvEfoGApR9rrHh6E5" name="RX 9070 XT Hellhound" alt="RX 9070 XT Hellhound" src="https://cdn.mos.cms.futurecdn.net/SbYUJuvEfoGApR9rrHh6E5.jpg" mos="" align="middle" fullscreen="" width="890" height="501" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: PowerColor)</span></figcaption></figure><h2 id="udna-rdna-5-amd-s-next-generation-gpu-architecture-2">UDNA / RDNA 5: AMD's next-generation GPU architecture</h2><p>While AMD roadmaps historically labeled this successor "RDNA 5," current industry reports suggest a potential rebranding to "<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-announces-unified-udna-gpu-architecture-bringing-rdna-and-cdna-together-to-take-on-nvidias-cuda-ecosystem"><u>UDNA</u></a>" (Unified DNA). This signifies a strategic shift towards a single architecture foundation targeting both consumer gaming (replacing RDNA) and compute/data center workloads (replacing CDNA).</p><p>AMD publicly emphasizes the challenge and resource drain of maintaining two distinct architectures (RDNA for gaming, CDNA for compute). A unified UDNA architecture aims to simplify the software stack (particularly <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-unveils-rocm-7-new-platform-boosts-ai-performance-up-to-3-5x-adds-radeon-gpu-support">ROCm</a>), improve memory optimization consistency, and enhance forward/backward compatibility across the products, from laptops to servers.</p><p>AMD aims to streamline development, hardware design, and software optimization by adopting a consistent core Arithmetic Logic Unit (ALU) design reminiscent of the pre-RDNA Graphics Core Next (GCN) lineage, enabling compatibility across consumer gaming, AI workloads, and professional compute workloads alike.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="4eZrCtk8yyPbygdoere4cc" name="tsmc-fab-semiconductor-wafer-chip-hero.jpg" alt="TSMC" src="https://cdn.mos.cms.futurecdn.net/4eZrCtk8yyPbygdoere4cc.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>Crucially, UDNA is expected to be fabricated on TSMC’s 3nm-class manufacturing node (N3 or N3E). This will represent a substantial leap in transistor density and power efficiency over RDNA 4’s 5nm process node.</p><p>AMD has publicly stated that improving ray tracing performance is a core focus for future generations. RDNA 5/UDNA is projected to feature significantly redesigned Ray Accelerators, potentially moving more fixed-function hardware into the pipeline to alleviate shader engine burden and dramatically increase ray intersection throughput compared to RDNA 4.</p><p>The UDNA architecture may also see AMD shift back from monolithic <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/according-to-a-linkedin-profile-amd-is-working-on-another-chiplet-based-gpu-udna-could-herald-the-return-of-2-5d-3-5d-chiplet-based-configuration">to a chiplet-based design</a>, optimizing manufacturing yields and enabling finer die cutdowns.
AMD already employs a technique allowing it to produce more SKUs from a single silicon design through a technique named <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/amd-details-how-it-built-a-product-line-up-with-just-two-rdna-4-dies-flexible-design-and-asymmetric-harvesting-enables-production-of-multiple-models-without-new-silicon">asymmetric harvesting</a>. Potentially using this, can expect a range from <a data-analytics-id="inline-link" href="https://www.techpowerup.com/339101/amds-upcoming-udna-rdna-5-gpu-could-feature-96-cus-and-384-bit-memory-bus"><u>96 CUs</u></a> all the way down to 32 CUs for UDNA, with GDDR7 memory being the VRAM technology of choice.</p><p>We expect UDNA to debut in late 2026. Broader availability across desktop segments and mobile variants (RX 10000M series) might arrive in Q1-Q2 2027. However, this remains unconfirmed. We expect to hear official details on UDNA at AMD's 2025 Financial Analyst Day in November 2025.</p><h2 id="intel-2">Intel</h2><div ><table><thead><tr><th class="firstcol " ><p>Architecture</p></th><th
><p>Expected Launch</p></th><th
><p>Process Node</p></th><th
><p>Compute Units (Max)</p></th><th
><p>Memory Type</p></th><th
><p>Power</p></th></tr></thead><tbody><tr><td class="firstcol " ><p>Xe3 Celestial</p></td><td
><p>2026 - Early 2027</p></td><td
><p>Intel 18A</p></td><td
><p>TBC</p></td><td
><p>TBC</p></td><td
><p>TBC</p></td></tr><tr><td class="firstcol " ><p>Xe4 Druid</p></td><td
><p>Late 2027 - 2028</p></td><td
><p>TBC</p></td><td
><p>TBC </p></td><td
><p>TBC</p></td><td
><p>TBC</p></td></tr></tbody></table></div><p>Intel officially launched its second-generation discrete GPU family, namely Battlemage (Xe2), with the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-arc-b580-review-the-new-usd249-gpu-champion-has-arrived">Arc B580</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-arc-b570-review-asrock-challenger-oc-tested">Arc B570</a> in December 2024 and January 2025, respectively. Despite some teething issues, these GPUs were surprisingly capable, affordable, and generously equipped with 12GB/10GB of VRAM, capacities that are unheard of in the $250 market.</p><p>Intel has officially established its commitment to discrete graphics beyond the current Battlemage generation, with Co-CEO Michelle Johnston Holthaus <a data-analytics-id="inline-link" href="https://www.intel.com/content/www/us/en/events/ces.html">confirming at CES 2025</a> that Intel remains "very committed to the discrete graphics market" and will "continue to make strategic investments".</p><p>With the Battlemage (Xe2 architecture) now deployed, Intel's roadmap extends through the Xe3 "Celestial" and Xe4 "Druid" architectures, representing significant steps in Intel’s GPU design and manufacturing strategy.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="k2F24yrE2J7gp2Viej7p6m" name="Intel-Arc-B580-docimage.jpg" alt="Intel Arc B580 Limited Edition Battlemage graphics card" src="https://cdn.mos.cms.futurecdn.net/k2F24yrE2J7gp2Viej7p6m.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Intel)</span></figcaption></figure><h2 id="xe3-celestial-and-xe4-druid-2">Xe3 Celestial and Xe4 Druid </h2><p>Intel <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-says-arc-xe4-druid-gpus-are-already-in-the-works-software-optimization-is-the-only-remaining-step-for-xe3-celestial-as-it-approaches-launch-with-panther-lake">Fellow Tom Petersen confirmed</a> in December 2024 that the Xe3 Celestial architecture has been finalized, with hardware design locked and the development team transitioning to Xe4 development. Intel has not disclosed full architectural details, but Xe3 builds on Xe2's vector engines with projected refinements in compute throughput and cache hierarchies.</p><p>Celestial has progressed to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-arc-xe3-celestial-gpu-enters-pre-validation-stage">pre-silicon validation</a> as of May 2025, with Intel's OEM partners conducting virtual GPU testing for firmware development. Based on Intel's validation timeline, Celestial is expected to enter volume production by late 2025 or early 2026.</p><p>Celestial will initially debut as integrated graphics within <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-announces-18a-process-node-has-entered-risk-production-crucial-milestone-comes-as-company-ramps-to-panther-lake-chips">Intel's Panther Lake mobile processors</a>, likely utilizing Intel's 18A process node. While Intel has not officially disclosed the target process node, its alignment with the Panther Lake CPU platform (built on Intel 18A) suggests a high probability that the initial Celestial variants will utilize the same node.</p><p>Intel's focus on AI acceleration suggests higher memory capacities will be prioritized to support emerging AI inference workloads alongside traditional gaming applications.</p><p>Discrete Celestial GPUs are not expected until after the architecture debuts in integrated form within Panther Lake mobile CPUs. Based on typical development cycles, volume production of discrete Celestial GPUs might not begin until late 2026, with availability beginning in early 2027. However, this remains unconfirmed until Intel itself offers up more information.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1280px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="W4hyK9JHiaswZLNdXDNEJ7" name="intel-arc-feature.jpg" alt="Intel Arc Alchemist" src="https://cdn.mos.cms.futurecdn.net/W4hyK9JHiaswZLNdXDNEJ7.jpg" mos="" align="middle" fullscreen="" width="1280" height="720" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: Intel)</span></figcaption></figure><p>For<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-says-arc-xe4-druid-gpus-are-already-in-the-works-software-optimization-is-the-only-remaining-step-for-xe3-celestial-as-it-approaches-launch-with-panther-lake"> Xe4 Druid</a>, Intel has confirmed hardware work is underway, as Petersen noted, "The hardware teams are off on to the next thing (Xe4)". This architecture is projected as a modular redesign, potentially incorporating hybrid tiles for graphics and media, as hinted in Intel's June 2025 leaks on <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/intel-nova-lake-cpus-reportedly-get-a-gpu-overhaul-xe3-celestial-and-xe4-druid-ips-used-for-graphics-media-and-display">Nova Lake iGPUs</a> using Xe3/Xe4 combinations, though discrete details are absent.</p><p>Petersen also noted that Intel's development lifecycles can exceed one year, meaning that it's likely that we won't see this particular architecture materialize for desktop system use for quite some time, so don't hold your breath for Druid until 2026, or beyond.</p><p><em>We will continue to keep this page updated as soon as we hear any official details. </em></p>
https://www.tomshardware.com/pc-components/gpus/desktop-gpu-roadmap-nvidia-rubin-amd-udna-and-intel-xe3-celestial
We put our thinking caps on to come up with a desktop GPU roadmap for all brands, with all of the expected details for what's to come for Nvidia, AMD, and Intel's next-generation architectures.
5HZL59D9fjmgP6zd2SxkwT
Tue, 16 Sep 2025 11:00:39 +0000 GPUs
PC Components
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
Nvidia
Nvidia AD102 Die Shot
Nvidia AD102 Die Shot
<![CDATA[ Start-up hails world's first quantum computer made from everyday silicon — fits in three 19-inch server racks and is touted as 'quantum computing's silicon moment' ]]>
<p>A UK start-up says that it has built the world’s <a data-analytics-id="inline-link" href="https://quantummotion.tech/quantum-motion-delivers-the-industrys-first-full-stack-silicon-cmos-quantum-computer/" target="_blank">first full-stack quantum computer</a> using the same silicon chip technology used in laptops and phones, and it has already been installed at the UK’s National Quantum Computing Centre (NQCC).</p><p>Quantum Motion, a 2017 spinout from University College London and Oxford, unveiled the three-rack system on September 15 as part of a government-backed push to commercialize scalable quantum hardware. Built entirely on a conventional CMOS process, the machine is being pitched as “quantum computing’s silicon moment,” which can be fabricated in commercial foundries and dropped into existing server infrastructure.</p><p>At least, that’s the idea. Unlike superconducting or photonic systems, Quantum Motion’s system is built around a silicon spin-qubit processor, housed in a tileable architecture that is designed to scale. The company says that the entire stack, including cryogenics and control systems, fits into three standard 19-inch racks. It also supports existing software frameworks like Qiskit and Cirq, allowing developers to build and run quantum workloads without having to reinvent the tooling.</p><p>But for all the talk of standard chips and data center form factors, the company hasn’t revealed any data that actually demonstrates performance. There’s no disclosed qubit count, no gate fidelities, no coherence times, and no early benchmarks. There’s also no confirmation of how — or whether — the system handles error mitigation or connectivity scaling, the key hurdles facing every current quantum platform.</p><p>It’s also not the first system to show up at the NQCC. Oxford Ionics installed a trapped-ion setup earlier this year, and several other UK projects are contributing hardware and firmware under the national program. What Quantum Motion is claiming is not first-to-ship, but first to build a full-stack quantum machine entirely using standard silicon CMOS manufacturing, and to fit the whole thing into a datacenter-friendly rack footprint.</p><p>Most current-gen quantum systems live in fridge-sized enclosures and require bespoke power, plumbing, and thermal integration. Getting that down to three racks, including the dilution fridge, is a notable engineering win. But without published specs or real workloads, it’s impossible to know how far the platform goes beyond being a neat demonstration. That’s now up to the NQCC, which will validate and test the system in the coming months.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><u><em>Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/tech-industry/supercomputers/uk-start-up-quantum-computer-runs-on-standard-chips
A UK start-up says that it has built the world’s first full-stack quantum computer using the same silicon chip technology used in laptops and phones.
jAwDGUnzRG2SVDNh4mJiA8
Tue, 16 Sep 2025 10:45:02 +0000 Supercomputers
Tech Industry
lukejamesalden@gmail.com (Luke James)
Luke James
Quantum Motion
A graphical representation of Quantum Motion&#039;s quantum computing technology.
A graphical representation of Quantum Motion&#039;s quantum computing technology.
<![CDATA[ Rare Apple-1 with storied ownership could fetch over $300,000 at auction — unit housed in original wood case thought to be one of just nine surviving examples ]]>
<p>A rare and fully functional Apple-1 with its rare Byte Shop wooden case is up for auction right now. Thought to be one of just nine surviving samples remaining in the original wood case, bidding on Lot #7083 will conclude on Saturday, September 20, 2025. You can join the RR Auctions <a data-analytics-id="inline-link" href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0">Remarkable Rarities</a> event in person at 1 pm EST (Boston, MA), by phone, or online (worldwide).</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="ehEQAZK2scwZ6n4gAvvSL5" name="case-detail" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/ehEQAZK2scwZ6n4gAvvSL5.jpg" mos="" align="middle" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure><p>The estimate for this wooden tech history marvel from 1976 is $300,000+. It has already achieved $144,311 in pre-live bidding.</p><p>As mentioned in the intro, this is a fully functional <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/smartykit-apple-i-replica-builder">Apple-1</a>, and it also comes with “all components and accessories required for operation,” according to the listing. Alongside the computer, in good working condition, you will get a cassette interface, keyboard, monitor, and software. These are all original and era-appropriate.</p><p><strong>The set includes:</strong></p><ul><li>Original Apple-1 board, marked on the reverse with "01-0020"</li><li>Original Apple Cassette Interface (ACI) board</li><li>Original Byte Shop wooden case with built-in Datanetics keyboard and Triad power supply</li><li>Period-correct video monitor and associated cables</li><li>Period-correct copies of software on cassette tapes, with contemporary handwritten notes and instructions</li><li>Modern copy of the Apple-1 Operation Manual</li></ul><p>As it stands, this rare computer would be a desirable item, but its appeal is lifted further because it was owned by the first female graduate of Stanford Law School, June Blodgett Moore.</p><p>The condition of the computer is graded at 8.0/10 by the auction house. As such an old tech artifact, there are issues impacting the score. For example, RR Auctions notes a hairline crack on part of the case and a section of rear paneling that has been removed to provide access to cabling.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:38.81%;"><img id="ocGD53GpHfmRisPwV2iAL5" name="rear" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/ocGD53GpHfmRisPwV2iAL5.jpg" mos="" link="" align="" fullscreen="" width="1600" height="621" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:59.44%;"><img id="ieZYtLmQPp3XHGm9criLL5" name="pcb2" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/ieZYtLmQPp3XHGm9criLL5.jpg" mos="" link="" align="" fullscreen="" width="1600" height="951" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:69.50%;"><img id="NgyTa9YdHbhpoc923YNyK5" name="pcb1" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/NgyTa9YdHbhpoc923YNyK5.jpg" mos="" link="" align="" fullscreen="" width="1600" height="1112" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure></div></div></div><p>Inside, this Apple-1 is a great period example. The auctioneers point out that the PCB is marked ‘Apple Computer 1, Palo Alto, Ca. Copyright 1976’ and its breadboard prototyping area “is untouched and the green coat exhibits some minor scuffs but minimal peeling, unlike many Apple-1 boards.” Other points of note are its white ceramic MOS 6502 processor and all three original Sprague 'Big Blue' capacitors. Some power supply diodes have been replaced, but carefully swapped with period-correct replacements.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:85.44%;"><img id="ntPYwN2cY2aqi3ZqSkpLL5" name="software" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/ntPYwN2cY2aqi3ZqSkpLL5.jpg" mos="" link="" align="" fullscreen="" width="1600" height="1367" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 2</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1600px;"><p class="vanilla-image-block" style="padding-top:72.00%;"><img id="JWrcmbxSqVRUZxJHXzaRK5" name="monitor" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/JWrcmbxSqVRUZxJHXzaRK5.jpg" mos="" link="" align="" fullscreen="" width="1600" height="1152" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure></div></div></div><h2 id="wooden-case-history-2">Wooden case history</h2><p>The wooden case seen used for this model was implemented to elevate the Apple-1 beyond being a Homebrew Computer Club kit aimed at DIYers. The Byte Shop in Mountain View, California, insisted on completed kits being supplied for its retail operation. Steve Jobs and Steve ‘Woz’ Wozniak complied by supplying 50 units in this wooden case. It would be one of the first personal computers available to consumers that didn’t require assembly.</p><p>The retail deal meant that The Byte Shop bought 50 Apple-1 computers in wood cases for $500 a piece, and resold them at $666.66. Wozniak would recount, “That was the biggest single episode in all of the company's history. Nothing in subsequent years was so great and so unexpected.”</p><h2 id="steven-jobs-check-2">Steven Jobs Check</h2><p>Another Apple-flavored auction that concludes on Saturday is for a 'Steven Jobs' signed Apple Computer Company check. The check was drawn up for $10 on June 25, 1976. At this time, the company was still operating from the Jobs family garage.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:800px;"><p class="vanilla-image-block" style="padding-top:49.13%;"><img id="UuJUkhfFuimfkCCTxwT5J5" name="steve-check" alt="Byte Shop wooden cased Apple-1 computer auction" src="https://cdn.mos.cms.futurecdn.net/UuJUkhfFuimfkCCTxwT5J5.jpg" mos="" align="middle" fullscreen="" width="800" height="393" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: <a href="https://www.rrauction.com/auctions/lot-detail/350542107267083-apple-1-computer-with-rare-byte-shop-wooden-case-a-high-grade-fully-functional-example/?cat=0" target="_blank">RR Auctions</a>)</span></figcaption></figure><p>This check is encapsulated and graded as a ‘Mint 9’ and was expected to fetch $25,000. However, it has already hit $24,655 in pre-live bidding, so it should go somewhat higher on Saturday</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/pc-cases/rare-apple-1-with-storied-ownership-could-fetch-over-usd300-000-at-auction-unit-housed-in-original-wood-case-thought-to-be-one-of-just-nine-surviving-examples
A rare Apple-1 housed in its original wooden case is expected to fetch more than $300,000 at auction.
Dnr7KP3Pn3GFD3Z4Ak4Vh3
Tue, 16 Sep 2025 10:37:37 +0000 PC Cases
PC Components
Mark Tyson
RR Auctions
Byte Shop wooden cased Apple-1 computer auction
Byte Shop wooden cased Apple-1 computer auction
<![CDATA[ Google terminates 200 AI contractors — 'ramp-down' blamed, but workers claim questions over pay and job insecurity are the real reason behind layoffs ]]>
<p>Google has laid off over 200 contractors who worked on improving its AI product offerings, Gemini, and search AI overviews, <a data-analytics-id="inline-link" href="https://www.wired.com/story/hundreds-of-google-ai-workers-were-fired-amid-fight-over-working-conditions/" target="_blank">according to Wired</a>. Some were told it was part of a "ramp-down" on the project they were working on, but others believe it was due to complaints made over pay and working conditions. These laid-off contractors join hundreds of other AI-related contractors who have been fired from other major AI firms like xAI and Meta in recent months.</p><p>For the first half of 2025, AI growth was everywhere, and all the major companies were spending big to try to get ahead. Meta was offering individuals <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/sam-altman-says-meta-is-offering-obscene-usd100m-bonuses-to-poach-ai-employees-and-even-bigger-salaries-openai-ceo-says-none-of-our-best-people-decided-to-take-them-up-on-that">hundreds of millions to join its ranks</a>, and entire companies were swallowed up in the race to be the first to the next big development in AI technology. But while <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/openai-signs-contract-to-buy-usd300-billion-worth-of-oracle-computing-power-over-the-next-five-years-company-needs-4-5-gigawatts-of-power-enough-to-power-four-million-homes">announcements of enormous industry deals continue</a>, there's also a lot of talk of contraction, particularly when it comes to lower-level positions like data annotation and AI response rating.</p><p>In the case of Google's latest firings, the contractors mostly worked at GlobalLogic, a software developer owned by Hitachi. Per the report, workers on the 'super rater' program were required to have either a PhD or a master's, and were tasked with moderating AI responses.</p><p>Google seemingly didn't need that expertise any longer, though. It has reportedly been working on developing an AI model for rating AI responses, though it's not clear if that's matured enough to take over what the human raters were doing. The <em>Wired</em> report even cites some workers worried "they are being set up to replace themselves."</p><p>Instead, many of them believe that it is their complaints over compensation that lead to them being laid off. <em>Wired</em> states that workers "attempted to unionize" earlier in the year to no avail. According to the report, "they allege that the company has retaliated against them." Two have filed complaints with the National Labor Relations Board. For its part, Google said in a statement that GlobalLogic is responsible for the working conditions of its employees.</p><p>AI developmental companies have been repeatedly accused of using underpaid human workers to classify AI data and rate responses to improve their services. The company Meta invested almost $15 billion to poach their CEO, <a data-analytics-id="inline-link" href="https://en.wikipedia.org/wiki/Scale_AI#Remotasks" target="_blank">ScaleAI, was accused of using low-paid workers in Southeast Asian countries</a> to build out its data annotation services. After Meta bought a 49% stake in the company, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/scale-ai-lays-off-200-employees-one-month-after-metas-usd14-billion-investment-says-it-scaled-up-too-quickly">over 200 of its staff were cut</a>.</p><p>Just a few days ago,<a data-analytics-id="inline-link" href="https://www.businessinsider.com/elon-musk-xai-layoffs-data-annotators-2025-9" target="_blank"> xAI also announced it was laying off around a third of its data annotation team</a>, amounting to over 500 workers. However, unlike Google, company messaging suggests this is to pivot towards more specialist AI trainers.</p><p>That may mean employment opportunities for some of the AI trainers Google let go, but it does make it clear what a shaky industry this is to get into. The big AI developers don't appear to have a coherent strategy for how to improve their products in the near term and are taking different approaches in doing so.</p><p>All the firings come in stark contrast to the major AI developer hiring sprees that companies like Meta went on earlier this year. While low-paid data annotators may have limited employment prospects at the big firms, there is less concern over hiring big names and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/abel-founder-claims-meta-offered-usd1-25-billion-over-four-years-to-ai-hire-person-still-said-no-despite-equivalent-of-usd312-million-yearly-salary">rising stars for hundreds of millions of dollars</a>.</p><p>Although Meta and others have seriously slowed their spending in recent weeks, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/despite-whispers-of-a-bubble-openai-is-planning-a-gigawatt-scale-data-center-in-india">massive expansion projects in the AI industry</a> continue unabated.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/tech-industry/artificial-intelligence/google-terminates-200-ai-contractors-ramp-down-blamed-but-workers-claim-questions-over-pay-and-job-insecurity-are-the-real-reason-behind-layoffs
Google has fired over 200 AI response rating contractors as part of what it claims is a "ramping down" of that role. They join hundreds of other low-paid AI workers who have been let go at various AI developers in recent weeks.
QcF3wM4qbNHbkwoKzxQhyi
Tue, 16 Sep 2025 10:21:14 +0000 Artificial Intelligence
Tech Industry
Jon Martindale
Getty Images/Bloomberg
Google CEO Sundar Pinchai waving.
Google CEO Sundar Pinchai waving.
<![CDATA[ Nvidia tipped to be TSMC's first 16A customer, ahead of Apple — Feynman GPUs could make full use of GAA transistors and backside power
]]>
<p>Nvidia will be the first customer to use TSMC’s A16 node, a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmcs-1-6nm-node-to-be-production-ready-in-late-2026-roadmap-remains-on-track">1.6nm-class process</a> that marries gate-all-around (GAA) transistors with backside power delivery, according to China's <a data-analytics-id="inline-link" href="https://www-ctee-com-tw.translate.goog/news/20250915700077-430501?_x_tr_sl=auto&_x_tr_tl=en&_x_tr_hl=en" target="_blank"><em>Commercial Times</em></a>. This is no small change in tradition: For more than a decade, Apple has been the one to break in each new process node from TSMC, with its iPhone SoCs serving as the high-volume anchor tenant.</p><p>But that tradition ends here. A16's first customer isn't building phones; its chips are designed for AI and other applications with extreme power delivery requirements. As TSMC’s <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design">first commercial node to integrate backside power delivery</a> — which lifts power rails off the front and routes them through the back of the wafer — the foundry is pitching A16 as the natural progression from its N2 process.</p><p>If reports that Nvidia plans to skip this N2 process for its upcoming Feynman architecture in favor of A16 are true, that could make Feynman the first GPU, and the first chip of any kind, to combine GAA and backside power in production.
Nvidia has historically waited for process maturity before adopting new nodes. Hopper was on TSMC’s 4N, not N5, and Blackwell's data center products use 4NP. Feynman potentially changes that by putting Nvidia at the bleeding edge, ahead of even Apple, suggesting that the company views AI as the driver of its most advanced silicon.</p><h2 id="what-makes-a16-different-2">What makes A16 different?</h2><p>A16 is more than a shrink. It’s the first TSMC process to feature both GAA nanosheet transistors and backside power delivery. By shifting power delivery to the backside, signal routing on the front side becomes less constrained, reducing congestion and improving performance. Power reaches the transistors via a shorter, less resistive path, thereby reducing voltage drop and enabling higher frequencies or tighter integration.</p><p>TSMC claims that A16 delivers 8-10% higher speed or 15-20% lower power compared to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmcs-2nm-n2-process-node-enters-production-this-year-a16-and-n2p-arriving-next-year">baseline N2</a>, plus a modest 7-10% density gain. The real benefit isn’t in the numbers, but rather what they unlock. With more available routing and cleaner power, large chips like GPUs gain new architectural freedom with wider cores, larger caches, more AI engines, and better scaling.</p><p>And because backside power delivery frees front-side metal for signals, it simplifies high-density hybrid bonding on the top surface. This makes 3D-stacked cache or vertically integrated SRAM more practical, and eases front-side congestion around wide I/O like HBM physical layers (PHYs), provided the design also employs fine-pitch hybrid bonding and adequate thermal mitigation at the package level.</p><h2 id="the-pressure-is-on-2">The pressure is on</h2><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2560px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="4eZrCtk8yyPbygdoere4cc" name="tsmc-fab-semiconductor-wafer-chip-hero.jpg" alt="TSMC" src="https://cdn.mos.cms.futurecdn.net/4eZrCtk8yyPbygdoere4cc.jpg" mos="" align="middle" fullscreen="" width="2560" height="1440" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="credit" itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>Nvidia’s decision to lead with A16 suggests that GPU designs are now pressing against front-side power delivery limits on advanced nodes. Moving power to the backside shortens the supply path and frees front-side interconnect, mitigating IR drop and routing congestion that become bottlenecks. In other words, these factors are turning backside power delivery into an architectural necessity for AI and HPC applications.</p><p>It also helps Nvidia leapfrog the competition. AMD is reportedly targeting standard 2nm for its next-gen EPYC and MI400-class accelerators. Intel’s 18A node is also expected to offer backside power through PowerVia around the same time. By moving straight to A16, Nvidia avoids this middle ground entirely and could potentially land with a full node advantage over its rivals with a chip based on <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/nvidia-enterprise-roadmap-rubin-rubin-ultra-feynman-and-silicon-photonics">Feynman architecture</a> as early as 2028.</p><p>Naturally, gaining this edge won’t be cheap. Wafer pricing for A16 is rumored to exceed $30,000 based on N2 pricing, which far exceeds <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/tsmcs-wafer-pricing-now-usd18-000-for-a-3nm-wafer-increased-by-over-3x-in-10-years-analyst">Apple’s typical wafer costs</a>. But for Nvidia, where a single AI GPU can retail for tens of thousands, that premium might be easier to absorb. More importantly, Nvidia is betting that the node’s density and efficiency gains will more than offset the cost and lock in the company’s lead for the second half of the decade.</p><h2 id="a-calculated-shift-2">A calculated shift</h2><p>Handing A16’s debut to Nvidia is a calculated shift for Nvidia. While Apple remains a major partner and is still expected to adopt baseline N2 for its 2026 iPhone 18 chips, Nvidia’s AI chips offer faster demand growth and a use case that showcases the A16’s strengths. AI chips are power hungry, bandwidth-constrained behemoths sensitive to layout limitations — and A16 has been built to address all these things.</p><p>It’s also not unthinkable to see this as a hedge against Intel. With its 18A process approaching, which also features a backside power solution, TSMC needs a flagship customer to prove it can execute at the same or higher level. Getting Feynman out the door on A16 before Intel gets any third-party 18A designs will help to reinforce TSMC’s leadership.</p><p>If Feynman on A16 is a success, it will ultimately set the tone for the next generation of AI silicon. Nvidia will have proven that backside power is not just viable but essential for extreme compute. That could force AMD, Intel, and others to accelerate their own roadmap decisions or risk falling behind on performance.</p><p>It may also reshape how packaging and architectures evolve. Designers will need new thermal models and power domain strategies to work with backside power delivery. Still, Nvidia’s status as the first to move in this territory will give it a leg-up in tooling and methodology — advantages that are difficult to copy.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em> Tom's Hardware on Google News</em></a><em> to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button.</em></p>
https://www.tomshardware.com/tech-industry/semiconductors/nvidia-dethrones-apple-to-debut-tsmc-a16
Nvidia will be the first customer to use TSMC’s A16, a 1.6nm-class process that marries gate-all-around (GAA) transistors with backside power delivery.
DY74DD8Rx6FwE7Aez9QCSJ
Tue, 16 Sep 2025 10:17:43 +0000 Semiconductors
Tech Industry
Manufacturing
lukejamesalden@gmail.com (Luke James)
Luke James
Getty Images - Annabelle Chich/ Stringer
TSMC building with logo
TSMC building with logo
<![CDATA[ Researchers embed digital 'fingerprints' into 3D printed parts — tech may make future ghost guns more traceable ]]>
<p>Netanel Raviv and a team at the McKelvey School of Engineering (part of Washington University in St. Louis) are continuing to develop a way to embed traceable digital 'fingerprints' into 3D-printed objects.<br><br>Initially reported by <a data-analytics-id="inline-link" href="https://3dprintingindustry.com/news/washington-university-team-develops-embedded-fingerprints-to-track-ghost-guns-and-3d-printed-parts-244362"><u>3D Printing Industry</u></a>, the markers are designed in a way to be detectable, even if the printed object has been broken, because they can be identified with just a fragment of the object. Depending on the fingerprint, information such as what printer was used and when the object was created can be embedded in the print.</p><p>One of the biggest practical use cases for this development is, of course, forensics. Traceable fingerprints are crucial for helping law enforcement track ghost gun manufacturing operations. We reported on a similar approach just a few months ago in which police were able to <a data-analytics-id="inline-link" href="https://www.tomshardware.com/3d-printing/police-link-3d-printers-to-ghost-guns-using-fingerprints-from-printers-toolmarks-left-behind-during-printing-can-make-ghost-guns-traceable"><u>identify markers</u></a> left behind when printing.</p><p>The process, created by the team at Washington University, is known as Secure Information Embedding and Extraction (or SIDE for short). The fingerprinting process adds a permanent marker to the object, which can be deciphered later to determine any data factors that were put in during the printing process, such as the owner of the printer that was used. <br><br>Details on exactly how this is done are scarce, with Raviv saying it's accomplished through "mathematical contributions and new security mechanisms." Perhaps the point is to keep potential bad actors from attempting to subvert the technology. But given that these are plastic objects, it's also unclear how traceable a print might be if someone just takes a minute or two to melt the print after using it.</p><p>This development is an extension of Raviv's previous work, which was presented in 2024 at the IEEE International Symposium. Last year, the focus was mainly on the ability to recover information from broken 3D-printed parts. Now it seems the effort is in placing intentional markers into the 3D printing process so they can be more easily interpreted in the future.</p><p>At the moment, it's nearly impossible to determine much about the machine used to print an object by studying the object alone. That doesn't mean we won't see more efforts to change that as time goes on. After all, 2D printer makers have embedded model-identifying dots in printers since the 1980s (though it wasn't disclosed until much later).</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q="><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/3d-printing/researchers-embed-digital-fingerprints-into-3d-printed-parts-tech-may-make-future-ghost-guns-more-traceable
Washington University researchers have developed a way to embed traceable fingerprints into 3D printed objects, which could make it easier to track ghost guns in the future.
pZfN3fpx8eaGXowt4m3T3W
Tue, 16 Sep 2025 10:00:00 +0000 3D Printing
Ash Hill
Vvzvlad (Creative Commons 3)
The Liberator Gun
The Liberator Gun
<![CDATA[ China's entry-level GPU with AMD RX 550-level of performance is ready for tapeout — Loongson 9A1000 is finally off the drawing board and headed to fabs ]]>
<p>Having started its development in 2023, Loongson Technology's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/chinese-loongson-gpu-promises-rx-550-level-performance-likely-arriving-in-2025">9A1000</a> graphics card is one step closer to the finishing line. According to Chinese media outlet <a data-analytics-id="inline-link" href="https://www.ithome.com/0/883/160.htm">ITHome</a>, the development of the 9A1000 has been completed, and the graphics card will begin tapeout in the third quarter of this year.</p><p>The 9A1000 is Loongson's first graphics card, marking a significant milestone for the Chinese manufacturer, which had previously focused mainly on processors. The company positions the 9A1000 as an entry-level graphics card that supports AI acceleration. Therefore, it doesn't compete in the same segment as the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/chinas-first-6nm-domestic-gpu-with-purported-rtx-4060-like-performance-has-powered-on">Lisuan G100</a>, another Chinese graphics card, that allegedly rivals the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-review-asus-dual">GeForce RTX 4060</a>.</p><p>Although we've been aware of the 9A1000 for some time, we still don't know its exact specifications. Loongson has kept details under wraps, only hinting that it offers performance similar to the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/amd-radeon-rx-550-2gb,5034.html">Radeon RX 550</a>, a card that was released eight years ago. However, it's too early to call it a win for Loongson, since the manufacturer still has to evaluate the 9A1000 after the tapeout.</p><p>The latest update on the 9A1000 indicates that Loongson has apparently reduced the area of the stream processor by 20%. The manufacturer also claims that it has increased the 9A1000's operating frequency by 25%, while optimizing power consumption during light loads by 70%. In terms of feature set, the 9A1000 supports OpenGL 4.0 and OpenCL ES 3.2 APIs.</p><p>According to Looongson, the 9A1000 is up to 4X faster than the LG200, the integrated graphics unit inside the 2K3000 processor. The 9A1000 also provides up to 40 TOPS of AI computing power, which is slightly below that of AMD's XDNA 2 NPU inside the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amds-beastly-strix-halo-ryzen-ai-max-debuts-with-radical-new-memory-tech-to-feed-rdna-3-5-graphics-and-zen-5-cpu-cores">Ryzen AI Max+</a> (codenamed Strix Halo) chips, which deliver up to 50 TOPS.</p><p>The 9A1000 isn't the only graphics card on Loongson's plate. The company is also working on the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/next-gen-chinese-gpu-touts-rtx-2080-level-performance-loongson-claims-9a2000-is-up-to-10x-faster-than-the-9a1000">9A2000,</a> which it claims is up to 10X faster than the 9A1000, with performance levels comparable to those of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/nvidia-geforce-rtx-2080-founders-edition,5809.html">GeForce RTX 2080</a>. There are also plans for a 9A3000, a follow-up to the 9A2000, but no known specifications are available yet.</p><p>Although it may not be immediately apparent, numerous Chinese corporations and startups have entered the graphics card industry. However, many of these entities fail and subsequently cease operations. Therefore, we only hear news about the more prominent firms, such as Biren, Moore Threads, and, in recent years, Loongson and Lisuan Technology.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/chinas-entry-level-gpu-with-amd-rx-550-level-of-performance-is-ready-for-tapeout-loongson-9a1000-is-finally-off-the-drawing-board-and-headed-to-fabs
Chinese manufacturer Loongson Technology has completed development on the company's 9A1000 graphics card, and it's ready for tapeout.
mvfUyXH7DB52WNCeBhtRJ4
Mon, 15 Sep 2025 18:19:46 +0000 GPUs
PC Components
Zhiye Liu
Loongson
Loongson 9A1000
Loongson 9A1000
<![CDATA[ ASRock's revamped AI Quickset WSL virtualization tool makes it easy to run Linux AI apps on Windows ]]>
<p>ASRock released a special AI tool a few years back that gave users the ability to easily and quickly deploy AI applications on PCs with supported AMD or Intel GPUs. The board maker has announced its second iteration of the app, known as<a data-analytics-id="inline-link" href="https://www.asrock.com/news/index.us.asp?iD=5692"> AI Quickset WSL</a>, that further enhances the tool's capabilities. Giving users an environment that can easily deploy AI apps made specifically for Linux on Windows machines without dealing with a complicated setup process.</p><p>The app takes advantage of Microsoft's WSL virtual compatibility layer to achieve this. WSL is essentially a GUI-less virtual machine natively supported in the latest versions of Windows that allows users to run Linux apps in Windows through virtualization. AI Quickset WSL is built on AMD's ROCm platform to provide all the necessary setup configuration to run Linux AI-based apps efficiently on AMD's RX 7900 series GPUs or newer.</p><p>ASRock's tool is designed to automate all of the complicated parts of running AI applications on Windows. Depending on the method, installing and running AI models on a PC can be tough. You need to account for what hardware you have and what runtime(s) that hardware supports. You might also need to manually tweak the LLM's optimizations under the hood so it runs well on your hardware, if you're going with a manual setup.</p><p>Making matters worse, most "cutting-edge" AI applications are typically optimized for Linux, making it even harder for Windows users to get these apps up and running in Windows (if at all). AI QuickSet WSL essentially turns the process of running AI apps into a simplified wizard, with a GUI that provides a step-by-step process for whatever model you want to run (so long as it's also supported by AI QuickSet WSL). ASRock's app also includes several AI models ready to be used, such as audio, image, text, and object translators and detectors.</p><p>The original version of AI Quickset was only capable of configuring AI applications that were designed with either Windows or Linux in mind. AI Quickset WSL expands upon this and again allows users the freedom to run Linux-based AI apps on Windows, which is a huge deal if you dabble in AI models that are mostly regulated to the Linux space. But, just like most AI software, AI Quickset's minimum hardware requirements are high, requiring either Intel 12th Gen or newer or AMD Ryzen 5000 or newer CPUs, 64GB of memory, and ASRock's RX 7900 series or later graphics cards.</p>
https://www.tomshardware.com/tech-industry/artificial-intelligence/asrocks-revamped-ai-quickset-wsl-virtualization-tool-makes-it-easy-to-run-linux-ai-apps-on-windows
ASRock has developed a new iteration of its AI Quickset tool that provides users with an automated method of deploying Linux-based AI models on Windows with the help of virtualization.
DJGobrNZfTEGaq9wAdwcv4
Mon, 15 Sep 2025 18:01:16 +0000 Artificial Intelligence
Tech Industry
editors@tomshardware.com (Aaron Klotz)
Aaron Klotz
ASRock
ASRock AI Quickset WSL
ASRock AI Quickset WSL
<![CDATA[ Is Borderlands 4 the new Crysis? Official GPU setting recommendations peg 4K performance with the RTX 5090 at 60 FPS, with DLSS and frame generation enabled ]]>
<p>Video game publisher 2K Games has released an extensive list of recommended graphics settings for <em>Borderlands 4</em> across Nvidia and AMD GPUs at 1080p, 1440p, and 4K. These presets are said to offer players a reliable baseline, something that many found missing right after the game’s launch last week.</p><p>The official requirements for <em>Borderlands 4 </em>highlight just how demanding the game is across GPU generations, and the results aren’t flattering by any means. If we look at Nvidia, the minimum requirements list the RTX 2070, which can barely scrape by at 1080p, managing just 30 FPS with DLSS upscaling, along with low settings for textures, shadows, and foliage. A smoother 60 FPS gaming experience at 1080p requires an RTX 3060 Ti. If you want to play the game smoothly at 1440p with 60 FPS, the RTX 3080 12GB is the minimum requirement, but not without DLSS and demanding texture features set to medium.</p><div ><table><caption>Recommended graphics settings for Borderlands 4 at 1080p</caption><tbody><tr><td class="firstcol empty" ></td><td
><p><strong>RTX 2070 (30 FPS)</strong></p></td><td
><p><strong>RTX 2080 Ti (30 FPS)</strong></p></td><td
><p><strong>RTX 3050 8GB (30 FPS)</strong></p></td><td
><p><strong>RTX 3060 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 3070 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 3080 12GB (60 FPS)</strong></p></td><td
><p><strong>RTX 3090 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 4060 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 4070 Ti Super (60 FPS)</strong></p></td><td
><p><strong>RTX 4080 Super (60 FPS)</strong></p></td><td
><p><strong>RTX 4090 (60 FPS)</strong></p></td><td
><p><strong>RTX 5050 (60 FPS)</strong></p></td><td
><p><strong>RTX 5060 (60 FPS)</strong></p></td><td
><p><strong>RTX 5060 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 5070 (60 FPS)</strong></p></td><td
><p><strong>RTX 5070 Ti (60 FPS)</strong></p></td><td
><p><strong>RTX 5080 (60 FPS)</strong></p></td><td
><p><strong>RTX 5090 (60 FPS)</strong></p></td></tr><tr><td class="firstcol " ><p><strong>Display mode</strong></p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td><td
><p>Full-screen</p></td></tr><tr><td class="firstcol " ><p><strong>V-Sync</strong></p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td><td
><p>Off</p></td></tr><tr><td class="firstcol " ><p><strong>Anti-aliasing</strong></p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td></tr><tr><td class="firstcol " ><p><strong>Upscaling method</strong></p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td><td
><p>DLSS</p></td></tr><tr><td class="firstcol " ><p><strong>Upscaling quality</strong></p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td><td
><p>Quality</p></td></tr><tr><td class="firstcol " ><p><strong>DLSS FG</strong></p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td></tr><tr><td class="firstcol " ><p><strong>DLSS MFG</strong></p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>-</p></td><td
><p>2X</p></td><td
><p>2X</p></td><td
><p>2X</p></td><td
><p>2X</p></td><td
><p>4X</p></td><td
><p>4X</p></td><td
><p>4X</p></td><td
><p>4X</p></td><td
><p>4X</p></td><td
><p>4X</p></td><td
><p>4X</p></td></tr><tr><td class="firstcol " ><p><strong>Nvidia Reflex</strong></p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td><td
><p>On</p></td></tr><tr><td class="firstcol " ><p><strong>HLOD loading range</strong></p></td><td
><p>Near</p></td><td
><p>Medium</p></td><td
><p>Near</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Medium</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td><td
><p>Far</p></td></tr><tr><td class="firstcol " ><p><strong>Geometry quality</strong></p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Low</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td></tr><tr><td class="firstcol " ><p><strong>Texture quality</strong></p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Low</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Textures streaming speed</strong></p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Anisotropic filtering quality</strong></p></td><td
><p>Off</p></td><td
><p>x4</p></td><td
><p>Off</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x16</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x16</p></td><td
><p>x16</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x4</p></td><td
><p>x16</p></td><td
><p>x16</p></td><td
><p>x16</p></td></tr><tr><td class="firstcol " ><p><strong>Foliage density</strong></p></td><td
><p>Off</p></td><td
><p>Very low</p></td><td
><p>Off</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Volumetric fog</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Volumetric cloud</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Shadow quality</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Directional shadow quality</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Volumetric cloud shadows</strong></p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Disabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Disabled</p></td><td
><p>Disabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td><td
><p>Enabled</p></td></tr><tr><td class="firstcol " ><p><strong>Lighting quality</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Reflections quality</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr><tr><td class="firstcol " ><p><strong>Shading quality</strong></p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td><td
><p>High</p></td></tr><tr><td class="firstcol " ><p><strong>Post-process quality</strong></p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Medium</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Low</p></td><td
><p>Medium</p></td><td
><p>High</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td><td
><p>Very high</p></td></tr></tbody></table></div><p><em>More settings have been listed by 2K Games for </em><a data-analytics-id="inline-link" href="https://borderlands.2k.com/borderlands-4/news/nvidia-optimization/"><em>Nvidia GPUs </em></a><em>and </em><a data-analytics-id="inline-link" href="https://borderlands.2k.com/borderlands-4/news/amd-optimization/"><em>AMD GPUs.</em></a><em></em></p><p>On paper, the RTX 5090 stands out as the most powerful gaming graphics card available, and <em>Borderlands 4</em> puts that muscle to good use. According to 2K’s recommendations, it’s the only GPU positioned to run Borderlands 4 at 4K (with DLSS and frame generation enabled) while pushing nearly every visual setting to the max. Notably, these recommendations only target a minimum of 60 FPS, which feels less than impressive for a flagship-grade GPU that costs upwards of $3,000.</p><p>On the other hand, the Radeon RX 5700 XT from AMD serves as an entry point for 1080p, although this can only be achieved using FSR and reduced settings for shadows and lighting to maintain frame rates at 60 FPS and above. As for mid-range GPUs like the RX 6700 XT and RX 7700 XT, they should be good enough at 1440p while maintaining much of the game’s visual quality. At the higher end, the RX 6950 XT and RX 7900 XTX push into 4K territory, but still rely on FSR in Balanced or Performance mode to deliver consistent performance.</p><p>AMD's latest Radeon 9000 series is also part of the recommended list, with the latest RDNA 4 GPUs offering the best experience for <em>Borderlands 4</em>. The lineup benefits from FSR 4 and improved frame generation support, thus making the Radeon RX 9060 and 9060 XT suitable for 1440p, while the RX 9070 and 9070 XT are recommended to run the game at 4K / 60.</p><p>The release of these preset settings comes in the wake of <em>Borderlands 4</em> drawing <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/borderlands-4-launch-marred-by-performance-issues">criticism for severe performance issues</a>. Players have reportedly been running into all sorts of issues, ranging from low frame rates, stuttering, and crashes, even on top-tier graphics cards like the RTX 5090. While a 2.7GB day-one patch improved stability and fixed some crashes and errors, reports of inconsistent performance continue to surface. Gearbox CEO Randy Pitchford acknowledged the situation, noting that players with systems below spec or without SSDs would likely struggle.</p><p>The recommended settings also highlight just how demanding the game truly is. Even with Nvidia’s latest RTX 50-series and AMD’s Radeon 9000-series GPUs, players are expected to lean on upscaling and frame generation to achieve smooth performance at higher resolutions. That in itself speaks volumes about the game’s hardware demands, underlying optimization issues,
or likely both.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/video-games/pc-gaming/is-borderlands-4-the-new-crysis-official-gpu-setting-recommendations-peg-4k-performance-with-the-rtx-5090-at-60-fps-with-dlss-and-frame-generation-enabled
Borderlands 4’s official recommended graphics settings point to steep GPU requirements across resolutions, raising concerns over optimization.
5d2VejfECHFWfBGpC2YgtE
Mon, 15 Sep 2025 16:28:51 +0000 PC Gaming
Video Games
editors@tomshardware.com (Kunal Khullar)
Kunal Khullar
Steam
Borderlands 4
Borderlands 4
<![CDATA[ Intel Arc A750 prototype spotted with 16GB VRAM — Engineering sample made by Gunnir sports sticker claiming a 512-bit memory bus ]]>
<p>Intel released the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-adds-more-arc-gpus-to-end-of-life-a750-limited-edition-rides-into-the-sunset-3-years-after-launch">Arc A750 roughly three years ago</a> as part of its first generation "Alchemist" lineup of discrete GPUs. It launched with 8GB of GDDR6 memory saturated across a 256-bit bus. While the card's specs are nothing extraordinary, a new version of the A750 has just surfaced — seemingly with double the VRAM and twice as wide of a memory bus — which never came out. It looks like a prototype and <a data-analytics-id="inline-link" href="https://x.com/komenezumi1006/status/1966748711238942832" target="_blank"><em>@komenezumi1006</em> on X </a>claims they have one.</p><div class="see-more see-more--clipped"><blockquote class="twitter-tweet hawk-ignore" data-lang="en"><p lang="en" dir="ltr">Sample(迫真) https://t.co/mOcETYDuEO pic.twitter.com/dMskNiV3te<a href="https://twitter.com/cantworkitout/status/1966748711238942832">September 13, 2025</a></p></blockquote><div class="see-more__filter"></div></div><p>This unusual A750 is from Gunnir, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/intel-gpu-vendor-teases-arc-battlemage-reveal-for-december-4-gpus-may-launch-a-little-over-a-week-later">an experienced name in the Intel Arc community</a> that has developed a myriad of GPUs for the Blue Team. Therefore, it stands to reason that Gunnir was possibly experimenting with different versions of the A750 with Intel, including this one with 16 GB of memory and a 512-bit bus. It's not just for show either, as the card pops up with the full 16 GB VRAM in Task Manager, so it seems to be a working engineering sample.</p><p>The user has provided images that confirm there's only one core on the card, turning down speculation of a dual-GPU prototype with double the memory. That still doesn't explain the wider 512-bit bus. Perhaps it's been mislabeled by someone who thought that twice the VRAM capacity means twice the bus width. Regardless, it's an interesting sample, but it unfortunately wasn't benchmarked, so we don't know how it performs (or if it's better than the standard A750).</p><p>From the pictures, we can see that two 8-pin PCIe power connectors are present on this A750, which is different from the 1x 8-pin and 1x 6-pin config that the retail A750 had. Moreover, there are stickers on the GPU that specifically say "Intel Arc Sample," suggesting that Intel might have floated around the idea of a 16GB A750 at some point, and developed this prototype to test out the feasibility.</p><p>Ultimately, we never got such a card. The only 16 GB GPU from Alchemist was the Arc A770 (which also had an 8 GB variant). The current-gen Arc B750 that succeeded the A750 has 10 GB of VRAM, while the <a data-analytics-id="inline-link" href="https://www.techpowerup.com/340802/intel-arc-b770-battlemage-nears-launch-as-intel-prepares-packaging" target="_blank">B770 is rumored to feature 16 GB</a>, effectively making this 16 GB A750 the only "midrange" Intel GPU we know of with that memory pool.</p><p><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><u><em> Tom's Hardware on Google News</em></u></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><u><em> add us as a preferred source</em></u></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/gpus/intel-arc-a750-prototype-spotted-with-16gb-vram-engineering-sample-made-by-gunnir-sports-sticker-claiming-a-512-bit-memory-bus
A new engineering sample for the Intel Arc A750 has just surfaced with 16 GB of VRAM, double the memory that was in the standard A750. It also has dual 8-pin power connectors and somehow a 512-bit memory bus. The prototype is made by Gunnir and it works when connected to a computer, just like any other GPU.
KRWNnnxBfhsm7ShMunY6ki
Mon, 15 Sep 2025 16:01:57 +0000 GPUs
PC Components
editors@tomshardware.com (Hassam Nasir)
Hassam Nasir
Intel
Arc A750
Arc A750
<![CDATA[ Engineer creates ‘blazingly fast’ web server powered by a disposable vape — 'VapeServer' powered by 24 MHz Arm chip with 24 kilobytes of flash, 3KB of SRAM ]]>
<p>Engineer and origami artist Bogdan Ionescu, AKA BogdanTheGeek, has created a web server that runs on a disposable vape. Inspired by his growing collection of these disposables, and prior work he had done on semihosting on any Arm CPU using “a few lines of code,” Bogdan had a lightbulb moment and decided to host “a web server on a vape,” thus creating <a data-analytics-id="inline-link" href="https://bogdanthegeek.github.io/blog/projects/vapeserver/" target="_blank">the VapeServer</a>.</p><p>Disposable vapes can contain a surprising amount of computing power/components. Bogdan had been collecting discarded units for ‘future projects’ for a couple of years, with eyes on reusing the batteries. However, he recently became aware of “fancier” units that pack more advanced ICs and microcontrollers. They didn’t just contain PCBs with unknown ‘blob chips.’ He found some with more advanced microcontrollers.</p><p>Bogdan says one of the fancier units he disassembled contained an IC marked ‘PUYA C642F15.’ This sparked some research, and the engineer determined that this was actually a PY32F002B, which has the following specs:</p><ul><li>24 MHz Arm Cortex M0+ processor</li><li>24KB of Flash Storage</li><li>3KB of Static RAM</li><li>a few peripheral interfaces</li></ul><p>Those are not stellar specs, and perhaps “about 100x slower” than a 10-year-old mobile, by our hero’s estimation. For web serving, though, Bogdan thought the PY32F002B-powered ex-vape with USB-C port could be leveraged to make a “blazingly fast” device.</p><p>The method, in brief, would see Bogdan emulate a dial-up modem on the microcontroller using SLIP (Serial Line Internet Protocol) over the USB serial connection. Linux ‘slattach’ and ‘socat’ utilities enabled IP packet transmission, and then the microcontroller leveraged the compact uIP stack to communicate via TCP/IP and set up a web server. The web page, a copy of the linked blog post, just about fit in the remaining 20KB of flash on the PY32F002B.</p><h2 id="cutting-page-load-times-from-20s-to-160ms-2">Cutting page load times from 20s to 160ms </h2><p>Optimization to get a usably performant web server presented several challenges. Bogdan says he almost gave up after the first tests, with the vape-powered performance being laughably bad. Pings were ~1.5s, and a simple page load took 20 seconds.</p><p>However, he humbly admits the big issue was his code. So the engineer added a buffer and batched writes to improve throughput, and with a few more tweaks managed to get pings down to 20ms with no packet loss, and full-page loading in about 160ms. Not bad.</p><p>The source link from Bogdan’s blog we shared isn’t hosted on this vape-powered web server. However, if you are really curious, you can try <a data-analytics-id="inline-link" href="http://ewaste.fka.wtf/">this link</a> to get the post served from the VapeServer. We say ‘try’ because the vape-hosted page is currently throwing up a ‘503’ error, probably due to being overloaded by visitors.</p><p>Bogdan has also shared the semihost-ip <a data-analytics-id="inline-link" href="https://github.com/BogdanTheGeek/semihost-ip">project code</a> for the VapeServer on GitHub.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/maker-stem/microcontrollers-projects/engineer-creates-blazingly-fast-web-server-powered-by-a-disposable-vape-vapeserver-powered-by-24-mhz-arm-chip-with-24-kilobytes-of-flash-3kb-of-sram
Engineer and origami artist Bogdan Ionescu has created a web server that runs on a disposable vape.
7gDm5P4MtsAiFfMPeXJq5F
Mon, 15 Sep 2025 15:53:52 +0000 Microcontroller Projects
Maker and STEM
Microcontrollers
Mark Tyson
Bogdan Ionescu
Making the VapeServer
Making the VapeServer
<![CDATA[ Expect HDD, SSD shortages as AI rewrites the rules of storage hierarchy — multiple companies announce price hikes, too ]]>
<p>The computing market is absolutely ablaze with AI-driven growth. Regardless of how sustainable it might be, companies are spending untold amounts of wealth on hardware, with most headlines revolving around GPUs. But the storage market is also under pressure, especially hard drive vendors who purportedly haven't done much to increase manufacturing capacity in a decade. <a data-analytics-id="inline-link" href="https://www.trendforce.com/presscenter/news/20250915-12714.html" target="_blank">TrendForce says</a> lead times for high-capacity "nearline" hard drives have ballooned to over 52 weeks — more than a full year.</p><p>TredForce posted two articles on essentially the same topic today. <a data-analytics-id="inline-link" href="https://www.trendforce.com/news/2025/09/15/news-western-digital-raises-hdd-prices-amid-soaring-demand-shipping-delays-of-up-to-10-weeks/" target="_blank">One of them</a> includes a letter from Western Digital to its customers warning of "unprecedented demand for every capacity in [its] portfolio," and stating that it is raising prices on all of its hard drives. WD says, of course, that this is "to support this growth and ensure continued excellence," but of course, the company will benefit from the bump to its margins and thus, profits.</p><div class="see-more see-more--clipped"><blockquote class="twitter-tweet hawk-ignore" data-lang="en"><p lang="en" dir="ltr">📈 Following SanDisk’s 10% #NAND hike and Micron’s week-long pricing freeze, #WesternDigital is joining the price-raise club! #HDDs across all capacities are set to go up, and ocean freight delays could stretch delivery by weeks—better plan your orders now!💡More:… pic.twitter.com/iFj1vCPW5E<a href="https://twitter.com/cantworkitout/status/1967517514067292652">September 15, 2025</a></p></blockquote><div class="see-more__filter"></div></div><p>If you're unfamiliar with the term, "nearline" refers to storage that is not quite online, yet also not quite offline. It's "warm" data, information that needs to be available for ready access, but doesn't have to be as quick or responsive as the SSDs that serve as primary online storage for essentially all systems now. Because it isn't constantly being accessed, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/ssds-will-not-replace-hard-drives-for-several-years-report" target="_blank">hard drives can fill this role</a> in an economical fashion. While SSDs have made huge strides in price-per-gigabyte, hard disks are still typically four to five times cheaper by capacity.</p><p>Generative AI, as a class of workload, implies tremendous demands for nearline storage. Obviously, generative AI can spew out an unlimited pile of output, but it's not just the AI models' output that is filling up servers' storage. The software infrastructure to both set up and run generative AI workloads is itself quite heavy: Training datasets, model checkpoints, inference logs, and more specialized fine-tuning datasets can all eat up petabytes of data in a shockingly short amount of time.</p><figure class="van-image-figure
inline-layout" data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:2000px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="ApPuynDJYdz8ErVLrtWVCD" name="SSD vs HDD-1.jpg" alt="A selection of SSD and HDD storage devices." src="https://cdn.mos.cms.futurecdn.net/ApPuynDJYdz8ErVLrtWVCD.jpg" mos="" align="middle" fullscreen="" width="2000" height="1125" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=" inline-layout"><span class="caption-text">Fortunately, consumer storage devices like the above are less likely to be affected. </span><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure><p>That's why the trendline for warm storage is going vertical: You don't just need the data required to run inference. You also need the history of everything to prove to regulators that you're not laundering bias, to retrain when new data comes in, and to roll back to a previous checkpoint if your fine-tuned model goes feral and, say, starts <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/the-new-frontier-meet-the-power-players-cashing-in-on-the-ai-gold-rush" target="_blank">referring to itself as MechaHitler</a>. This stuff can't go to offline storage until you're certain it isn't needed in the short term. But it's too big to live in the primary storage of all but the beefiest servers. Thus, the need for nearline hard drives.</p><p>Because the supply of hard drives is insufficient, cloud service providers (CSPs) and other hyperscalers might be looking at economical QLC SSDs for cold data storage. This has its benefits; performance is better, physical density <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/ssd-capacity-could-quadruple-by-2029-8tb-nand-will-bring-big-and-affordable-ssds-to-the-market" target="_blank">can be improved</a>, power consumption is typically lower, and most importantly, they're actually available to purchase. However, as we noted, SSD prices start at around four times the cost per gigabyte, and that adds up real quick when you're buying hundreds, thousands, or tens of thousands of terabytes of storage.</p><p>In response, Trendforce reports that memory suppliers are actively developing SSD products intended for deployment in nearline service. These should help bring costs down once they hit the market. But in the short term, we can expect the storage crunch to cause rising SSD prices as well, at least for enterprise drives. If you're keen on picking up some solid-state storage, it might not be a bad idea to start shopping now. Make sure you check out our list of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/best-ssds,3891.html" target="_blank">best SSDs for 2025</a> before you do.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
https://www.tomshardware.com/pc-components/storage/expect-hdd-ssd-shortages-as-ai-rewrites-the-rules-of-storage-hierarchy-multiple-companies-announce-price-hikes-too
The computing market is absolutely ablaze with growth, and what's driving it is AI, of course. The most common headlines on this topic tend to revolve around GPUs, but the storage market is under heavy pressure as well
— especially hard drive vendors who purportedly haven't done much to increase manufacturing capacity in a decade. The AI hardware crunch is hitting storage as well as GPUs. Sources say lead times for high-capacity hard drives have ballooned to more than a full year.
2Z6ZdyqPFfUmdZLCBhr5TW
Mon, 15 Sep 2025 15:37:09 +0000 Storage
PC Components
Zak Killian
Google
Google
Google
<![CDATA[ Samsung's 4TB 990 Evo Plus SSD drops to a new all-time low of 5 cents per gigabyte — speedy and spacious drive drops to $199 at B&H ]]>
<p>Samsung's excellent<a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/samsung-990-evo-plus-ssd-review"> 990 EVO Plus 4TB</a> was already one of the best bargains in the 4TB M.2 space, at its previous low price of around $230. But at a new all-time low price of <a data-analytics-id="inline-link" href="https://www.bhphotovideo.com/c/product/1855151-REG/samsung_mz_v9s4t0b_am_4tb_990_evo_plus.html">just $199 at B&H</a> (with a $40 coupon applied automatically), it's an absolute steal for anyone who needs speed and roomy storage.<br><br>Similar 4TB options in the same price range mostly deliver lesser performance, with some featuring slower QLC flash memory, rather than the TLC in Samsung's drive. The 990 EVO Plus 4TB's discount also brings the drive into price parity with technically faster 2TB PCIe 5.0 x4 SSD pricing. So if you don't need the fastest speeds possible (which generally doesn't matter for gaming or most mainstream tasks), you can get twice the storage for the same price or less than cutting-edge alternatives.</p><ul><li><a href="https://www.bhphotovideo.com/c/product/1855151-REG/samsung_mz_v9s4t0b_am_4tb_990_evo_plus.html">Grab this deal at B&H</a></li></ul><p>The 990 Evo Plus employs Samsung's proprietary 5nm-based Piccolo controller, which can be used in PCIe 4.0 x4 or PCIe 5.0 x2 configurations, depending on your setup. The drive uses 236-layer (V8) TLC V-NAND but is DRAM-less, and instead focuses on HMB
to compensate. The 990 Evo Plus delivers good to great all-around performance, and is quite power efficient whilst still achieving sequential read and write speeds of 7,250/6,300 MB/s. The random reads and writes, too, stand at an impressive 1,050K IOPS and 1,400K, respectively.</p><div class="product star-deal"><a data-dimension112="bf989a94-6015-466c-bbdd-9836c7580883" data-action="Star Deal Block" data-label="The Samsung 990 EVO Plus 4TB is an interesting drive with PCIe behavior that skirts the border between Gen 4.0 and Gen 5.0. Use 4 lanes in PCIe Gen 4x4, or 2 pipelines in Gen 5x2 on a newer PCIe Gen 5.0 device. With sequential read and write speeds of up to 7,250/7,250 MB/s, this is a fast drive. And it's single-sided and power-efficient, making it great for use in a laptop or desktop." data-dimension48="The Samsung 990 EVO Plus 4TB is an interesting drive with PCIe behavior that skirts the border between Gen 4.0 and Gen 5.0. Use 4 lanes in PCIe Gen 4x4, or 2 pipelines in Gen 5x2 on a newer PCIe Gen 5.0 device. With sequential read and write speeds of up to 7,250/7,250 MB/s, this is a fast drive. And it's single-sided and power-efficient, making it great for use in a laptop or desktop." data-dimension25="$199" href="https://www.bhphotovideo.com/c/product/1855151-REG/samsung_mz_v9s4t0b_am_4tb_990_evo_plus.html" target="_blank" rel="nofollow"><figure class="van-image-figure "
><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1500px;"><p class="vanilla-image-block" style="padding-top:27.87%;"><img id="LbeQX9fMiBu6ATgAa9LSmG" name="Samsung 990 EVO Plus 4TB Listing" caption="" alt="" src="https://cdn.mos.cms.futurecdn.net/LbeQX9fMiBu6ATgAa9LSmG.jpg" mos="" align="middle" fullscreen="" width="1500" height="418" attribution="" endorsement="" credit="" class=""></p></div></div></figure></a><p>The Samsung 990 EVO Plus 4TB is an interesting drive with PCIe behavior that skirts the border between Gen 4.0 and Gen 5.0. Use 4 lanes in PCIe Gen 4x4, or 2 pipelines in Gen 5x2 on a newer PCIe Gen 5.0 device. With sequential read and write speeds of up to 7,250/7,250 MB/s, this is a fast drive. And it's single-sided and power-efficient, making it great for use in a laptop or desktop. <a class="view-deal button" href="https://www.bhphotovideo.com/c/product/1855151-REG/samsung_mz_v9s4t0b_am_4tb_990_evo_plus.html" target="_blank" rel="nofollow" data-dimension112="bf989a94-6015-466c-bbdd-9836c7580883" data-action="Star Deal Block" data-label="The Samsung 990 EVO Plus 4TB is an interesting drive with PCIe behavior that skirts the border between Gen 4.0 and Gen 5.0. Use 4 lanes in PCIe Gen 4x4, or 2 pipelines in Gen 5x2 on a newer PCIe Gen 5.0 device. With sequential read and write speeds of up to 7,250/7,250 MB/s, this is a fast drive. And it's single-sided and power-efficient, making it great for use in a laptop or desktop." data-dimension48="The Samsung 990 EVO Plus 4TB is an interesting drive with PCIe behavior that skirts the border between Gen 4.0 and Gen 5.0. Use 4 lanes in PCIe Gen 4x4, or 2 pipelines in Gen 5x2 on a newer PCIe Gen 5.0 device. With sequential read and write speeds of up to 7,250/7,250 MB/s, this is a fast drive. And it's single-sided and power-efficient, making it great for use in a laptop or desktop." data-dimension25="$199">View Deal</a></p></div><p>For gaming, the Samsung 990 EVO Plus competes with the best PCIe 4.0 drives, and in our benchmarking tests using 3DMark, it finishes mid-table or slightly above. Each round of tests involved stress-testing the drive based on standard gaming activities such as loading games, saving progress, installing game files, and recording gameplay video streams.</p><div class="inlinegallery
carousel-layout"><div class="inlinegallery-wrap" style="display:flex; flex-flow:row nowrap;"><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 1 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="ugUPeDBn4VhjGVq8phYFyG" name="ALLSSD-3DMLatency.png" alt="Samsung 990 EVO Plus SSD" src="https://cdn.mos.cms.futurecdn.net/ugUPeDBn4VhjGVq8phYFyG.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 2 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="kzwRxrGYtc3EZKP66ebn5H" name="ALLSSD-3DMMBps.png" alt="Samsung 990 EVO Plus SSD" src="https://cdn.mos.cms.futurecdn.net/kzwRxrGYtc3EZKP66ebn5H.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div><div class="inlinegallery-item" style="flex: 0 0 auto;"><span class="slidecount">Image 3 of 3</span><figure class="van-image-figure " data-bordeaux-image-check ><div class='image-full-width-wrapper'><div class='image-widthsetter' style="max-width:1920px;"><p class="vanilla-image-block" style="padding-top:56.25%;"><img id="wjCHE2h87fpbuGQoE9fRBH" name="ALLSSD-3DMPoints.png" alt="Samsung 990 EVO Plus SSD" src="https://cdn.mos.cms.futurecdn.net/wjCHE2h87fpbuGQoE9fRBH.png" mos="" link="" align="" fullscreen="" width="1920" height="1080" attribution="" endorsement="" class=""></p></div></div><figcaption itemprop="caption description" class=""><span class="credit" itemprop="copyrightHolder">(Image credit: Tom's Hardware)</span></figcaption></figure></div></div></div><p>If you're PC or PlayStation 5 is constantly running out of space to install your game library, this is a good way of instantly expanding your capacity. Having up to 4TB of space means you can install the latest AAA titles without worrying about shuffling off other games to make room.</p><p><em>If you're looking for more savings, check out our </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-deals-on-tech"><em>Best PC Hardware deals</em></a><em> for a range of products, or dive deeper into our specialized </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/features/best-deals-on-ssds"><em>SSD and Storage Deals,</em></a><em> </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/ssds/best-hard-drive-deals"><em>Hard Drive Deals</em></a><em>, </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-computer-monitor-deals"><em>Gaming Monitor Deals</em></a><em>, </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/best-graphics-card-deals-now"><em>Graphics Card Deals</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://www.tomshardware.com/features/best-cpu-deals"><em>CPU Deals</em></a><em> pages.</em></p>
https://www.tomshardware.com/pc-components/ssds/samsungs-4tb-990-evo-plus-ssd-drops-to-a-new-all-time-low-of-5-cents-per-gigabyte-speedy-and-spacious-drive-drops-to-usd199-at-b-and-h
Hitting a new low price of $199 at B&H for 4TB, Samsung's 990 EVO Plus is a fast mainstream drive at a great price.
G4AZZDpfDdhbMytfurG6bT
Mon, 15 Sep 2025 14:56:25 +0000 SSDs
PC Components
Storage
Matt Safford
Future
Tech Deals cover featuring a Samsung 990 EVO Plus 4TB SSD
Tech Deals cover featuring a Samsung 990 EVO Plus 4TB SSD