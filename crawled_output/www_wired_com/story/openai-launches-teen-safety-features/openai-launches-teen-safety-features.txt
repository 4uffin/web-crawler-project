OpenAI's Teen Safety Features Will Walk a Thin Line | WIREDSkip to main contentMenuSECURITYPOLITICSTHE BIG STORYBUSINESSSCIENCECULTUREREVIEWSMenuAccountAccountNewslettersSecurityPoliticsThe Big StoryBusinessScienceCultureReviewsChevronMoreExpandThe Big InterviewMagazineThe New Era of Business TravelEventsWIRED InsiderWIRED ConsultingNewslettersPodcastsVideoMerchSearchSearchSign InSign InBy Kylie RobisonBusinessSep 16, 2025 4:53 PMOpenAI's Teen Safety Features Will Walk a Thin LineCEO Sam Altman announced an age-prediction system and new parental controls in a blog post on Tuesday.FacebookXEmailSave StoryPhoto-Illustration: WIRED Staff; Getty ImagesCommentLoaderSave StorySave this storyCommentLoaderSave StorySave this storyOpenAI announced new teen safety features for ChatGPT on Tuesday as part of an ongoing effort to respond to concerns about how minors engage with chatbots. The company is building an age-prediction system that identifies if a user is under 18 years old and routes them to an “age-appropriate” system that blocks graphic sexual content. If the system detects that the user is considering suicide or self-harm, it will contact the user’s parents. In cases of imminent danger, if a user's parents are unreachable, the system may contact the authorities.In a blog post about the announcement, CEO Sam Altman wrote that the company is attempting to balance freedom, privacy, and teen safety.“We realize that these principles are in conflict, and not everyone will agree with how we are resolving that conflict,” Altman wrote. “These are difficult decisions, but after talking with experts, this is what we think is best and want to be transparent in our intentions.”While OpenAI tends to prioritize privacy and freedom for adult users, for teens the company says it puts safety first. By the end of September, the company will roll out parental controls so that parents can link their child’s account to their own, allowing them to manage the conversations and disable features. Parents can also receive notifications when “the system detects their teen is in a moment of acute distress,” according to the company’s blog post, and set limits on the times of day their children can use ChatGPT.The moves come as deeply troubling headlines continue to surface about people dying by suicide or committing violence against family members after engaging in lengthy conversations with AI chatbots. Lawmakers have taken notice, and both Meta and OpenAI are under scrutiny. Earlier this month, the Federal Trade Commission asked Meta, OpenAI, Google, and other AI firms to hand over information about how their technologies impact kids, according to Bloomberg.At the same time, OpenAI is still under a court order mandating that it preserve consumer chats indefinitely—a fact that the company is extremely unhappy about, according to sources I’ve spoken to. Today’s news is both an important step toward protecting minors and a savvy PR move to reinforce the idea that conversations with chatbots are so personal that consumer privacy should only be breached in the most extreme circumstances.“A Sexbot Avatar in ChatGPT”From the sources I’ve spoken to at OpenAI, the burden of protecting users weighs heavily on many researchers. They want to create a user experience that is fun and engaging, but it can quickly veer into becoming disastrously sycophantic. It's positive that companies like OpenAI are taking steps to protect minors. At the same time, in the absence of federal regulation, there's still nothing forcing these firms to do the right thing.In a recent interview, Tucker Carlson pushed Altman to answer exactly who is making these decisions that impact the rest of us. The OpenAI chief pointed to the model behavior team, which is responsible for tuning the model for certain attributes. “The person I think you should hold accountable for those calls is me,” Altman added. “Like, I’m a public face. Eventually, like, I’m the one that can overrule one of those decisions or our board.”He’s right, yet some of the imminent harms seem to escape him. In another podcast interview with YouTuber Cleo Abrams, Altman said that “sometimes we do get tempted” to launch products “that would really juice growth.” He added: “We haven’t put a sexbot avatar in ChatGPT yet.” Yet! How strange.OpenAI recently released research on who uses ChatGPT, and how they use it. That research excluded users who were under the age of 18. We don’t yet have a full understanding of how teens are using AI, and it’s an important question to answer before the situation grows more dire.Sources SayElon Musk’s xAI is suing a former staffer who left the company to join OpenAI, alleging in a complaint that he misappropriated trade secrets and confidential information. In the current era of AI companies swapping staffers for multimillion-dollar compensation packages, I’m sure we’ll see more of these types of lawsuits pop up.The staffer in question, Xuechen Li, never made it to OpenAI’s internal Slack, according to two sources at the company. It’s unclear whether his offer was rescinded, or if he was onboarded only to be let go. OpenAI and Li did not respond to WIRED’s request for comment.This is an edition of Kylie Robison’s Model Behavior newsletter. Read previous newsletters here.CommentsBack to topTriangleYou Might Also Like …In your inbox: Will Knight's AI Lab explores advances in AITesla's trillion-dollar bet that it's more than just carsBig Interview: Hasan Piker will never run for officeThe doomers who insist AI will kill us allWatch: Uncanny Valley live with Jack Conte, CEO of PatreonKylie Robison is a senior correspondent at WIRED covering the business of artificial intelligence. She was previously a reporter at The Verge, Fortune, and Business Insider. Please send story tips (no PR pitches) to @kylie.01 on Signal. ... Read MoreSenior correspondentTopicsModel Behaviorartificial intelligenceOpenAISafetyprivacyalgorithmsSam AltmanTeensRead MoreShould AI Get Legal Rights?Model welfare is an emerging field of research that seeks to determine whether AI is conscious and, if so, how humanity should respond.Elon Musk’s xAI Sues Apple and OpenAI Over App Store RankingsThe xAI lawsuit claims that Grok’s ranking below ChatGPT is a sign of allegedly monopolistic behavior.Bluesky Goes Dark in Mississippi Over Age Verification LawBluesky has chosen to block access in the state rather than risk potential fines of up to $10,000 per violation.Latam-GPT: The Free, Open Source, and Collaborative AI of Latin AmericaWIRED talks to the director of the Chilean National Center for Artificial Intelligence about Latam-GPT, the large-language model that aims to address the region’s specific needs and change the current technological dynamic.Do Large Language Models Dream of AI Agents?For AI models, knowing what to remember might be as important as knowing what to forget. Welcome to the era of “sleeptime compute.”The Era of AI-Generated Ransomware Has ArrivedCybercriminals are increasingly using generative AI tools to fuel their attacks, with new research finding instances of AI being used to develop ransomware.Silicon Valley Is Panicking About Zohran Mamdani. NYC’s Tech Scene Is NotNew York City tech leaders aren’t rattled by the prospect of a Mayor Mamdani. In fact, many of them welcome it.Big Businesses Are Doing Carbon Dioxide Removal All WrongThe technology is needed to limit global warming. But corporations are supporting it in lieu of reducing emissions.Anthropic Agrees to Pay Authors at Least $1.5 Billion in AI Copyright SettlementAnthropic will pay at least $3,000 for each copyrighted work that it pirated. The company downloaded unauthorized copies of books in early efforts to gather training data for its AI tools.The Internet Revolutionized Porn. Age Verification Could Upend EverythingPlatforms like Pornhub and OnlyFans have given porn stars more autonomy. But sweeping age-check laws are already impacting their bottom lines.Top CDC Officials Resign After Director Is Pushed OutThe exodus has set off alarms among staff at the US Centers for Disease Control and Prevention: “My main concern is they will be replaced with puppets.”AI Is Eliminating Jobs for Younger WorkersNew research from Stanford provides the clearest available evidence that AI is reshaping the workforce—but it’s complicated.WIRED is where tomorrow is realized. It is the essential source of information and ideas that make sense of a world in constant transformation. The WIRED conversation illuminates how technology is changing every aspect of our lives—from culture to business, science to design. The breakthroughs and innovations that we uncover lead to new ways of thinking, new connections, and new industries.SubscribeNewslettersTravelFAQWIRED StaffWIRED EducationEditorial StandardsArchiveRSSAccessibility HelpReviewsBuying GuidesMattressesElectric BikesSoundbarsStreaming GuidesWearablesTVsCouponsGift GuidesAdvertiseContact UsManage AccountJobsPress CenterCondé Nast StoreUser AgreementPrivacy PolicyYour California Privacy Rights© 2025 Condé Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad ChoicesSelect international siteUnited StatesLargeChevronItaliaJapónCzech Republic & SlovakiaFacebookXPinterestYouTubeInstagramTiktok