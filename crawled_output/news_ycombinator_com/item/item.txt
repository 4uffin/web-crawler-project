RustGPT: A pure-Rust transformer LLM built from scratch | Hacker NewsHacker Newsnew | past | comments | ask | show | jobs | submitloginRustGPT: A pure-Rust transformer LLM built from scratch (github.com/tekaratzas)81 points by amazonhut 1 hour ago
| hide | past | favorite | 21 comments
abricq 6 minutes ago
| next [–]
This is great ! Congratulations. I really like your project, especially I like how easily it is to peak at.Do you plan on moving forward with this project ? I seem to understand that all the training is done on the CPU, and that you have next steps regarding optimizing that. Do you consider GPU accelerations ?Also, do you have any benchmarks on known hardware ? Eg, how long would it take to train on a macbook latest gen or your own computer ?replyuntrimmed 34 minutes ago
| prev | next [–]
As someone who has spent days wrestling with Python dependency hell just to get a model running, a simple cargo run feels like a dream. But I'm wondering, what was the most painful part of NOT having a framework? I'm betting my coffee money it was debugging the backpropagation logic.replytaminka 16 minutes ago
| parent | next [–]
lowkey ppl who praise cargo seem to have no idea of the tradeoffs involved in dependency managementthe difficulty of including a dependency should be proportional to the risk you're taking on, meaning it shouldn't be as difficult as it in, say, C where every other library is continually reinventing the same 5 utilities, but also not as easy as it is with npm or cargo, because you get insane dependency clutter, and all the related issues like security, build times, etchow good a build system isn't equivalent of how easy it is include a dependency, while modern languages should have a consistent build system, but having a centralised package repository that anyone freely pull to/from, and having those dependencies freely take on any number of other dependencies is a bad way to handle dependenciesreplyGoto80 36 minutes ago
| prev | next [–]
Nice. Mind to put a license on that?replyenricozb 28 minutes ago
| prev | next [–]
I did this [0] (gpt in rust) with picogpt, following the great blog by jaykmody [1].[0]: https://github.com/enricozb/picogpt-rust
[1]: https://jaykmody.com/blog/gpt-from-scratch/replytechsystems 1 hour ago
| prev | next [–]
> ndarray = "0.16.1" rand = "0.9.0" rand_distr = "0.5.0"Looking good!replykachapopopow 57 minutes ago
| parent | next [–]
I was slightly curious: cargo tree
llm v0.1.0 (RustGPT)
├── ndarray v0.16.1
│
├── matrixmultiply v0.3.9
│
│
└── rawpointer v0.2.1
│
│
[build-dependencies]
│
│
└── autocfg v1.4.0
│
├── num-complex v0.4.6
│
│
└── num-traits v0.2.19
│
│
└── libm v0.2.15
│
│
[build-dependencies]
│
│
└── autocfg v1.4.0
│
├── num-integer v0.1.46
│
│
└── num-traits v0.2.19 ()
│
├── num-traits v0.2.19 ()
│
└── rawpointer v0.2.1
├── rand v0.9.0
│
├── rand_chacha v0.9.0
│
│
├── ppv-lite86 v0.2.20
│
│
│
└── zerocopy v0.7.35
│
│
│
├── byteorder v1.5.0
│
│
│
└── zerocopy-derive v0.7.35 (proc-macro)
│
│
│
├── proc-macro2 v1.0.94
│
│
│
│
└── unicode-ident v1.0.18
│
│
│
├── quote v1.0.39
│
│
│
│
└── proc-macro2 v1.0.94 ()
│
│
│
└── syn v2.0.99
│
│
│
├── proc-macro2 v1.0.94 ()
│
│
│
├── quote v1.0.39 ()
│
│
│
└── unicode-ident v1.0.18
│
│
└── rand_core v0.9.3
│
│
└── getrandom v0.3.1
│
│
├── cfg-if v1.0.0
│
│
└── libc v0.2.170
│
├── rand_core v0.9.3 ()
│
└── zerocopy v0.8.23
└── rand_distr v0.5.1
├── num-traits v0.2.19 ()
└── rand v0.9.0 ()yep, still looks relatively good.replycmrdporcupine 1 minute ago
| root | parent | next [–]
linking both rand-core 0.9.0 and rand-core
0.9.3 which the project could maybe avoid by just specifying 0.9 for its own dep on itreplytonyhart7 47 minutes ago
| parent | prev | next [–]
is this satire or does I must know context behind this comment???replystevedonovan 40 minutes ago
| root | parent | next [–]
These are a few well-chosen dependencies for a serious project.Rust projects can really go bananas on dependencies, partly because it's so easy to include themreplyobsoleszenz 35 minutes ago
| root | parent | prev | next [–]
The project only has 3 dependencies which i interpret as a sign of qualityreplyndai 49 minutes ago
| prev | next [–]
I’m curious where you got your training data? I will look myself, but saw this and thought I’d ask. I have a CPU-first, no-backprop architecture that works very well on classification datasets. It can do single‑example incremental updates which might be useful for continuous learning. I made a toy demo to train on tiny.txt and it can predict next characters, but I’ve never tried to make an LLM before. I think my architecture might work well as an on-device assistant or for on-premises needs, but I want to work with it more before I embarrass myself. Any open-source LLM training datasets you would recommend?replyelectroglyph 46 minutes ago
| parent | next [–]
https://huggingface.co/datasets/NousResearch/Hermes-3-Datase...replykachapopopow 47 minutes ago
| parent | prev | next [–]
huggingface has plenty of openai and antrophic user to assistant chains, beware there are dragons (hallucinations), but good enough for instruction training. I actually recommend distilling kimi k2 instead for instruction following capabilities.replyCharon77 1 hour ago
| prev | next [–]
Absolutely love how readable the entire project isreplykoakuma-chan 4 minutes ago
| parent | next [–]
It's AI generatedreplyyieldcrv 55 minutes ago
| parent | prev | next [–]
Never knew Rust could be that readable. Makes me think other Rust engineers are stuck in a masochistic ego driven contest, which would explain everything else I've encountered about the Rust community and recruiting on that side.replyjmaker 42 minutes ago
| root | parent | next [–]
Not sure what you’re alluding to but that’s just ordinary Rust without performance or async IO concerns.replyemporas 35 minutes ago
| parent | prev | next [–]
It is very procedural/object oriented. This is not considered good Rust practice. Iterators make it more functional, which is better, more succinct that is, and enums more algebraic. But it's totally fine for a thought experiment.replykachapopopow 48 minutes ago
| prev | next [–]
This looks rather similar to when I asked an AI to implement a basic xor problem solver I guess fundementally there's really only a very limited amount of ways to implement this.replybigmuzzy 25 minutes ago
| prev [–]
nicereply
Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | Contact
Search: