Quantitative Biology
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
q-bio
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Quantitative Biology
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Monday, 15 September 2025
Total of 27 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 9 of 9 entries)
[1]
arXiv:2509.09693
[pdf, html, other]
Title:
Glorbit: A Modular, Web-Based Platform for AI Based Periorbital Measurement in Low-Resource Settings
George R. Nahass, Jacob van der Ende, Sasha Hubschman, Benjamin Beltran, Bhavana Kolli, Caitlin Berek, James D. Edmonds, R.V. Paul Chan, Pete Setabutr, James W. Larrick, Darvin Yi, Ann Q. Tran
Comments:
10 pages, 3 figures, 3 tables
Subjects:
Tissues and Organs (q-bio.TO); Image and Video Processing (eess.IV)
Periorbital measurements such as margin reflex distances (MRD1/2), palpebral fissure height, and scleral show are essential in diagnosing and managing conditions like ptosis and eyelid disorders. We developed Glorbit, a lightweight, browser-based application for automated periorbital distance measurement using artificial intelligence, designed for use in low-resource clinical settings. The app integrates a DeepLabV3 segmentation model into a modular pipeline with secure, site-specific Google Cloud storage. Glorbit supports offline mode, local preprocessing, and cloud upload via Firebase-authenticated logins. We evaluated usability, cross-platform compatibility, and deployment readiness through a simulated enrollment study of 15 volunteers. The app completed the full workflow -- metadata entry, image capture, segmentation, and upload -- on all tested sessions without error. Glorbit successfully ran on laptops, tablets, and mobile phones across major browsers. The segmentation model succeeded on all images. Average session time was 101.7 seconds (standard deviation: 17.5). Usability survey scores (1-5 scale) were uniformly high: intuitiveness and efficiency (5.0), workflow clarity (4.8), output confidence (4.9), and clinical utility (4.9). Glorbit provides a functional, scalable solution for standardized periorbital measurement in diverse environments. It supports secure data collection and may enable future development of real-time triage tools and multimodal AI-driven oculoplastics. Tool available at: this https URL
[2]
arXiv:2509.09696
[pdf, html, other]
Title:
DCHO: A Decomposition-Composition Framework for Predicting Higher-Order Brain Connectivity to Enhance Diverse Downstream Applications
Weibin Li, Wendu Li, Quanying Liu
Subjects:
Neurons and Cognition (q-bio.NC); Machine Learning (cs.LG)
Higher-order brain connectivity (HOBC), which captures interactions among three or more brain regions, provides richer organizational information than traditional pairwise functional connectivity (FC). Recent studies have begun to infer latent HOBC from noninvasive imaging data, but they mainly focus on static analyses, limiting their applicability in dynamic prediction tasks. To address this gap, we propose DCHO, a unified approach for modeling and forecasting the temporal evolution of HOBC based on a Decomposition-Composition framework, which is applicable to both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting). DCHO adopts a decomposition-composition strategy that reformulates the prediction task into two manageable subproblems: HOBC inference and latent trajectory prediction. In the inference stage, we propose a dual-view encoder to extract multiscale topological features and a latent combinatorial learner to capture high-level HOBC information. In the forecasting stage, we introduce a latent-space prediction loss to enhance the modeling of temporal trajectories. Extensive experiments on multiple neuroimaging datasets demonstrate that DCHO achieves superior performance in both non-predictive tasks (state classification) and predictive tasks (brain dynamics forecasting), significantly outperforming existing methods.
[3]
arXiv:2509.09718
[pdf, html, other]
Title:
A Comprehensive Pipeline for Aortic Segmentation and Shape Analysis
Nairouz Shehata, Amr Elsawy, Mohamed Nagy, Muhammad ElMahdy, Mariam Ali, Soha Romeih, Heba Aguib, Magdi Yacoub, Ben Glocker
Comments:
STACOM 2025 with MICCAI 2025
Subjects:
Tissues and Organs (q-bio.TO); Image and Video Processing (eess.IV)
Aortic shape analysis plays a key role in cardiovascular diagnostics, treatment planning, and understanding disease progression. We present a robust, fully automated pipeline for aortic shape analysis from cardiac MRI, combining deep learning and statistical techniques across segmentation, 3D surface reconstruction, and mesh registration. We benchmark leading segmentation models including nnUNet, TotalSegmentator, and MedSAM2 highlighting the effectiveness of domain specific training and transfer learning on a curated dataset. Following segmentation, we reconstruct high quality 3D meshes and introduce a DL based mesh registration method that directly optimises vertex displacements. This approach significantly outperforms classical rigid and nonrigid methods in geometric accuracy and anatomical consistency. Using the registered meshes, we perform statistical shape analysis on a cohort of 599 healthy subjects. Principal Component Analysis reveals dominant modes of aortic shape variation, capturing both global morphology and local structural differences under rigid and similarity transformations. Our findings demonstrate the advantages of integrating traditional geometry processing with learning based models for anatomically precise and scalable aortic analysis. This work lays the groundwork for future studies into pathological shape deviations and supports the development of personalised diagnostics in cardiovascular medicine.
[4]
arXiv:2509.09740
[pdf, html, other]
Title:
HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets
Ying Yuan, Xing-Yue Monica Ge, Aaron Archer Waterman, Tommaso Biancalani, David Richmond, Yogesh Pandit, Avtar Singh, Russell Littman, Jin Liu, Jan-Christian Huetter, Vladimir Ermakov
Subjects:
Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)
Large-scale single-cell and Perturb-seq investigations routinely involve clustering cells and subsequently annotating each cluster with Gene-Ontology (GO) terms to elucidate the underlying biological programs. However, both stages, resolution selection and functional annotation, are inherently subjective, relying on heuristics and expert curation. We present HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming cluster annotation into a quantitatively optimizable task. Initially, an LLM functioning as a gene-set analyst analyzes the content of each gene program or perturbation module and generates a ranked list of GO-based hypotheses, accompanied by calibrated confidence scores. Subsequently, we embed every predicted description with a sentence-embedding model, compute pair-wise cosine similarities, and let the agent referee panel score (i) the internal consistency of the predictions, high average similarity within the same cluster, termed intra-cluster agreement (ii) their external distinctiveness, low similarity between clusters, termed inter-cluster separation. These two quantities are combined to produce an agent-derived resolution score, which is maximized when clusters exhibit simultaneous coherence and mutual exclusivity. When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary test, our Resolution Score selects clustering granularities that exhibit alignment with known pathway compared to classical metrics such silhouette score, modularity score for gene functional enrichment summary. These findings establish LLM agents as objective adjudicators of cluster resolution and functional annotation, thereby paving the way for fully automated, context-aware interpretation pipelines in single-cell multi-omics studies.
[5]
arXiv:2509.09818
[pdf, other]
Title:
Cerebellar Contributions to Action and Cognition: Prediction, Timescale, and Continuity
Jonathan Tsay, Richard Ivry
Subjects:
Neurons and Cognition (q-bio.NC)
The cerebellum is implicated in nearly every domain of human cognition, yet our understanding of how this subcortical structure contributes to cognition remains elusive. Efforts on this front have tended to fall into one of two camps. On one side are those who seek to identify a universal cerebellar transform, a single algorithm that can be applied across domains as diverse as sensorimotor learning, social cognition, and decision making. On the other side are those who focus on functional specializations tailored for different task domains. In this perspective, we propose an integrated approach, one that recognizes functional specialization across different cerebellar subregions, but also builds on common constraints that help define the conditions that engage the cerebellum. Drawing on recurring principles from the cerebellum's well-established role in motor control, we identify three core constraints: Prediction - the cerebellum performs anticipatory, not reactive, computations; Timescale - the cerebellum generates predictions limited to short intervals; and Continuity - the cerebellum transforms continuous representations such as space and time. Together, these constraints define the boundary conditions underlying when and how the cerebellum supports cognition, and, just as importantly, specify the types of computations that should not depend on the cerebellum.
[6]
arXiv:2509.09923
[pdf, html, other]
Title:
Engineering Spatial and Molecular Features from Cellular Niches to Inform Predictions of Inflammatory Bowel Disease
Myles Joshua Toledo Tan, Maria Kapetanaki, Panayiotis V. Benos
Comments:
18 pages, 7 figures, 7 tables. Submitted to the 25th BNAIC Conference, Namur, Belgium, November 19 - 21, 2025
Subjects:
Genomics (q-bio.GN); Machine Learning (cs.LG)
Differentiating between the two main subtypes of Inflammatory Bowel Disease (IBD): Crohns disease (CD) and ulcerative colitis (UC) is a persistent clinical challenge due to overlapping presentations. This study introduces a novel computational framework that employs spatial transcriptomics (ST) to create an explainable machine learning model for IBD classification. We analyzed ST data from the colonic mucosa of healthy controls (HC), UC, and CD patients. Using Non-negative Matrix Factorization (NMF), we first identified four recurring cellular niches, representing distinct functional microenvironments within the tissue. From these niches, we systematically engineered 44 features capturing three key aspects of tissue pathology: niche composition, neighborhood enrichment, and niche-gene signals. A multilayer perceptron (MLP) classifier trained on these features achieved an accuracy of 0.774 +/- 0.161 for the more challenging three-class problem (HC, UC, and CD) and 0.916 +/- 0.118 in the two-class problem of distinguishing IBD from healthy tissue. Crucially, model explainability analysis revealed that disruptions in the spatial organization of niches were the strongest predictors of general inflammation, while the classification between UC and CD relied on specific niche-gene expression signatures. This work provides a robust, proof-of-concept pipeline that transforms descriptive spatial data into an accurate and explainable predictive tool, offering not only a potential new diagnostic paradigm but also deeper insights into the distinct biological mechanisms that drive IBD subtypes.
[7]
arXiv:2509.10046
[pdf, other]
Title:
The nature of alpha modulation through neurofeedback
Jacob Maaz (CRPN), Laurent Waroquier (PsyCLÉ), Alexandra Dia (CRPN), Véronique Paban (LNIA, CRPN), Arnaud Rey (CRPN)
Subjects:
Neurons and Cognition (q-bio.NC)
Electroencephalographic neurofeedback (EEG-NF) has been proposed as a promising technique to modulate brain activity through real-time EEG-based feedback. Alpha neurofeedback in particular is believed to induce rapid self-regulation of brain rhythms, with applications in cognitive enhancement and clinical treatment. However, whether this modulation reflects specific volitional control or non-specific influences remains unresolved. In a preregistered, double-blind, sham-controlled study, we evaluated alpha upregulation in healthy participants receiving either genuine or sham EEG-NF during a single-session design. A third arm composed of a passive control group was also included to differentiate between non-specific influences related or not to the active engagement in EEG-NF. Throughout the session, alpha power increased robustly, yet independently of feedback veracity, engagement in self-regulation, or feedback update frequency. Parallel increases in theta and sensorimotor rhythms further suggest broadband non-specific modulation. Importantly, these results challenge the foundational assumption of EEG-NF: that feedback enables volitional EEG control. Instead, they point to spontaneous repetition-related processes as primary drivers, calling for a critical reassessment of neurofeedback efficacy and its underlying mechanisms.
[8]
arXiv:2509.10428
[pdf, html, other]
Title:
Near-Hamiltonian dynamics and energy-like quantities of next-generation neural mass models
Daniele Andrean, Morten Gram Pedersen
Comments:
11 pages, 6 figures, 1 page Supplementary text
Subjects:
Neurons and Cognition (q-bio.NC); Dynamical Systems (math.DS); Classical Physics (physics.class-ph)
Neural mass models describe the mean-field dynamics of populations of neurons. In this work we illustrate how fundamental ideas of physics, such as energy and conserved quantities, can be explored for such models. We show that time-rescaling renders recent next-generation neural mass models Hamiltonian in the limit of a homogeneous population or strong coupling. The corresponding energy-like quantity provides considerable insight into the model dynamics even in the case of heterogeneity, and explain for example why orbits are near-ellipsoidal and predict spike amplitude during bursting dynamics. We illustrate how these energy considerations provide a possible link between neuronal population behavior and energy landscape theory, which has been used to analyze data from brain recordings. Our introduction of near-Hamiltonian descriptions of neuronal activity could permit the application of highly developed physics theory to get insight into brain behavior.
[9]
arXiv:2509.10432
[pdf, other]
Title:
Standards in the Preparation of Biomedical Research Metadata: A Bridge2AI Perspective
Harry Caufield, Satrajit Ghosh, Sek Wong Kong, Jillian Parker, Nathan Sheffield, Bhavesh Patel, Andrew Williams, Timothy Clark, Monica C. Munoz-Torres
Subjects:
Other Quantitative Biology (q-bio.OT); Artificial Intelligence (cs.AI)
AI-readiness describes the degree to which data may be optimally and ethically used for subsequent AI and Machine Learning (AI/ML) methods, where those methods may involve some combination of model training, data classification, and ethical, explainable prediction. The Bridge2AI consortium has defined the particular criteria a biomedical dataset may possess to render it AI-ready: in brief, a dataset's readiness is related to its FAIRness, provenance, degree of characterization, explainability, sustainability, and computability, in addition to its accompaniment with documentation about ethical data practices.
To ensure AI-readiness and to clarify data structure and relationships within Bridge2AI's Grand Challenges (GCs), particular types of metadata are necessary. The GCs within the Bridge2AI initiative include four data-generating projects focusing on generating AI/ML-ready datasets to tackle complex biomedical and behavioral research problems. These projects develop standardized, multimodal data, tools, and training resources to support AI integration, while addressing ethical data practices. Examples include using voice as a biomarker, building interpretable genomic tools, modeling disease trajectories with diverse multimodal data, and mapping cellular and molecular health indicators across the human body.
This report assesses the state of metadata creation and standardization in the Bridge2AI GCs, provides guidelines where required, and identifies gaps and areas for improvement across the program. New projects, including those outside the Bridge2AI consortium, would benefit from what we have learned about creating metadata as part of efforts to promote AI readiness.
Cross submissions (showing 5 of 5 entries)
[10]
arXiv:2505.15709
(cross-list from nlin.CD)
[pdf, html, other]
Title:
Composing $α$-Gauss and logistic maps: Gradual and sudden transitions to chaos
Marcelo A. Pires, Constantino Tsallis, Evaldo M.F. Curado
Comments:
11 pages and 12 figures. This updated version, accepted by Physical Review E, presents a more comprehensive set of analytical results
Subjects:
Chaotic Dynamics (nlin.CD); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph); Physics and Society (physics.soc-ph); Populations and Evolution (q-bio.PE)
We introduce the $\alpha$-Gauss-Logistic map, a new nonlinear dynamics constructed by composing the logistic and $\alpha$-Gauss maps. Explicitly, our model is given by $x_{t+1} = f_L(x_t)x_t^{-\alpha} - \lfloor f_L(x_t)x_t^{-\alpha} \rfloor $ where $f_L(x_t) = r x_t (1-x_t)$ is the logistic map and $ \lfloor \ldots \rfloor $ is the integer part function. Our investigation reveals a rich phenomenology depending solely on two parameters, $r$ and $\alpha$. For $\alpha < 1$, the system exhibits multiple period-doubling cascades to chaos as the parameter $r$ is increased, interspersed with stability windows within the chaotic attractor. In contrast, for $1 \leq \alpha < 2$, the onset of chaos is abrupt, occurring without any prior bifurcations, and the resulting chaotic attractors emerge without stability windows. For $\alpha \geq 2$, the regular behavior is absent. The special case of $\alpha = 1$ allows an analytical treatment, yielding a closed-form formula for the Lyapunov exponent and conditions for an exact uniform invariant density, using the Perron-Frobenius equation. Chaotic regimes for $\alpha = 1$ can exhibit gaps or be gapless. Surprisingly, the golden ratio $\Phi$ marks the threshold for the disappearance of the largest gap in the regime diagram. Additionally, at the edge of chaos in the abrupt transition regime, the invariant density approaches a $q$-Gaussian with $q=2$, which corresponds to a Cauchy distribution.
[11]
arXiv:2509.09738
(cross-list from cs.AI)
[pdf, other]
Title:
Human-AI Collaboration Increases Efficiency in Regulatory Writing
Umut Eser, Yael Gozin, L. Jay Stallons, Ari Caroline, Martin Preusse, Brandon Rice, Scott Wright, Andrew Robertson
Subjects:
Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)
Background: Investigational New Drug (IND) application preparation is time-intensive and expertise-dependent, slowing early clinical development. Objective: To evaluate whether a large language model (LLM) platform (AutoIND) can reduce first-draft composition time while maintaining document quality in regulatory submissions. Methods: Drafting times for IND nonclinical written summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly recorded. For comparison, manual drafting times for IND summaries previously cleared by the U.S. FDA were estimated from the experience of regulatory writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was assessed by a blinded regulatory writing assessor using seven pre-specified categories: correctness, completeness, conciseness, consistency, clarity, redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a percentage. A critical regulatory error was defined as any misrepresentation or omission likely to alter regulatory interpretation (e.g., incorrect NOAEL, omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870 pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2). Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical regulatory errors were detected, but deficiencies in emphasis, conciseness, and clarity were noted. Conclusions: AutoIND can dramatically accelerate IND drafting, but expert regulatory writers remain essential to mature outputs to submission-ready quality. Systematic deficiencies identified provide a roadmap for targeted model improvements.
[12]
arXiv:2509.10369
(cross-list from cs.LG)
[pdf, other]
Title:
Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms
Gul Rukh Khattak, Konstantinos Patlatzoglou, Joseph Barker, Libor Pastika, Boroumand Zeidaabadi, Ahmed El-Medany, Hesham Aggour, Yixiu Liang, Antonio H. Ribeiro, Jeffrey Annis, Antonio Luiz Pinho Ribeiro, Junbo Ge, Daniel B. Kramer, Jonathan W. Waks, Evan Brittain, Nicholas Peters, Fu Siong Ng, Arunashis Sau
Comments:
Currently under review at npj Digital Medicine
Subjects:
Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Tissues and Organs (q-bio.TO)
Contrastive learning is a widely adopted self-supervised pretraining strategy, yet its dependence on cohort composition remains underexplored. We present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation model and pretrain on four cohorts (n = 5,203,352), from diverse populations across three continents (North America, South America, Asia). We systematically assess how cohort demographics, health status, and population diversity influence the downstream performance for prediction tasks also including two additional cohorts from another continent (Europe). We find that downstream performance depends on the distributional properties of the pretraining cohort, including demographics and health status. Moreover, while pretraining with a multi-centre, demographically diverse cohort improves in-distribution accuracy, it reduces out-of-distribution (OOD) generalisation of our contrastive approach by encoding cohort-specific artifacts. To address this, we propose the In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency during pretraining and enhances OOD robustness. This work provides important insights for developing clinically fair and generalisable foundation models.
[13]
arXiv:2509.10390
(cross-list from cs.LG)
[pdf, html, other]
Title:
Vendi Information Gain for Active Learning and its Application to Ecology
Quan Nguyen, Adji Bousso Dieng
Subjects:
Machine Learning (cs.LG); Information Theory (cs.IT); Populations and Evolution (q-bio.PE)
While monitoring biodiversity through camera traps has become an important endeavor for ecological research, identifying species in the captured image data remains a major bottleneck due to limited labeling resources. Active learning -- a machine learning paradigm that selects the most informative data to label and train a predictive model -- offers a promising solution, but typically focuses on uncertainty in the individual predictions without considering uncertainty across the entire dataset. We introduce a new active learning policy, Vendi information gain (VIG), that selects images based on their impact on dataset-wide prediction uncertainty, capturing both informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG achieves impressive predictive accuracy close to full supervision using less than 10% of the labels. It consistently outperforms standard baselines across metrics and batch sizes, collecting more diverse data in the feature space. VIG has broad applicability beyond ecology, and our results highlight its value for biodiversity monitoring in data-limited environments.
[14]
arXiv:2509.10410
(cross-list from cond-mat.soft)
[pdf, html, other]
Title:
Knotted DNA Configurations in Bacteriophage Capsids: A Liquid Crystal Theory Approach
Pei Liu, Zhijie Wang, Tamara Christiani, Mariel Vazquez, M. Carme Calderer, Javier Arsuaga
Subjects:
Soft Condensed Matter (cond-mat.soft); Biomolecules (q-bio.BM)
Bacteriophages, viruses that infect bacteria, store their micron long DNA inside an icosahedral capsid with a typical diameter of 40 nm to 100 nm. Consistent with experimental observations, such confinement conditions induce an arrangement of DNA that corresponds to a hexagonal chromonic liquid-crystalline phase, and increase the topological complexity of the genome in the form of knots. A mathematical model that implements a chromonic liquid-crystalline phase and that captures the changes in topology has been lacking. We adopt a mathematical model that represents the viral DNA as a pair of a vector field and a line. The vector field is a minimizer of the total Oseen-Frank energy for nematic liquid crystals under chromonic constraints, while the line is identified with the tangent to the field at selected locations, representing the central axis of the DNA molecule. The fact that the Oseen-Frank functional assigns infinite energy to topological defects (point defects in two dimensions and line defects in three dimensions) precludes the presence of singularities and, in particular, of knot structures. To address this issue, we begin with the optimal vector field and helical line, and propose a new algorithm to introduce knots through stochastic perturbations associated with splay and twist deformations, modeled by means of a Langevin system. We conclude by comparing knot distributions generated by the model and by interpreting them in the context of previously published experimental results. Altogether, this work relies on the synergy of modeling, analysis and computation in the study of viral DNA organization in capsids.
Replacement submissions (showing 13 of 13 entries)
[15]
arXiv:2201.10960
(replaced)
[pdf, other]
Title:
Triplication: an important component of the modern scientific method
Jeremy S.C. Clark, Karina Szczypiór-Piasecka, Kamila Rydzewska, Konrad Podsiadło
Comments:
41 pages, 6 figures. Supplemental files at this https URL
Subjects:
Quantitative Methods (q-bio.QM)
A scientific-study protocol, as defined here, is designed to deliver results from which inductive inference is allowed. In the nineteenth century, triplication was introduced into the plant sciences and Fisher's p<0.05 rule (1925) was incorporated into a triple-result protocol designed to counter random/systematic errors. Aims here were to: (1) classify replication (including non-replicated) protocols; (2) assess their prevalence in plant-science studies published in 2017 for a defined variable construct; and (3) explore the theoretical rationale for the use of triplication. Methods: the plant sciences were surveyed and a protocol-prevalence report produced; association versus experimental proportions analyzed; and real-world-data proxies were used to show confidence-interval-width patterns with increasing replicate number. Results: triplication was found in ~70% of plant-science studies analyzed, with triple-result protocols observed in ~15%. Theoretical considerations showed that, even if systematic errors predominate, "square-root rules" sometimes apply, contributing to the predominance of triplication (real-world-data proxy examples given). Conclusions: Triplication was extensively applied in the studies analyzed and there are strong methodological reasons why (1) triplication, rather than duplication/quadruplication, is the most appropriate standard; (2) triple-result protocols are preferable to global averaging approaches; and (3) plant science methodological standards remain high, despite immense publication pressures.
[16]
arXiv:2311.10913
(replaced)
[pdf, html, other]
Title:
The structure of deviations from maximum parsimony for densely-sampled data and applications for clade support estimation
William Howard-Snyder, Will Dumm, Mary Barker, Ognian Milanov, Claris Winston, David H. Rich, Marc A Suchard, Frederick A Matsen IV
Comments:
20 pages, 10 figures, Accepted in IEEE Transactions on Computational Biology and Bioinformatics, 2025
Subjects:
Populations and Evolution (q-bio.PE)
How do phylogenetic reconstruction algorithms go astray when they return incorrect trees? This simple question has not been answered in detail, even for maximum parsimony (MP), the simplest phylogenetic criterion. Understanding MP has recently gained relevance in the regime of extremely dense sampling, where each virus sample commonly differs by zero or one mutation from another previously sampled virus. Although recent research shows that evolutionary histories in this regime are close to being maximally parsimonious, the structure of their deviations from MP is not yet understood. In this paper, we develop algorithms to understand how the correct tree deviates from being MP in the densely sampled case. By applying these algorithms to simulations that realistically mimic the evolution of SARS-CoV-2, we find that simulated trees frequently only deviate from maximally parsimonious trees locally, through simple structures consisting of the same mutation appearing independently on sister branches. We leverage this insight to design approaches for sampling near-MP trees and using them to efficiently estimate clade supports.
[17]
arXiv:2501.00720
(replaced)
[pdf, html, other]
Title:
Overground gait transitions are not sharp but involve gradually changing walk-run mixtures even over long distances
Nicholas S. Baker, Leroy Long, Manoj Srinivasan
Subjects:
Neurons and Cognition (q-bio.NC)
Humans typically walk at low speeds and run at higher speeds. Previous studies of transitions between walking and running were mostly on treadmills, but real-world locomotion allows more flexibility. Here, we study overground locomotion over long distances (800 m or 2400 m) under time constraints, simulating everyday scenarios like going to an appointment. Unlike on treadmills, participants can vary both speed and gait during this task. We find that gait transition in this overground task occurs over a broad `gait transition regime' spanning average speeds from 1.9 m/s to 3.0 m/s. In this regime, people use mixtures of walking and running: mostly walking at low average speeds (around 1.9 m/s) and mostly running at high average speeds (3.0 m/s); the walk vs run fraction gradually changes between these speed limits. Within any walk-run mixture, there is a speed gap between the walking and running. These gait mixtures and their specific structure are predicted by energy optimality. These findings extend earlier results from much shorter distance tasks, showing that similar energetic principles govern longer, more physically and cognitively demanding tasks. Overall, our results highlight the role of whole-task energy minimization including transients in shaping human locomotion.
[18]
arXiv:2508.04435
(replaced)
[pdf, html, other]
Title:
Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach
Alvaro Garrido Perez, Viktor Lemoine, Amrapali Pednekar, Yara Khaluf, Pieter Simoens
Comments:
Paper accepted in the International Workshop on Active Inference, 2025: this https URL
Subjects:
Neurons and Cognition (q-bio.NC)
High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.
[19]
arXiv:2508.10178
(replaced)
[pdf, html, other]
Title:
Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?
Jozef Skakala
Comments:
24 pages, 9 figures (3 in the appendix), v2 - minor changes
Subjects:
Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)
Shelf seas are important for carbon sequestration and carbon cycle, but shelf sea observations for carbon pools are often sparse, or highly uncertain. Alternative can be provided by reanalyses, but these are often expensive to run. We propose to use an ensemble of neural networks (i.e. deep ensemble) to learn from a coupled physics-biogeochemistry model the relationship between the directly observable variables and carbon pools. We demonstrate for North-West European Shelf (NWES) sea environment, that when the deep ensemble trained on a model free run simulation is applied to the NWES reanalysis, it is capable to reproduce the reanalysis outputs for carbon pools and additionally provide uncertainty information. We focus on explainability of the results and demonstrate potential use of the deep ensembles for future climate what-if scenarios. We suggest that model-informed machine learning presents a viable alternative to expensive reanalyses and could complement observations, wherever they are missing and/or highly uncertain.
[20]
arXiv:2509.02196
(replaced)
[pdf, html, other]
Title:
Beyond Ensembles: Simulating All-Atom Protein Dynamics in a Learned Latent Space
Aditya Sengar, Ali Hariri, Pierre Vandergheynst, Patrick Barth
Subjects:
Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI)
Simulating the long-timescale dynamics of biomolecules is a central challenge in computational science. While enhanced sampling methods can accelerate these simulations, they rely on pre-defined collective variables that are often difficult to identify. A recent generative model, LD-FPG, demonstrated that this problem could be bypassed by learning to sample the static equilibrium ensemble as all-atom deformations from a reference structure, establishing a powerful method for all-atom ensemble generation. However, while this approach successfully captures a system's probable conformations, it does not model the temporal evolution between them. Here we extend LD-FPG with a temporal propagator that operates within the learned latent space and compare three classes: (i) score-guided Langevin dynamics, (ii) Koopman-based linear operators, and (iii) autoregressive neural networks. Within a unified encoder-propagator-decoder framework, we evaluate long-horizon stability, backbone and side-chain ensemble fidelity, and functional free-energy landscapes. Autoregressive neural networks deliver the most robust long rollouts; score-guided Langevin best recovers side-chain thermodynamics when the score is well learned; and Koopman provides an interpretable, lightweight baseline that tends to damp fluctuations. These results clarify the trade-offs among propagators and offer practical guidance for latent-space simulators of all-atom protein dynamics.
[21]
arXiv:2509.06426
(replaced)
[pdf, html, other]
Title:
Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster
Pembe Gizem Özdil, Chuanfang Ning, Jasper S. Phelps, Sibo Wang-Chen, Guy Elisha, Alexander Blanke, Auke Ijspeert, Pavan Ramdya
Comments:
23 pages, 11 figures
Subjects:
Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)
Computational models are critical to advance our understanding of how neural, biomechanical, and physical systems interact to orchestrate animal behaviors. Despite the availability of near-complete reconstructions of the Drosophila melanogaster central nervous system, musculature, and exoskeleton, anatomically and physically grounded models of fly leg muscles are still missing. These models provide an indispensable bridge between motor neuron activity and joint movements. Here, we introduce the first 3D, data-driven musculoskeletal model of Drosophila legs, implemented in both OpenSim and MuJoCo simulation environments. Our model incorporates a Hill-type muscle representation based on high-resolution X-ray scans from multiple fixed specimens. We present a pipeline for constructing muscle models using morphological imaging data and for optimizing unknown muscle parameters specific to the fly. We then combine our musculoskeletal models with detailed 3D pose estimation data from behaving flies to achieve muscle-actuated behavioral replay in OpenSim. Simulations of muscle activity across diverse walking and grooming behaviors predict coordinated muscle synergies that can be tested experimentally. Furthermore, by training imitation learning policies in MuJoCo, we test the effect of different passive joint properties on learning speed and find that damping and stiffness facilitate learning. Overall, our model enables the investigation of motor control in an experimentally tractable model organism, providing insights into how biomechanics contribute to generation of complex limb movements. Moreover, our model can be used to control embodied artificial agents to generate naturalistic and compliant locomotion in simulated environments.
[22]
arXiv:2509.07983
(replaced)
[pdf, html, other]
Title:
Steering Protein Language Models
Long-Kai Huang, Rongyi Zhu, Bing He, Jianhua Yao
Comments:
Accepted to ICML 2025
Subjects:
Biomolecules (q-bio.BM); Machine Learning (cs.LG)
Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. In this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.
[23]
arXiv:2112.08474
(replaced)
[pdf, other]
Title:
Snakes combine vertical and lateral bending to traverse uneven terrain
Qiyuan Fu, Henry C. Astely, Chen Li
Journal-ref:
Bioinspiration & Biomimetics 17, 036009 (2022)
Subjects:
Biological Physics (physics.bio-ph); Quantitative Methods (q-bio.QM)
Terrestrial locomotion requires generating appropriate ground reaction forces which depend on substrate geometry and physical properties. The richness of positions and orientations of terrain features in the 3-D world gives limbless animals like snakes that can bend their body versatility to generate forces from different contact areas for propulsion. Despite many previous studies of how snakes use lateral body bending for propulsion on relatively flat surfaces with lateral contact points, little is known about whether and how much snakes use vertical body bending in combination with lateral bending in 3-D terrain. This lack had contributed to snake robots being inferior to animals in stability, efficiency, and versatility when traversing complex 3-D environments. Here, to begin to elucidate this, we studied how the generalist corn snake traversed an uneven arena of blocks of random height variation 5 times its body height. The animal traversed the uneven terrain with perfect stability by propagating 3-D bending down its body with little transverse motion (11° slip angle). Although the animal preferred moving through valleys with higher neighboring blocks, it did not prefer lateral bending. Among body-terrain contact regions that potentially provide propulsion, 52% were formed by vertical body bending and 48% by lateral bending. The combination of vertical and lateral bending may dramatically expand the sources of propulsive forces available to limbless locomotors by utilizing various asperities available in 3-D terrain. Direct measurements of contact forces are necessary to further understand how snakes coordinate 3-D bending along the entire body via sensory feedback to propel through 3-D terrain. These studies will open a path to new propulsive mechanisms for snake robots, potentially increasing the performance and versatility in 3-D terrain.
[24]
arXiv:2501.09087
(replaced)
[pdf, html, other]
Title:
First-Passage Time Fluctuation Theorem and Thermodynamic Bound in Cooperative Biomolecular Networks
D. Evan Piephoff, Jianshu Cao
Subjects:
Biological Physics (physics.bio-ph); Chemical Physics (physics.chem-ph); Molecular Networks (q-bio.MN)
A fluctuation theorem is examined for the first-passage time of a biomolecular machine (e.g., a motor protein or an enzyme) in a nonequilibrium steady-state. For such machines in which the driven, observable process is coupled to a hidden process in a kinetically cooperative fashion, the entropy produced along first-passage trajectories is no longer constant, resulting in a breakdown of this expression. Here, we consider the canonical model for this type of system, a kinetic scheme for conformation-modulated single-enzyme catalysis (a type of continuous-time Markov process with relevance to $\beta$-galactosidase and human glucokinase), as we explore this fluctuation theorem in cooperative biomolecular networks. Kinetic evaluations are performed using a novel, efficient pathway analysis technique, allowing us to attain surprising and concise results from complex calculations. We find that in the absence of hidden current, a fluctuation theorem can be established for the first-passage time of the observable process, and we demonstrate that this dramatic reduction is a general feature applicable to a wide variety of cooperative networks. The validity of this expression can be experimentally tested, with its violation serving as a unique signature of hidden detailed balance breaking. In addition, we obtain a remarkably compact exact expression for the integrated correction to this first-passage time fluctuation theorem, as well as the general form, revealing a thermodynamic bound on the kinetic branching ratio (a measure of directionality defined as the ratio of the forward observable process probability to the backward one). These results provide detailed insight into the rich connections between dynamic measurements and the underlying nonequilibrium thermodynamics for cooperative biomolecular machines.
[25]
arXiv:2501.13639
(replaced)
[pdf, html, other]
Title:
Physics of droplet regulation in biological cells
David Zwicker, Oliver W. Paulin, Cathelijne ter Burg
Comments:
Review, 31 pages, 12 figures
Subjects:
Biological Physics (physics.bio-ph); Soft Condensed Matter (cond-mat.soft); Statistical Mechanics (cond-mat.stat-mech); Chemical Physics (physics.chem-ph); Subcellular Processes (q-bio.SC)
Droplet formation has emerged as an essential concept for the spatiotemporal organisation of biomolecules in cells. However, classical descriptions of droplet dynamics based on passive liquid-liquid phase separation cannot capture the complex situations inside cells. This review discusses three general aspects that are crucial in cells: (i) biomolecules are diverse and individually complex, implying that cellular droplets posses complex internal behaviour, e.g., in terms of their material properties; (ii) the cellular environment contains many solid-like structures that droplets can wet; (iii) cells are alive and use fuel to drive processes out of equilibrium. We illustrate how these principles control droplet nucleation, growth, position, and count to unveil possible regulatory mechanisms in biological cells and other applications of phase separation.
[26]
arXiv:2502.16446
(replaced)
[pdf, html, other]
Title:
Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation
Haocheng Tang, Jing Long, Beihong Ji, Junmei Wang
Comments:
Accepted by Journal of Chemical Information and Modeling, ASAP
Subjects:
Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)
In this work, we introduce Auxiliary Discriminator Sequence Generative Adversarial Networks (ADSeqGAN), a novel approach for molecular generation in small-sample datasets. Traditional generative models often struggle with limited training data, particularly in drug discovery, where molecular datasets for specific therapeutic targets, such as nucleic acids binders and central nervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by integrating an auxiliary random forest classifier as an additional discriminator into the GAN framework, significantly improves molecular generation quality and class specificity. Our method incorporates pretrained generator and Wasserstein distance to enhance training stability and diversity. We evaluate ADSeqGAN across three representative cases. First, on nucleic acid- and protein-targeting molecules, ADSeqGAN shows superior capability in generating nucleic acid binders compared to baseline models. Second, through oversampling, it markedly improves CNS drug generation, achieving higher yields than traditional de novo models. Third, in cannabinoid receptor type 1 (CB1) ligand design, ADSeqGAN generates novel druglike molecules, with 32.8\% predicted actives surpassing hit rates of CB1-focused and general-purpose libraries when assessed by a target-specific LRIP-SF scoring function. Overall, ADSeqGAN offers a versatile framework for molecular design in data-scarce scenarios, with demonstrated applications in nucleic acid binders, CNS drugs, and CB1 ligands.
[27]
arXiv:2509.08578
(replaced)
[pdf, html, other]
Title:
MAESTRO: Multi-modal Adaptive Estimation for Temporal Respiratory Disease Outbreak
Hong Liu, Kerui Cen, Yanxing Chen, Zige Liu, Dong Chen, Zifeng Yang, Chitin Hon
Subjects:
Machine Learning (cs.LG); Populations and Evolution (q-bio.PE); Quantitative Methods (q-bio.QM)
Timely and robust influenza incidence forecasting is critical for public health decision-making. This paper presents MAESTRO (Multi-modal Adaptive Estimation for Temporal Respiratory Disease Outbreak), a novel, unified framework that synergistically integrates advanced spectro-temporal modeling with multi-modal data fusion, including surveillance, web search trends, and meteorological data. By adaptively weighting heterogeneous data sources and decomposing complex time series patterns, the model achieves robust and accurate forecasts. Evaluated on over 11 years of Hong Kong influenza data (excluding the COVID-19 period), MAESTRO demonstrates state-of-the-art performance, achieving a superior model fit with an R-square of 0.956. Extensive ablations confirm the significant contributions of its multi-modal and spectro-temporal components. The modular and reproducible pipeline is made publicly available to facilitate deployment and extension to other regions and pathogens, presenting a powerful tool for epidemiological forecasting.
Total of 27 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack