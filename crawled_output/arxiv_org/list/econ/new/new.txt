Economics
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
econ
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Economics
New submissions
Cross-lists
Replacements
See recent articles
Showing new listings for Thursday, 18 September 2025
Total of 24 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 9 of 9 entries)
[1]
arXiv:2509.13462
[pdf, html, other]
Title:
Strategic Pricing and Ranking in Recommendation Systems with Seller Competition
Tushar Shankar Walunj, Veeraruna Kavitha, Jayakrishnan Nair, Priyank Agarwal
Subjects:
Theoretical Economics (econ.TH)
We study a recommendation system where sellers compete for visibility by strategically offering commissions to a platform that optimally curates a ranked menu of items and their respective prices for each customer. Customers interact sequentially with the menu following a cascade click model, and their purchase decisions are influenced by price sensitivity and positions of various items in the menu. We model the seller-platform interaction as a Stackelberg game with sellers as leaders and consider two different games depending on whether the prices are set by the platform or prefixed by the sellers. It is complicated to find the optimal policy of the platform in complete generality; hence, we solve the problem in an important asymptotic regime.
The core contribution of this paper lies in characterizing the equilibrium structure of the limit game. We show that when sellers are of different strengths, the standard Nash equilibrium does not exist due to discontinuities in utilities. We instead establish the existence of a novel equilibrium solution, namely `$\mu$-connected equilibrium cycle' ($\mu$-EC), which captures oscillatory strategic responses at the equilibrium. Unlike the (pure) Nash equilibrium, which defines a fixed point of mutual best responses, this is a set-valued solution concept of connected components. This novel equilibrium concept identifies a Cartesian product set of connected action profiles in the continuous action space that satisfies four important properties: stability against external deviations, no external chains, instability against internal deviations, and minimality. We extend a recently introduced solution concept equilibrium cycle to include stability against measure-zero violations and, by avoiding topological difficulties to propose $\mu$-EC.
[2]
arXiv:2509.13492
[pdf, html, other]
Title:
Generalized Covariance Estimator under Misspecification and Constraints
Aryan Manafi Neyazi
Subjects:
Econometrics (econ.EM)
This paper investigates the properties of the Generalized Covariance (GCov) estimator under misspecification and constraints with application to processes with local explosive patterns, such as causal-noncausal and double autoregressive (DAR) processes. We show that GCov is consistent and has an asymptotically Normal distribution under misspecification. Then, we construct GCov-based Wald-type and score-type tests to test one specification against the other, all of which follow a $\chi^2$ distribution. Furthermore, we propose the constrained GCov (CGCov) estimator, which extends the use of the GCov estimator to a broader range of models with constraints on their parameters. We investigate the asymptotic distribution of the CGCov estimator when the true parameters are far from the boundary and on the boundary of the parameter space. We validate the finite sample performance of the proposed estimators and tests in the context of causal-noncausal and DAR models. Finally, we provide two empirical applications by applying the noncausal model to the final energy demand commodity index and also the DAR model to the US 3-month treasury bill.
[3]
arXiv:2509.13578
[pdf, html, other]
Title:
In-between Transatlantic (Monetary) Disturbances
Santiago Camara, Jeanne Aublin
Subjects:
General Economics (econ.GN)
This paper studies the spillovers of European Central Bank (ECB) interest rate shocks into the Canadian economy and compares them with those of the U.S. Federal Reserve (Fed). We combine a VAR model and local projection regressions with identification strategies that explicitly purge information effects around policy announcements. We find that an ECB rate hike leads to a depreciation of the Canadian dollar and a sharp contraction in economic activity. The main transmission channel is international trade: ECB shocks trigger a decline in oil prices and exports, while leaving domestic financial conditions largely unaffected. By contrast, Fed shocks tighten Canadian financial conditions significantly, with more limited effects on trade flows. These findings show that Canada is exposed to foreign monetary policy both directly and indirectly, through its integration in global financial and trade markets.
[4]
arXiv:2509.13623
[pdf, html, other]
Title:
Deep Learning in the Sequence Space
Marlon Azinovic-Yang, Jan Žemlička
Subjects:
General Economics (econ.GN)
We develop a deep learning algorithm for approximating functional rational expectations equilibria of dynamic stochastic economies in the sequence space. We use deep neural networks to parameterize equilibrium objects of the economy as a function of truncated histories of exogenous shocks. We train the neural networks to fulfill all equilibrium conditions along simulated paths of the economy. To illustrate the performance of our method, we solve three economies of increasing complexity: the stochastic growth model, a high-dimensional overlapping generations economy with multiple sources of aggregate risk, and finally an economy where households and firms face uninsurable idiosyncratic risk, shocks to aggregate productivity, and shocks to idiosyncratic and aggregate volatility. Furthermore, we show how to design practical neural policy function architectures that guarantee monotonicity of the predicted policies, facilitating the use of the endogenous grid method to simplify parts of our algorithm.
[5]
arXiv:2509.13698
[pdf, html, other]
Title:
Time-Varying Heterogeneous Treatment Effects in Event Studies
Irene Botosaru, Laura Liu
Subjects:
Econometrics (econ.EM)
This paper examines the identification and estimation of heterogeneous treatment effects in event studies, emphasizing the importance of both lagged dependent variables and treatment effect heterogeneity. We show that omitting lagged dependent variables can induce omitted variable bias in the estimated time-varying treatment effects. We develop a novel semiparametric approach based on a short-T dynamic linear panel model with correlated random coefficients, where the time-varying heterogeneous treatment effects can be modeled by a time-series process to reduce dimensionality. We construct a two-step estimator employing quasi-maximum likelihood for common parameters and empirical Bayes for the heterogeneous treatment effects. The procedure is flexible, easy to implement, and achieves ratio optimality asymptotically. Our results also provide insights into common assumptions in the event study literature, such as no anticipation, homogeneous treatment effects across treatment timing cohorts, and state dependence structure.
[6]
arXiv:2509.13887
[pdf, html, other]
Title:
Can the decoy effect increase cooperation in networks? An experiment
Claudia Cerrone, Francesco Feri, Anita Gantner, Paolo Pin
Subjects:
General Economics (econ.GN)
This paper investigates whether the decoy effect - specifically the attraction effect - can foster cooperation in social networks. In a lab experiment, we show that introducing a dominated option increases the selection of the target choice, especially in early decisions. The effect is stronger in individual settings but persists in networks despite free-riding incentives, with variation depending on the decision-maker's strategic position.
[7]
arXiv:2509.14057
[pdf, html, other]
Title:
Machines are more productive than humans until they aren't, and vice versa
Riccardo Zanardelli
Subjects:
General Economics (econ.GN); Artificial Intelligence (cs.AI)
With the growth of artificial skills, organizations may increasingly confront with the problem of optimizing skill policy decisions guided by economic principles. This paper addresses the underlying complexity of this challenge by developing an in-silico framework based on Monte Carlo simulations grounded in empirical realism to analyze the economic impact of human and machine skills, individually or jointly deployed, in the execution of tasks presenting varying levels of complexity. Our results provide quantitative support for the established notions that automation tends to be the most economically-effective strategy for tasks characterized by low-to-medium generalization difficulty, while automation struggles to match the economic utility of human skills in more complex scenarios. Critically, our simulations highlight that combining human and machine skills can be the most effective strategy when a high level of generalization is required, but only if genuine augmentation is achieved. In contrast, when failing to realize this synergy, the human-machine policy is severely penalized by the inherent costs of its dual skill structure, causing it to destroy value and becoming the worst choice from an economic perspective. The takeaway for decision-makers is unambiguous: simply allocating human and machine skills to a task is insufficient, and a human-machine skill policy is neither a silver-bullet solution nor a low-risk compromise. Rather, it is a critical opportunity to boost competitiveness that demands a strong organizational commitment to enabling augmentation. Also, our findings show that improving the cost-effectiveness of machine skills over time, while useful, does not replace the fundamental need to focus on achieving augmentation.
[8]
arXiv:2509.14102
[pdf, html, other]
Title:
Incentivizing High Quality Entrants When Creators Are Strategic
Felicia Nguyen
Subjects:
General Economics (econ.GN)
We study how a platform should design early exposure and rewards when creators strategically choose quality before release. A short testing window with a pass/fail bar induces a pass probability, the slope of which is the key sufficient statistic for incentives. We derive three main results. First, a closed-form ``implementability bounty'' can perfectly align creator and platform objectives, correcting for incomplete revenue sharing. Second, front-loading guaranteed impressions is the most effective way to strengthen incentives for a given attention budget. Third, when impression and cash budgets are constrained, the optimal policy follows an equal-marginal-value rule based on the prize spread and certain exposure. We map realistic ranking engines (e.g., Thompson sampling) into the model's parameters and provide telemetry-based estimators. The framework is simple to operationalize and offers a direct, managerially interpretable solution for platforms to solve the creator cold-start problem and cultivate high-quality supply.
[9]
arXiv:2509.14116
[pdf, html, other]
Title:
Minimum pricing or volumetric taxation? Quantity, quality and competition effects of price regulations in alcohol markets
Celine Bonnet, Fabrice Etile, Sebastien Lecocq
Comments:
Main Text: 52 pages; 11 Tables
Subjects:
General Economics (econ.GN)
Reforming alcohol price regulations in wine-producing countries is challenging, as current price regulations reflect the alignment of cultural preferences with economic interests rather than public health concerns. We evaluate and compare the impact of counterfactual alcohol pricing policies on consumer behaviors, firms, and markets in France. We develop a micro-founded partial equilibrium model that accounts for consumer preferences over purchase volumes across alcohol categories and over product quality within categories, and for firms' strategic price-setting. After calibration on household scanner data, we compare the impacts of replacing current taxes by ethanol-based volumetric taxes with a minimum unit price (MUP) policy of 0.50 Euro per standard drink. The results show that the MUP in addition to the current tax outperforms a tax reform in reducing ethanol purchases (-15% vs. -10% for progressive taxation), especially among heavy drinking households (-17%). The MUP increases the profits of small and medium wine firms (+39%) while decreasing the profits of large manufacturers and retailers (-39%) and maintaining tax revenues stable. The results support the MUP as a targeted strategy to reduce harmful consumption while benefiting small and medium wine producers. This study provides ex-ante evidence that is crucial for alcohol pricing policies in wine-producing countries.
Cross submissions (showing 1 of 1 entries)
[10]
arXiv:2509.13323
(cross-list from cs.HC)
[pdf, html, other]
Title:
AI Behavioral Science
Matthew O. Jackson, Qiaozhu Me, Stephanie W. Wang, Yutong Xie, Walter Yuan, Seth Benzell, Erik Brynjolfsson, Colin F. Camerer, James Evans, Brian Jabarian, Jon Kleinberg, Juanjuan Meng, Sendhil Mullainathan, Asuman Ozdaglar, Thomas Pfeiffer, Moshe Tennenholtz, Robb Willer, Diyi Yang, Teng Ye
Subjects:
Human-Computer Interaction (cs.HC); General Economics (econ.GN)
We discuss the three main areas comprising the new and emerging field of "AI Behavioral Science". This includes not only how AI can enhance research in the behavioral sciences, but also how the behavioral sciences can be used to study and better design AI and to understand how the world will change as AI and humans interact in increasingly layered and complex ways.
Replacement submissions (showing 14 of 14 entries)
[11]
arXiv:2211.04763
(replaced)
[pdf, html, other]
Title:
Jihad over Centuries
Masahiro Kubo, Shunsuke Tsuda
Subjects:
General Economics (econ.GN)
This paper examines the origins of Islamist insurgencies, or jihad, through the lens of past prosperity, decline, and cultural revival in West Africa. Using shrinking water sources as an instrument, we show that trans-Saharan cities once-thriving under pre-colonial Islamic states but now deserted have become contemporary hotspots of jihadist violence. We argue that military power asymmetries between Islamic states and colonizers during historical jihad shaped the persistence of jihadist ideology, fueling today's resurgence especially in areas that lacked intense armed resistance against colonial invasions. Extensive qualitative evidence, a dynamic model of conflict, and individual-level surveys examining ideologies support this mechanism.
[12]
arXiv:2401.13694
(replaced)
[pdf, other]
Title:
The Arrival of Fast Internet and Employment in Africa: Comment
David Roodman
Subjects:
General Economics (econ.GN)
Hjort and Poulsen (2019) frames the staggered arrival of submarine Internet cables on the shores of Africa circa 2010 as a difference-in-differences natural experiment. The paper finds positive impacts of broadband on individual- and firm-level employment--with a bias toward skilled employment--and on nighttime light emissions. These results largely are not robust to alternative geocoding of survey locations, to correcting for a satellite changeover at end-2009, and to revisiting a definition of the treated zone that has no clear technological basis, is narrower than the spatial resolution of nearly all the data sources, and is empirically suboptimal as a representation of the geography of broadband.
[13]
arXiv:2403.18503
(replaced)
[pdf, html, other]
Title:
Distributional Treatment Effect with Latent Rank Invariance
Myungkou Shin
Subjects:
Econometrics (econ.EM)
Treatment effect heterogeneity is of a great concern when evaluating policy impact: "is the treatment Pareto-improving?", "what is the proportion of people who are better off under the treatment?", etc. However, even in the simple case of a binary random treatment, existing analysis has been mostly limited to an average treatment effect or a quantile treatment effect, due to the fundamental limitation that we cannot simultaneously observe both treated potential outcome and untreated potential outcome for a given unit. This paper assumes a conditional independence assumption that the two potential outcomes are independent of each other given a scalar latent variable. With a specific example of strictly increasing conditional expectation, I label the latent variable as 'latent rank' and motivate the identifying assumption as 'latent rank invariance.' In implementation, I assume a finite support on the latent variable and propose an estimation strategy based on a nonnegative matrix factorization. A limiting distribution is derived for the distributional treatment effect estimator, using Neyman orthogonality.
[14]
arXiv:2404.10111
(replaced)
[pdf, html, other]
Title:
From Predictive Algorithms to Automatic Generation of Anomalies
Sendhil Mullainathan, Ashesh Rambachan
Subjects:
Econometrics (econ.EM)
How can we extract theoretical insights from machine learning algorithms? We take a familiar lesson: researchers often turn their intuitions into theoretical insights by constructing "anomalies" -- specific examples highlighting hypothesized flaws in a theory, such as the Allais paradox and the Kahneman-Tversky choice experiments for expected utility. We develop procedures that replace researchers' intuitions with predictive algorithms: given a predictive algorithm and a theory, our procedures automatically generate anomalies for that theory. We illustrate our procedures with a concrete application: generating anomalies for expected utility theory. Based on a neural network that accurately predicts lottery choices, our procedures recover known anomalies for expected utility theory and discover new ones absent from existing work. In incentivized experiments, subjects violate expected utility theory on these algorithmically generated anomalies at rates similar to the Allais paradox and common ratio effect.
[15]
arXiv:2411.19572
(replaced)
[pdf, html, other]
Title:
Canonical correlation analysis of stochastic trends via functional approximation
Massimo Franchi, Iliyan Georgiev, Paolo Paruolo
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
This paper proposes a novel approach for semiparametric inference on the number $s$ of common trends and their loading matrix $\psi$ in $I(1)/I(0)$ systems. It combines functional approximation of limits of random walks and canonical correlations analysis, performed between the $p$ observed time series of length $T$ and the first $K$ discretized elements of an $L^2$ basis. Tests and selection criteria on $s$, and estimators and tests on $\psi$ are proposed; their properties are discussed as $T$ and $K$ diverge sequentially for fixed $p$ and $s$. It is found that tests on $s$ are asymptotically pivotal, selection criteria of $s$ are consistent, estimators of $\psi$ are $T$-consistent, mixed-Gaussian and efficient, so that Wald tests on $\psi$ are asymptotically Normal or $\chi^2$. The paper also discusses asymptotically pivotal misspecification tests for checking model assumptions. The approach can be coherently applied to subsets or aggregations of variables in a given panel. Monte Carlo simulations show that these tools have reasonable performance for $T\geq 10 p$ and $p\leq 300$. An empirical analysis of 20 exchange rates illustrates the methods.
[16]
arXiv:2504.12727
(replaced)
[pdf, html, other]
Title:
Efficient Major Transition Exchange under Distributional and Dual Priority-respecting Constraints
Yao Cheng, Jingsheng Yu, Ling Zheng
Subjects:
Theoretical Economics (econ.TH)
Many real matching markets encounter distributional and fairness constraints. Motivated by the Chinese Major Transition Program (CMT), this paper studies the design of exchange mechanisms within a fresh framework of both distributional and dual priority-respecting constraints. Specifically, each student has an initial assigned major and applies to transfer to a more desirable one. A student can successfully transfer majors only if they obtain eligibility from both their initial major and the applied major. Each major has a dual priority: a strict priority over current students who wish to transfer out and a strict priority over students from other majors who wish to transfer in. Additionally, each major faces a ceiling constraint and a floor constraint to regulate student distribution. We show that the existing mechanisms of CMT result in avoidable inefficiencies, and propose two mechanisms that can match students to majors in an efficient way as well as respecting each major's distributional and dual priority. The efficient mechanisms are based on a proposed solution concept: eligibility maximization (EM), and two processes for identifying improvement cycles--specifically, transfer-in exchangeable cycles and transfer-out exchangeable cycles.
[17]
arXiv:2507.06422
(replaced)
[pdf, html, other]
Title:
Trial Length, Pricing, and Rationally Inattentive Customers
F. Nguyen
Subjects:
General Economics (econ.GN)
The "free trial" followed by automatic renewal is a dominant business model in the digital economy. Standard models explain trials as a mechanism for consumers to learn their valuation for a product. We propose a complementary theory based on the rational inattention framework. Consumers know their valuation but face a cognitive cost to remember to cancel an unwanted subscription. We model this using a Shannon entropy-based cost of information processing, where a consumer's baseline attention level decays with the length of the trial period. This creates a novel trade-off for a monopolist firm: a longer trial increases "inattentive revenue" from consumers who fail to cancel, but it also lowers ex-ante consumer utility, making the initial offer less attractive. We show that this trade-off leads to an interior optimal trial length, even for products where value-learning is instantaneous. Our model, under standard assumptions about demand elasticity and the distribution of consumer valuations, generates sharp, testable predictions about the relationship between contract terms. We find that the optimal renewal price and trial length are complements: firms offering longer trials will also set higher post-trial prices. We analyze the impact of policies aimed at curbing consumer exploitation, such as "click-to-cancel" regulations. We show that such policies, by making attention effectively cheaper, lead firms to reduce trial lengths. The effect on price depends directly on the elasticity of demand from loyal subscribers. We also extend the model to include paid trials, showing that introductory prices and trial lengths act as strategic substitutes. Our framework provides a micro-founded explanation for common features of subscription contracts and offers a new lens through which to evaluate consumer protection policies in digital markets.
[18]
arXiv:2507.20410
(replaced)
[pdf, other]
Title:
Beyond pay: AI skills reward more job benefits
Alejandra Mira, Matthew Bone, Fabian Stephany
Comments:
42 pages, 10 figures, 6 tables
Subjects:
General Economics (econ.GN)
This study investigates the non-monetary rewards associated with artificial intelligence (AI) skills in the U.S. labour market. Using a dataset of approximately ten million online job vacancies from 2018 to 2024, we identify AI roles-positions requiring at least one AI-related skill-and examine the extent to which these roles offer non-monetary benefits such as tuition assistance, paid leave, health and well-being perks, parental leave, workplace culture enhancements, and remote work options. While previous research has documented substantial wage premiums for AI-related roles due to growing demand and limited talent supply, our study asks whether this demand also translates into enhanced non-monetary compensation. We find that AI roles are significantly more likely to offer such perks, even after controlling for education requirements, industry, and occupation type. It is twice as likely for an AI role to offer parental leave and almost three times more likely to provide remote working options. Moreover, the highest-paying AI roles tend to bundle these benefits, suggesting a compound premium where salary increases coincide with expanded non-monetary rewards. AI roles offering parental leave or health benefits show salaries that are, on average, 12% to 20% higher than AI roles without this benefit. This pattern is particularly pronounced in years and occupations experiencing the highest AI-related demand, pointing to a demand-driven dynamic. Our findings underscore the strong pull of AI talent in the labor market and challenge narratives of technological displacement, highlighting instead how employers compete for scarce talent through both financial and non-financial incentives.
[19]
arXiv:2508.16002
(replaced)
[pdf, html, other]
Title:
Land and Infinite Debt Rollover
Tomohiro Hirano, Alexis Akira Toda
Subjects:
Theoretical Economics (econ.TH)
Since McCallum (1987), it is well known that in an overlapping generations (OLG) economy with land, the equilibrium is Pareto efficient because with balanced growth, the interest rate exceeds the economic growth rate ($R>G$), which rules out infinite debt rollover (a Ponzi scheme). We show that once we remove knife-edge restrictions on the production function and allow unbalanced growth, under some conditions an efficient equilibrium with land bubbles necessarily emerges and infinite debt rollover becomes possible, which is a markedly different insight from the conventional view derived from the Diamond (1965) landless economy. We also examine the possibility of Pareto inefficient equilibria.
[20]
arXiv:2508.20075
(replaced)
[pdf, html, other]
Title:
Predicting Qualification Thresholds in UEFA's incomplete round-robin tournaments
David Winkelmann, Rouven Michels, Christian Deutscher
Subjects:
General Economics (econ.GN)
For the 2024/25 season, the Union of European Football Associations (UEFA) introduced an incomplete round-robin format in the Champions League, Europa League, and Conference League, replacing the traditional group stage with a single league table of all 36 teams. Under this structure, the top eight teams advance directly to the round of 16, while those ranked 9th-24th compete in a play-off round. Simulation-based analyses, such as those by commercial data analyst Opta, provide indicative point thresholds for qualification but reveal deviations when compared with actual outcomes in the first season. To overcome these discrepancies, we employ a bivariate Dixon-Coles model that accounts for the lower frequency of draws observed in the 2024/25 UCL season, with team strengths proxied by Elo ratings. This framework enables the simulation of match outcomes and the estimation of qualification thresholds for both direct advancement and play-off participation. Our results provide scientific guidance for clubs and managers, supporting strategic decision-making under uncertainty regarding their progression prospects in the new UEFA club competition formats.
[21]
arXiv:2203.16272
(replaced)
[pdf, html, other]
Title:
The infinite information gap between mathematical and physical representations
Pedro Hack, Daniel A. Braun, Sebastian Gottwald
Subjects:
Combinatorics (math.CO); Information Theory (cs.IT); Theoretical Economics (econ.TH)
Partial orders have been used to model several experimental setups, going from classical thermodynamics and general relativity to the quantum realm with its resource theories. In order to study such experimental setups, one typically characterizes them via a (numerical) representation, that is, a set of real-valued functions. In the context of resource theory, it is customary to use \textbf{mathematical} representations, i.e. a set of \textbf{measurement outcomes} which characterize the achievable transitions within the experimental setup. However, in line with the minimum energy and maximum entropy principles in classical mechanics and thermodynamics, respectively, one would expect an optimization interpretation for a representation to be called \textbf{physical}. More specifically, a physical representation could consist of a set of competing \textbf{optimization principles} such that a transition happens provided they are all optimized by it. Somewhat surprisingly, we show that this distinction can result in an \textbf{infinite information gap}, with some partial orders having mathematical representations that involve a finite amount of information and requiring infinite information to build a physical representation. We connect this phenomenon with well-known resource-theoretic scenarios like majorization, and develop notions of partial order dimension that run in parallel to the representations that we consider. Our results improve on the classification of preordered spaces in terms of real-valued functions.
[22]
arXiv:2504.13520
(replaced)
[pdf, html, other]
Title:
Bayesian Model Averaging in Causal Instrumental Variable Models
Gregor Steiner, Mark Steel
Subjects:
Methodology (stat.ME); Econometrics (econ.EM); Statistics Theory (math.ST)
Instrumental variables are a popular tool to infer causal effects under unobserved confounding, but choosing suitable instruments is challenging in practice. We propose gIVBMA, a Bayesian model averaging procedure that addresses this challenge by averaging across different sets of instrumental variables and covariates in a structural equation model. Our approach extends previous work through a scale-invariant prior structure and accommodates non-Gaussian outcomes and treatments, offering greater flexibility than existing methods. The computational strategy uses conditional Bayes factors to update models separately for the outcome and treatments. We prove that this model selection procedure is consistent. By explicitly accounting for model uncertainty, gIVBMA allows instruments and covariates to switch roles and provides robustness against invalid instruments. In simulation experiments, gIVBMA outperforms current state-of-the-art methods. We demonstrate its usefulness in two empirical applications: the effects of malaria and institutions on income per capita and the returns to schooling. A software implementation of gIVBMA is available in Julia.
[23]
arXiv:2506.04169
(replaced)
[pdf, html, other]
Title:
A primal-dual price-optimization method for computing equilibrium prices in mean-field games models
Xu Wang, Samy Wu Fung, Levon Nurbekyan
Subjects:
Optimization and Control (math.OC); Theoretical Economics (econ.TH); Numerical Analysis (math.NA)
We develop a simple yet efficient Lagrangian method for computing equilibrium prices in a mean-field game price-formation model. We prove that equilibrium prices are optimal in terms of a suitable criterion and derive a primal-dual gradient-based algorithm for computing them. One of the highlights of our computational framework is the efficient, simple, and flexible implementation of the algorithm using modern automatic differentiation techniques. Our implementation is modular and admits a seamless extension to high-dimensional settings with more complex dynamics, costs, and equilibrium conditions. Additionally, automatic differentiation enables a versatile algorithm that requires only coding the cost functions of agents. It automatically handles the gradients of the costs, thereby eliminating the need to manually form the adjoint equations.
[24]
arXiv:2506.20523
(replaced)
[pdf, html, other]
Title:
Anytime-Valid Inference in Adaptive Experiments: Covariate Adjustment and Balanced Power
Daniel Molitor, Samantha Gold
Comments:
14 pages, 5 figures
Subjects:
Methodology (stat.ME); Econometrics (econ.EM); Computation (stat.CO)
Adaptive experiments such as multi-armed bandits offer efficiency gains over traditional randomized experiments but pose two major challenges: invalid inference on the Average Treatment Effect (ATE) due to adaptive sampling and low statistical power for sub-optimal treatments. We address both issues by extending the Mixture Adaptive Design framework (arXiv:2311.05794). First, we propose MADCovar, a covariate-adjusted ATE estimator that is unbiased and preserves anytime-valid inference guarantees while substantially improving ATE precision. Second, we introduce MADMod, which dynamically reallocates samples to underpowered arms, enabling more balanced statistical power across treatments without sacrificing valid inference. Both methods retain MAD's core advantage of constructing asymptotic confidence sequences (CSs) that allow researchers to continuously monitor ATE estimates and stop data collection once a desired precision or significance criterion is met. Empirically, we validate both methods using simulations and real-world data. In simulations, MADCovar reduces CS width by up to $60\%$ relative to MAD. In a large-scale political RCT with $\approx32,000$ participants, MADCovar achieves similar precision gains. MADMod improves statistical power and inferential precision across all treatment arms, particularly for suboptimal treatments. Simulations show that MADMod sharply reduces Type II error while preserving the efficiency benefits of adaptive allocation. Together, MADCovar and MADMod make adaptive experiments more practical, reliable, and efficient for applied researchers across many domains. Our proposed methods are implemented through an open-source software package.
Total of 24 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack