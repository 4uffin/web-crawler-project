Economics
Skip to main content
We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors.
Donate
>
econ
Help | Advanced Search
All fields
Title
Author
Abstract
Comments
Journal reference
ACM classification
MSC classification
Report number
arXiv identifier
DOI
ORCID
arXiv author ID
Help pages
Full text
Search
open search
GO
open navigation menu
quick links
Login
Help Pages
About
Economics
New submissions
Replacements
See recent articles
Showing new listings for Wednesday, 17 September 2025
Total of 14 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
New submissions (showing 5 of 5 entries)
[1]
arXiv:2509.12388
[pdf, other]
Title:
A Decision Theoretic Perspective on Artificial Superintelligence: Coping with Missing Data Problems in Prediction and Treatment Choice
Jeff Dominitz, Charles F. Manski
Subjects:
Econometrics (econ.EM)
Enormous attention and resources are being devoted to the quest for artificial general intelligence and, even more ambitiously, artificial superintelligence. We wonder about the implications for our methodological research, which aims to help decision makers cope with what econometricians call identification problems, inferential problems in empirical research that do not diminish as sample size grows. Of particular concern are missing data problems in prediction and treatment choice. Essentially all data collection intended to inform decision making is subject to missing data, which gives rise to identification problems. Thus far, we see no indication that the current dominant architecture of machine learning (ML)-based artificial intelligence (AI) systems will outperform humans in this context. In this paper, we explain why we have reached this conclusion and why we see the missing data problem as a cautionary case study in the quest for superintelligence more generally. We first discuss the concept of intelligence, before presenting a decision-theoretic perspective that formalizes the connection between intelligence and identification problems. We next apply this perspective to two leading cases of missing data problems. Then we explain why we are skeptical that AI research is currently on a path toward machines doing better than humans at solving these identification problems.
[2]
arXiv:2509.12538
[pdf, html, other]
Title:
Policy-relevant causal effect estimation using instrumental variables with interference
Didier Nibbering, Matthijs Oosterveen
Subjects:
Econometrics (econ.EM)
Many policy evaluations using instrumental variable (IV) methods include individuals who interact with each other, potentially violating the standard IV assumptions. This paper defines and partially identifies direct and spillover effects with a clear policy-relevant interpretation under relatively mild assumptions on interference. Our framework accommodates both spillovers from the instrument to treatment and from treatment to outcomes and allows for multiple peers. By generalizing monotone treatment response and selection assumptions, we derive informative bounds on policy-relevant effects without restricting the type or direction of interference. The results extend IV estimation to more realistic social contexts, informing program evaluation and treatment scaling when interference is present.
[3]
arXiv:2509.12985
[pdf, html, other]
Title:
Dynamic Local Average Treatment Effects in Time Series
Alessandro Casini, Adam McCloskey, Luca Rolla, Raimondo Pala
Subjects:
Econometrics (econ.EM)
This paper discusses identification, estimation, and inference on dynamic local average treatment effects (LATEs) in instrumental variables (IVs) settings. First, we show that compliers--observations whose treatment status is affected by the instrument--can be identified individually in time series data using smoothness assumptions and local comparisons of treatment assignments. Second, we show that this result enables not only better interpretability of IV estimates but also direct testing of the exclusion restriction by comparing outcomes among identified non-compliers across instrument values. Third, we document pervasive weak identification in applied work using IVs with time series data by surveying recent publications in leading economics journals. However, we find that strong identification often holds in large subsamples for which the instrument induces changes in the treatment. Motivated by this, we introduce a method based on dynamic programming to detect the most strongly-identified subsample and show how to use this subsample to improve estimation and inference. We also develop new identification-robust inference procedures that focus on the most strongly-identified subsample, offering efficiency gains relative to existing full sample identification-robust inference when identification fails over parts of the sample. Finally, we apply our results to heteroskedasticity-based identification of monetary policy effects. We find that about 75% of observations are compliers (i.e., cases where the variance of the policy shifts up on FOMC announcement days), and we fail to reject the exclusion restriction. Estimation using the most strongly-identified subsample helps reconcile conflicting IV and GMM estimates in the literature.
[4]
arXiv:2509.13141
[pdf, html, other]
Title:
A hidden benefit of incomplete round-robin tournaments: Encouraging offensive play
László Csató
Subjects:
General Economics (econ.GN); Physics and Society (physics.soc-ph); Applications (stat.AP)
This paper aims to explore the impact of tournament design on the incentives of the contestants. We develop a simulation framework to quantify the potential gain and loss from attacking based on changes in the probability of reaching the critical ranking thresholds. The model is applied to investigate the 2024/25 UEFA Champions League reform. The novel incomplete round-robin league phase is found to create more powerful incentives for offensive play than the previous group stage, with an average increase of 119\% (58\%) regarding the first (second) prize. Our study provides the first demonstration that the tournament format itself can strongly influence team behaviour in sports.
[5]
arXiv:2509.13198
[pdf, html, other]
Title:
Efficiency, Envy, and Incentives in Combinatorial Assignment
Thành Nguyen, Alexander Teytelboym, Shai Vardi
Comments:
Abstract published in EC'25 (this https URL)
Subjects:
Theoretical Economics (econ.TH)
Ensuring efficiency and envy-freeness in allocating indivisible goods without money often requires randomization. However, existing combinatorial assignment mechanisms (for applications such as course allocation, food banks, and refugee resettlement) guarantee these properties either ex ante or ex post, but not both. We propose a new class of mechanisms based on Competitive Equilibrium from Random Incomes (CERI): Agents receive random token budgets and select optimal lotteries at competitive prices that clear markets in expectation. Our main insight is to let the CERI price vector guide all ex-post allocations. We show that all ordinally efficient allocations are CERI allocations, which can be implemented as lotteries over near-feasible Pareto-efficient outcomes. With identical budget distributions, CERI allocations are ordinally envy-free; with budget distributions on small supports, ex-post allocations are envy-free up to one good. Moreover, we design an asymptotically efficient implementation of CERI that satisfies a strong new non-manipulability property in large markets.
Replacement submissions (showing 9 of 9 entries)
[6]
arXiv:2411.04841
(replaced)
[pdf, html, other]
Title:
Robust Regulation of Labour Contracts
Théo Durandard, Alexis Ghersengorin
Subjects:
Theoretical Economics (econ.TH)
We study the robust regulation of contracts in moral hazard problems. A firm offers a contract to incentivise a worker protected by limited liability. A regulator restricts the set of permissible contracts to (i) improve efficiency and (ii) protect the worker. The regulator faces uncertainty about both the worker's actions and the firm's production cost, and evaluates regulations based on their worst-case regret. The regret-minimising regulation mandates a minimum piece rate compensation for the worker. This rule simultaneously guarantees a fair share for the worker and preserves enough contractual flexibility to provide incentives.
[7]
arXiv:2502.19788
(replaced)
[pdf, other]
Title:
Semiparametric Triple Difference Estimators
Sina Akbari, Negar Kiyavash, AmirEmad Ghassami
Comments:
59 pages
Subjects:
Econometrics (econ.EM); Methodology (stat.ME)
The triple difference causal inference framework is an extension of the well-known difference-in-differences framework. It relaxes the parallel trends assumption of the difference-in-differences framework through leveraging data from an auxiliary domain. Despite being commonly applied in empirical research, the triple difference framework has received relatively limited attention in the statistics literature. Specifically, investigating the intricacies of identification and the design of robust and efficient estimators for this framework has remained largely unexplored. This work aims to address these gaps in the literature. From the identification standpoint, we present outcome regression and weighting methods to identify the average treatment effect on the treated in both panel data and repeated cross-section settings. For the latter, we relax the commonly made assumption of time-invariant composition of units. From the estimation perspective, we develop semiparametric estimators for the triple difference framework in both panel data and repeated cross-sections settings. These estimators are based on the cross-fitting technique, and flexible machine learning tools can be used to estimate the nuisance components. We characterize conditions under which our proposed estimators are efficient, doubly robust, root-n consistent and asymptotically normal. As an application of our proposed methodology, we examined the effect of mandated maternity benefits on the hourly wages of women of childbearing age and found that these mandates result in a 2.6% drop in hourly wages.
[8]
arXiv:2504.17948
(replaced)
[pdf, html, other]
Title:
Robust Contracting for Sequential Search
Théo Durandard, Udayan Vaidya, Boli Xu
Subjects:
Theoretical Economics (econ.TH)
A principal contracts with an agent who sequentially searches over projects to generate a prize. The principal initially knows only one of the agent's available projects and evaluates a contract by its worst-case performance. We characterize the principal's robustly optimal contracts, which are all debt-like: the agent is only paid when the prize exceeds a threshold. Debt is optimal because it preserves the option value of continued exploration. Our characterization encompasses several common contract forms, including pure debt, debt-plus-equity, and capped-earnout debt. We identify settings in which each of these contracts is uniquely optimal.
[9]
arXiv:2504.19832
(replaced)
[pdf, html, other]
Title:
Assignment at the Frontier: Identifying the Frontier Structural Function and Bounding Mean Deviations
Dan Ben-Moshe, David Genesove
Subjects:
Econometrics (econ.EM); General Economics (econ.GN)
This paper analyzes a model in which an outcome equals a frontier function of inputs minus a nonnegative unobserved deviation. We allow the distribution of the deviation to depend on inputs. If zero lies in the support of the deviation given inputs -- an assumption we term assignment at the frontier -- then the frontier is identified by the supremum of the outcome at those inputs, obviating the need for instrumental variables. We then estimate the frontier, allowing for random error whose distribution may also depend on inputs. Finally, we derive a lower bound on the mean deviation, using only variance and skewness, that is robust to a scarcity of data near the frontier. We apply our methods to estimate a firm-level frontier production function and mean inefficiency.
[10]
arXiv:2509.07145
(replaced)
[pdf, html, other]
Title:
Efficient Defection: Overage-Proportional Rationing Attains the Cooperative Frontier
Florian Lengyel
Comments:
10 pages. Corrections to the boundary allocation in Appendix A to preserve budget balance; clarification of the dominant strategy result; bounded-actions paragraph added; aggregate-identity discussion tightened
Subjects:
Theoretical Economics (econ.TH); Optimization and Control (math.OC)
We study a noncooperative $n$-player game of slack allocation in which each player $j$ has entitlement $L_j>0$ and chooses a claim $C_j\ge0$. Let $v_j=(C_j-L_j)_+$ (overage) and $s_j=(L_j-C_j)_+$ (slack); set $X=\sum_j v_j$ and $I=\sum_j s_j$. At the end of the period an overage-proportional clearing rule allocates cooperative surplus $I$ to defectors in proportion to $v_j$; cooperators receive $C_j$. We show: (i) the selfish outcome reproduces the cooperative payoff vector $(L_1,\dots,L_n)$; (ii) with bounded actions, defection is a weakly dominant strategy; (iii) within the $\alpha$-power family, the linear rule ($\alpha=1$) is the unique boundary-continuous member; and (iv) the dominant-strategy outcome is Strong Nash under transferable utility and hence coalition-proof (Bernheim et al., 1987). We give a policy interpretation for carbon rationing with a penalty collar.
[11]
arXiv:2509.12084
(replaced)
[pdf, other]
Title:
Geopolitical Barriers to Globalization
Tianyu Fan, Mai Wo, Wei Xiang
Subjects:
General Economics (econ.GN)
This paper estimates and quantifies how geopolitical alignment shapes global trade across three distinct eras: the Cold War, hyper-globalization, and contemporary fragmentation. We construct a novel measure of bilateral alignment using large language models to compile and analyze 833,485 political events spanning 193 countries from 1950 to 2024. Our analysis reveals that trade flows systematically track geopolitical alignment in both bilateral relationships and aggregate patterns. Using local projections within a gravity framework, we estimate that a one-standard-deviation improvement in geopolitical alignment increases bilateral trade by 20 percent over ten years. Integrating these elasticities into a quantitative general equilibrium model, we find that deteriorating geopolitical relations have reduced global trade by 7 percentage points between 1995 and 2020. Our findings provide empirical benchmarks for evaluating the costs of geopolitical fragmentation in an era of renewed great power competition.
[12]
arXiv:2309.08808
(replaced)
[pdf, html, other]
Title:
Adaptive Neyman Allocation
Jinglong Zhao
Subjects:
Methodology (stat.ME); Econometrics (econ.EM)
In the experimental design literature, Neyman allocation refers to the practice of allocating units into treated and control groups, potentially in unequal numbers proportional to their respective standard deviations, with the objective of minimizing the variance of the treatment effect estimator. This widely recognized approach increases statistical power in scenarios where the treated and control groups have different standard deviations, as is often the case in social experiments, clinical trials, marketing research, and online A/B testing. However, Neyman allocation cannot be implemented unless the standard deviations are known in advance. Fortunately, the multi-stage nature of the aforementioned applications allows the use of earlier stage observations to estimate the standard deviations, which further guide allocation decisions in later stages. In this paper, we introduce a competitive analysis framework to study this multi-stage experimental design problem. We propose a simple adaptive Neyman allocation algorithm, which almost matches the information-theoretic limit of conducting experiments. We provide theory for estimation and inference using data collected from our adaptive Neyman allocation algorithm. Using online A/B testing data from a social media site, we demonstrate the effectiveness of our adaptive Neyman allocation algorithm, highlighting its practicality especially when applied with only a limited number of stages.
[13]
arXiv:2409.15320
(replaced)
[pdf, html, other]
Title:
Global Stock Market Volatility Forecasting Incorporating Dynamic Graphs and All Trading Days
Zhengyang Chi, Junbin Gao, Chao Wang
Subjects:
General Finance (q-fin.GN); General Economics (econ.GN)
This paper introduces a global stock market volatility forecasting model that enhances forecasting accuracy and practical utility in real-world financial decision-making by integrating dynamic graph structures and encompassing all active trading days of different stock markets. The model employs a spatial-temporal graph neural network architecture to capture the volatility spillover effect, where shocks in one market spread to others through the interconnective global economy. By calculating the volatility spillover index to depict the volatility network as graphs, the model effectively mirrors the volatility dynamics for the chosen stock market indices. In the empirical analysis covering 8 global market indices, the realized volatility forecasting performance of the proposed model surpasses the baseline models in all forecasting scenarios.
[14]
arXiv:2508.06788
(replaced)
[pdf, html, other]
Title:
Returns and Order Flow Imbalances: Intraday Dynamics and Macroeconomic News Effects
Makoto Takahashi
Subjects:
Trading and Market Microstructure (q-fin.TR); Econometrics (econ.EM)
We study the interaction between returns and order flow imbalances in the S&P 500 E-mini futures market using a structural VAR model identified through heteroskedasticity. The model is estimated at one-second frequency for each 15-minute interval, capturing both intraday variation and endogeneity due to time aggregation. We find that macroeconomic news announcements sharply reshape price-flow dynamics: price impact rises, flow impact declines, return volatility spikes, and flow volatility falls. Pooling across days, both price and flow impacts are significant at the one-second horizon, with estimates broadly consistent with stylized limit-order-book predictions. Impulse responses indicate that shocks dissipate almost entirely within a second. Structural parameters and volatilities also exhibit pronounced intraday variation tied to liquidity, trading intensity, and spreads. These results provide new evidence on high-frequency price formation and liquidity, highlighting the role of public information and order submission in shaping market quality.
Total of 14 entries
Showing up to 2000 entries per page:
fewer
|
more
|
all
About
Help
contact arXivClick here to contact arXiv
Contact
subscribe to arXiv mailingsClick here to subscribe
Subscribe
Copyright
Privacy Policy
Web Accessibility Assistance
arXiv Operational Status
Get status notifications via
email
or slack